{"docstore/metadata": {"5b82c9c8-2180-4e66-82e2-241b7c30ec93": {"doc_hash": "9c3fe7ea69f3c85341c1b6378c01a9b67063dc32436fb1754bea592e61204f4c"}, "c5673611-25e2-41d9-9876-9af11e195cf5": {"doc_hash": "b631a67f97299d2ebe112fe018d9cff8b48e36b22681fb576b29f57f47a6891a"}, "53dcb9dd-469f-49cc-80eb-3206a877b2a0": {"doc_hash": "76b587e877ce9d2f7ee8a418a4fb3d0f9817d90be1af24bddbad2ad26eceb4d3"}, "0dc195f2-5f50-4e4f-8d74-fbd2af902028": {"doc_hash": "761f8ce0cb8eb9ba64285469d48c5fb284949c76c850a42c2ca930a9537c2a4a"}, "d79af461-1059-4e52-9556-4891affa01c8": {"doc_hash": "6d9df816311071ef43c0c673d65b923d685e3d1fff63dee3c721d9af59443757"}, "eb1f3b57-90f3-49d0-972d-de767ce72e9a": {"doc_hash": "9d122fb7d1a23c0b0c927bb9d3466908e3aff5c8919ba53d90d21ef3b37482cd"}, "c9a4642b-d62e-4ad6-b31d-0062a0ca3a4a": {"doc_hash": "770189f91c5c4f49e6ec23bc1e7a5b243272f4a401728709e218bc824d5b1045"}, "1fcf03cb-ecee-4d5e-b18a-d9ee72a327d0": {"doc_hash": "24289008825ce08b7658534bac1b79fddf2af4bccb7f66b00cf598b6b372aeb7"}, "786a7d7a-0162-4682-b02b-531e5f4fc69f": {"doc_hash": "ec4cb1f7d06bdd8d591fed3c07ccd7675eb5719372fa92a9ba4b3348f45afbf9"}, "ea6b23f1-6fd5-4771-882d-3ea60524b2b1": {"doc_hash": "0ae1ba583f78b6f2aa6593a266c0778208097fa9f158eb7991396a3d8ebe05fd"}, "db3e17d0-e3f4-4e60-8045-5a737f60f8a2": {"doc_hash": "1e9fbd5c5b5e3f004dc9a37ac4af7f8f8920a1b5ce690a5f7345245b1d4e3589"}, "18d99bb5-3e1d-42f9-ba56-97d775b9be75": {"doc_hash": "951b5ea15bb0150dd07ec79a9c0ccb5a8889d812ed0fa54ee4334ad12d6129da"}, "215fcb91-3729-4a8e-b0c6-fcb94d63c1f9": {"doc_hash": "70ee743701db2d2c125a6aaffadba4498a8e7735cbde2f073d6c80f65fec4126"}, "c0e152a5-e5de-469d-8296-e42e4c91ce06": {"doc_hash": "8c690bb42a26dccbd08fee8dc46646be3bda7b3118c24e29208e9b790ee558a9"}, "b6dd1d79-b51e-4a4c-a10b-01042ab1231e": {"doc_hash": "8e790e397a42292ff9a476edc6837e421476260e0ba0ee490376049169f3c6c2"}, "b906dc53-6218-4965-bbee-11ff3773cbc3": {"doc_hash": "4b6f0381517ca1b91fe78f8c3e948711a74236bcbd3d4fa93040efd5de6b4b48"}, "6aefc6b9-dfc7-4145-8af6-d4cfe1d88b66": {"doc_hash": "dcb54571ff57041e6afefd05d9fbaa5d4a1d3ba695b6c5c47d15ef253cc70680"}, "395eba3c-e464-4324-91b7-cf394d58ff01": {"doc_hash": "8b84967c6fecc833800280d65580ba58e703a0f08ac5b0157fe0fe3f46efa0ad"}, "d9effd90-3af2-4a95-8ad0-0893de9c33d6": {"doc_hash": "7a7201b6e12ffd4a663e1a22ca29838b41cea1bf1625aeafcf5c097a1299a406"}, "16350240-6b3d-4820-b90a-c8c4fd7914f7": {"doc_hash": "6e98153abc046bbc36685c494d95130e764957915c9d9fcaba51290f5b99fb1e"}, "3b3c553c-e5d5-4856-911b-c7c534ff1862": {"doc_hash": "be838ad06135c9f04c99420f6fce7b11b59bd93d2affa4839f35780192b13799"}, "97ba6cc2-d0ec-458e-bf08-51f1d6f6f23d": {"doc_hash": "18288d4b615cb0a5957bacfb5bd54bfc0535199af32a899f147bd0e527afcf96"}, "76299b89-621f-4bbf-93ad-30aebf63a51c": {"doc_hash": "e7c2090cb4a02095c6941ad3b14a6a3551c237bb6f0900be087b96a8e9f90260"}, "5c4bf2ac-c79b-4f64-930e-f6173e1ed4ca": {"doc_hash": "ee72a5b96a7cd656684f9dac93371e34cc8907bbb4027ed0214e02ff73632816"}, "1e4eee52-55ec-4844-9b25-c1dbaf2dd1ec": {"doc_hash": "8d1c7fb0c14f4c7f91b9b3bc7c22a4121a3cac682bd17bd7ecbaf16bd1cbe9d9"}, "c56e98d0-04c6-4b38-9561-f61bcef455b6": {"doc_hash": "523bfe41daea5ddbce007a4bedc9367a9c5520f06fdef0dbe9a5c49f99aa69c1"}, "93e29045-984c-482e-b950-eb3404307ee8": {"doc_hash": "b2cd9d606f80fca81830e5ba6bdb7ef9e6fbc90a71413f3c4ea4d86d805f7570"}, "35ca024e-0d5f-4a44-8c30-4da4a10bc5c9": {"doc_hash": "5494be0141160b2d1bdeb79db50de4afc36a2159d31238d4c9159db99132039d"}, "d9c8293b-e05c-4d6f-85d2-d1a28989434b": {"doc_hash": "80264cc76d2fad124f28fa340b04a2543a5da7ab2f2c8a0ca1a03b3bcbb2f1ed"}, "1e93e5ce-8803-4eba-a06a-475d4452b068": {"doc_hash": "64197174f277691c3e6681a16629adc6f03c072c2bf01d50d71aa4ec89248d9d"}, "333ef42d-36fd-47a5-9ec1-69d996c5d8cb": {"doc_hash": "c47863698e9978f0b860354f0d556f6a01f70f363c3ad3edf185a01fbb6dedf0"}, "cd66a153-e7b6-4868-806c-9c0656c3397b": {"doc_hash": "261099be162bf43bf518ed0a6773837a6fcd6d8389ad1f1c539ea596e9f86056"}, "5cc245ff-6233-496b-bb08-15b535ae1ac8": {"doc_hash": "a8b98d8dd596982a93df524f24a459f7d848dce5f5c4e5d9bb21559b40d5620d"}, "4403b0c6-b720-4cc4-a2c1-3257daa22cc6": {"doc_hash": "4b6f0381517ca1b91fe78f8c3e948711a74236bcbd3d4fa93040efd5de6b4b48"}, "44ad1a04-e735-4821-ad7a-c69bba1a9be1": {"doc_hash": "dcb54571ff57041e6afefd05d9fbaa5d4a1d3ba695b6c5c47d15ef253cc70680"}, "1b1e80ce-831e-4f58-84b5-d9d2ff22e57d": {"doc_hash": "17042a59b63f98604e99678a2e3b7c20c6eb9ddb84275147941beb800cdb73c6"}, "5531282c-224e-4a4d-a57e-ab7e8088226d": {"doc_hash": "093092112155d07dc30969e5e93980781dc98dfab87c608a8410d5f83e3e1abd"}, "c442f20d-9eea-4b17-807f-395b8ca4098f": {"doc_hash": "4db1f84d1c35a3b282f03e32cd8ce18358ffe5de257a4b7b399e8a436226bf6c"}, "fd28e723-a1f8-4a41-91ce-023a2b41de59": {"doc_hash": "fd9246903b21c8674aa50f082d66526c6761a8abefec52f9c0097a54dda54840"}, "e716c6ef-b39b-432a-afa0-48e3407dc6ae": {"doc_hash": "042e78cda250fd261159fa79858b3ea45b2e5185cc1ac0273314c42fb41795ad"}, "866a1ff1-100d-45c6-86d8-d4a7e7b78dfe": {"doc_hash": "d6d8b3ba0036083babc7c3924c29ee73bc81185b78bc6508464623dc3e78ef17"}, "2829ca34-f061-428d-abb9-0fd026b6a0d1": {"doc_hash": "d1011bbb8dc0d5b1b2b26141c59ca6f4fb2c5d08fefc9d0995d43d345acabf22"}, "ce2e6bbc-d494-443a-8484-2d26fafa5653": {"doc_hash": "e4897479ef33e43208cee14ba6ce70ac34269c8fd848d5df69029f2bafc82962"}, "92bec081-db05-4090-83d1-9d0641d2db6a": {"doc_hash": "b8df4788e92aa19b3731924efdb5b0164fbf71f13c2030d419e6b0935fb2965c"}, "a0f8b6cf-6b44-4fd4-829f-cbd60e620347": {"doc_hash": "9ff3b1763ad62fbce73bd5f2db83f77332786c3c022721412594bad70ccd3de3"}, "79595773-0b28-409a-b62c-765f018efb84": {"doc_hash": "8093e195edf85c7254fc9fc3622c7c8874f8826eca5c9713be2bcd92dd77ae5c"}, "52eab5c2-81f9-4ab3-81f1-1d99b984af5f": {"doc_hash": "e7af29e5f78e7c02adbf7b0055d023480f538e2a0d9568fab4b85c5ed4a4bf82"}, "a9c5a44c-f72c-4e1d-b94d-c566a05da566": {"doc_hash": "5a1e0a842e627d7f2cf27abf8cdf0bc410d0cb5c4d7306b13a6d02c38890ce10"}, "b1490c59-64f6-40f4-9fd2-e059202e30c0": {"doc_hash": "c4733e39d19c9276c888f3274ca447563c4850fefb3a46c2187996e1b9e2cc18"}, "59751c52-fd4f-4cb5-8aef-62ed442d6dff": {"doc_hash": "94e2dc43bd4bdf03fc90d990f0665d65aed8c659bd8e0479b6fa5ba9234d6d58"}, "4c3eea78-409b-4958-81ae-21b705391912": {"doc_hash": "73db6d17f95493b7d008bc28168217e80a94901cb559fd55bffe6219ed4d298e"}, "7fe19708-d622-44a4-9a7a-786aa51572a3": {"doc_hash": "5fac918b14fe43bbacb62206aea41ec0c431b36d1c419b3adfe98c3fed1a2664"}, "f74d0530-7a58-4130-81b2-b77b6980b4ab": {"doc_hash": "07ed089568de7d9e643d2cd8ef0c90d0f2f3ed17f6c7148ccd669a4e47ca00f9"}, "6af856a7-a11f-414f-8373-a30f3c41256f": {"doc_hash": "31fb164d010ada6cb5ca66dd6aa0cf2d6898f058795e3e2e37a742b5c69df558"}, "08155926-75df-419b-9458-caf2c5ecc4b1": {"doc_hash": "53fb64cf97a4c847c5d24f3e06774f06f83afe4614fea1c79e485f7e5f2c8574"}, "1c716923-b0cc-4797-b227-8230b1fd6e3a": {"doc_hash": "48509ad97b1ca5bfb400104f8d69af3d3cf175c61febc404c4cdfcfe8f2202a6"}, "28f7d049-9981-48cf-84e2-795bf233cf37": {"doc_hash": "7d8e49173d0768995e6b29bac8b4247ff5a86525e9084d9617d1d3248b81dd6a"}, "7b197ddb-be91-4b3a-a59b-19cffb0b6342": {"doc_hash": "af9b0ac7f199da2d2d82b646186db484f607f811b75cf7f853bb3349113af2a3"}, "24982706-85ac-42c3-97ac-b4a8c6592e5d": {"doc_hash": "d5c45ace0f9088d500a2014a73f54c723c33c78d229de58c22119b217a1f15fc"}, "3b4440f3-9ce7-4247-adc0-9b23087c575e": {"doc_hash": "f9b278271342632cce5dd3a5cac603b29de16d40d112a048f3228c4369f72d08"}, "176eb101-e2ae-41b1-8a7b-450927351381": {"doc_hash": "dc5dd4dbf693efa122637841bd845f19d9a3dfcd4b99fcd4dadd62c375379dc9"}, "9d5e8ae6-6752-4f6a-8377-e72ad5638a9b": {"doc_hash": "9ca3aea90c3b3880314590de3c16db821ff069f0ca95bd761b8cb3d044d8d5ab"}, "06260f5f-be7b-4e98-9fb3-4c99ea145024": {"doc_hash": "d9f4b1627be78fed97105391f4eb8d3c41b5ef7c39c7268c913da5a5c481961a"}, "7e21868e-ba9b-4380-a855-202521461f7f": {"doc_hash": "408413b6d0a68efcc3f9907fe2f681f481cf225f0079c5f4a698b35e40dd3413"}, "be7eb8e5-f387-49e6-986c-690078e6b936": {"doc_hash": "4e0c57df8b4de8bcbaef304da6fce2699be958cd1d8dcd343782381c12b8585f"}, "aaf0c6f3-3762-4803-9d2c-0132320bbbe7": {"doc_hash": "9ff9fab4db751c49645de89455625da610f71b921b348f846d407ade49348886"}, "978d0625-cc07-4571-bfe3-0186b76ce3d9": {"doc_hash": "5dcbfadf1ecca523d7ab1a0c8bab459c21aec2e1f73a09ac0c5e6e4493776dc8"}, "1e938a27-90ae-4c2b-9c1a-07e6f872155a": {"doc_hash": "166a622da18b9518a93136ee8bc969546b4fd1e889e2092bd5e1a035114fe362"}, "b7ffda72-c1af-4db3-9444-f6be67aa1cae": {"doc_hash": "bef0c70f2ab51f0f37e56dcf285b0ad52c2de2933b0e411f5d6ded5e0bf99549"}, "705b6355-14b5-4f65-a675-8df3df6e5a93": {"doc_hash": "a39766a9bd339b63437a5dd13ae63719a19c2c8a8c21a66963b1e21cf72ff5ab"}, "8fa50a61-710c-4afd-8840-c3f3381797df": {"doc_hash": "a54408ce6b87a506414a873fb6fcc6c299863cbbd275f2ac4dfb75681cc8a4ba"}, "24dd446e-eae0-42f8-9eda-28e3458bb578": {"doc_hash": "7e49226ca395dd360d696dece841971f2fec0892c6f9d76482d69c6260e11839"}, "da610f06-05fe-46f6-bf63-22501ba7af0e": {"doc_hash": "69e9c3beda2adf873b444924e1596fe4255966db4abf35c40ffc6d12f40d9870"}, "0c0963c2-7f45-4042-888a-9480b7f17784": {"doc_hash": "a494d4adc91a960f949b08a2839b5b03585be50f7e77e75c54d8b55543b81a6b"}, "4761dfb3-ae18-4e5c-852a-c3548477a115": {"doc_hash": "d59792953cdeba1986724823fd1de8e625c65030ec112c1690aff2e663809829"}, "5b70fabd-409d-4e3b-aa8f-14f81ff6d65a": {"doc_hash": "3cd06d9706be8d117604d1543d048db6ac847ba82cc78cfa604d19ef194d839f"}, "cc48af09-46e0-49f4-b5c2-87ff02466785": {"doc_hash": "eb241f507c2dde2a45dbdafd0cc0cb7b342410625edfeed27fe211ef0b29e8bd"}, "53962387-3b3c-446b-ab21-cacf504125b9": {"doc_hash": "1a7e63f6261af5e185868672ae868db1fca2de25b682748f30ae09b69abb4ad1"}, "96e9b347-9800-47eb-9399-a007f8745435": {"doc_hash": "28d6242c15af974c9e7340ebb44fffe7095d0b3c036b8947ecf8cbbb2201e238"}, "3d2ed38b-83b4-463c-879d-4848c17b90ea": {"doc_hash": "1db4e3efc845aad285871a357c080b3606e2a8dbce1800e9a983b33981586006"}, "86157561-6dd2-4a14-9bf9-b8e8b375e3d7": {"doc_hash": "3e0cf9f85abdf1d6f5b938439af5ade12daa49bcfaa7ed522e1a32908227cfd0"}, "4e1c9e4b-560f-464c-b90d-d1075a93d7bd": {"doc_hash": "3dff0ae660a39feff1573f9922effcf16c50eeb79b404589a73bd52d96c472e3"}, "f65ae39d-cc22-4635-bafc-8e425f8d82df": {"doc_hash": "db73eb348311d82134814abdbf117feb9a8719687a8e4a6b20b6e898f0942d9e"}, "a72ef4a7-876d-4f9e-8bb5-451205468c25": {"doc_hash": "cfeecafd1736ec91e5d865a32872da6420cf0d76b5f6e4d66ab611e0840ff467"}, "f108b656-0942-4bdb-aa15-147e155bcabe": {"doc_hash": "dcf9dd34ae610fdc0cfcf6d86a74946d8ba643e4425c311b6533dd75f8fbd012"}, "9cf70eb0-ad15-4132-bd17-885ae901cac8": {"doc_hash": "097e4bcf7d8b13b84c860f3e7bdb3f9ef831e2d8b440e33f94e940c8675d23a3"}, "b524c727-3cf8-4da2-96d6-f6e24845ae2c": {"doc_hash": "ce332d0a85d2f9e6144da3f87854bcf8006241043ef092bb7a8c9dc596b17901"}, "bd593e76-48d0-4dd3-b561-00acf3774855": {"doc_hash": "2f70f13a55031125cedb8830ed220752db10050df52078c971cb77a259d2a4b2"}, "e1a6c8c7-cc88-4e8f-bb8c-243799aebc29": {"doc_hash": "88752cdcfce4591f22c6a82fd79e079c9cd1ea60443b70802e75b61daee6ff9e"}, "f3473ea0-1f2c-4e67-8efb-fdfc58dab74f": {"doc_hash": "b49313231efb9b1eab85742fd4879996c588d8f66abe026852c7ef85c4058904"}, "2c9b2e2a-f464-43f5-8c41-8f69c2f6033e": {"doc_hash": "cd3fe8cbe547f1f7075cb3f0b876de2ccb0ca06e199d331156dca13350fce092"}, "38467dda-af5e-44ec-b279-59183b7c27e1": {"doc_hash": "a9478112311dc22e2ed202e6122de6c9e09bbd7b2bbb863779313f2ad6c39d02"}, "d0c163a5-9633-44e2-a3f3-448fd7cf231e": {"doc_hash": "7802dc0f655e971ba86825db6b9873515301c44f650c302f422c34cc553f2c79"}, "b670af70-1630-4f47-a3bc-6dab9c2a37dd": {"doc_hash": "fa0b32c3d6112c6415e5fb5f6bb7c7078aa50134aa48f4f781ecf23419c7b299"}, "b46bee36-9570-442d-9993-fd84ea983d3d": {"doc_hash": "dd1ce3243b9b860e407bacd7d48d4611b6d884271677c92275517fcffe9507cd"}, "9ac93175-0006-4ce3-90d7-2507a4e86108": {"doc_hash": "a86689939adc1bd9a0a38f664164c8d7fc09812a222fc3a7b57b6fa66fa35587"}, "4059bd20-22f9-416f-afdc-298c74db92a7": {"doc_hash": "d9b10e6bba050b2ddd89942c46ac6e2002098c0f416b82f9a84a6a104acd88c5"}, "57f564f7-c3aa-4562-b2c4-e886a2dcdb53": {"doc_hash": "6201f0c75fc35a7ffd50c7cea624c186e4c66da5995461b9d169b807fdf6fd9a"}, "61fa05b9-975c-4b4b-9667-7e3489e10f9f": {"doc_hash": "75b2edcbe4317cd853824de73dc5c7444751257bce9d176fd0fc92b2cc9f006a"}, "19810c6a-0868-4938-ab54-f3b5cc53c9ce": {"doc_hash": "fd557cbe5ba07833de7287a3525df993e85477daaebdb4c895641ef89494080c"}, "d2641fbb-61a7-42a5-836a-171a1b20435f": {"doc_hash": "a0523de28d90a7f8ab02524756c161f31e172f1d4bd148a06f2f2ab19ef052d7"}, "cb5857cd-adf9-465f-945d-b7b30c423cb8": {"doc_hash": "c037684158751c528e889576efaec5113639fbdef5ce04835f2f3a8d6799d5a5"}, "51a81a72-5799-476e-b148-44c937a06617": {"doc_hash": "d34918f0c46dd2e88214df391cdee4006896cd73b0ae2c5142cb09f53e40b56c"}, "1fdd6e9a-5056-478f-b748-9ea0a81b8a10": {"doc_hash": "f9c90aabe1c507fb6b80f716c2ae822a3abeca1d3c17cf5385f557aaaef4f7ef"}, "fd442994-cc71-4b2a-a933-6d3865192a74": {"doc_hash": "58e6e54db37f16e3704fedba404a5e97d00a6c50944e075954d6c091774cdcf9"}, "77db2ca6-b087-4cab-93b3-6004dbe062ec": {"doc_hash": "e657c54399b6f392b31f4fc858cff8ee0088b0e8f521d10fc214d78403e54d80"}, "49ef36e9-1c50-4ae2-a637-6f1c4a417970": {"doc_hash": "e1c2e70fd6a31e4c3dafb706d8f5565cd6b22be5ef26e7fb12341668455aae01"}, "d6df3a02-605e-41f1-aa46-38afa2349f49": {"doc_hash": "fc9bea4e98a38fb4d2ac09770a304d306af608799c63567787374bba5622e9a0"}, "d975c688-3148-4d04-b3b5-0178dab9adae": {"doc_hash": "7226cb1a54a785b102c151dab4f292b215008fa57014756f94d6d1a1c6c59b64"}, "3cd81b77-ab85-41ec-9c79-9fb3cc86cf25": {"doc_hash": "1f979bc0903bbf3d19be9b5424ce542431757474277881ba2949af326d9960cc"}, "0ba565cf-c482-4ae1-a6be-fee70ec18d8c": {"doc_hash": "9a24a2ed3f3fd2a2c2adb6c615b8be8dc07cfaca30062bc19e3c713a73e9e427"}, "7536941f-493f-4b78-ac96-25be7855a2ea": {"doc_hash": "56b32b0417391c990c829c618b3b1a4dc62e3d499ba171d1398ac018720e61c2"}, "4ef6c73e-70af-45ee-a8a2-31a490be96b1": {"doc_hash": "a9a8bbdc294eb07b7ba70f7ee642a1eea8f8b3fc6158ce587ce851ccf572584c"}, "5bea2810-f0c6-491b-b964-19f7e7b957d3": {"doc_hash": "eff58b5617b567ea97e06b1bb7c05169584223491e37bbcca89674af38b680a9"}, "38b8056b-31ec-4341-96ea-6db2a7dc416d": {"doc_hash": "c623fa0568a85447f84ecf4a6258d3dfebad285232a0f8ad6685234ffa425668"}, "28476864-4b3c-413f-a4ee-17f7548f6b89": {"doc_hash": "12e4fb6dbab269d938841543b7a7a71fdc77f89da02fc8c4601563d17f3d80b3"}, "14373e0d-54df-47f1-9d27-d6a254e892d0": {"doc_hash": "eaa8eba7a74ea435a1e27dc2c1eaa5062f85afb64d885e637ac7ef4e121109f2"}, "3d292e04-cbda-4858-b780-680142b9eaaf": {"doc_hash": "3b8c54f03adab33f1eb3155209716301adfaaab8bed14c611bc3f0eb81c1022f"}, "b6fbf9e3-e0de-4ad9-8661-c11180333a14": {"doc_hash": "627a8eec6ba569a9907630290146d2fc9f190c618ef2319ee070fa2170b9eaf2"}, "f3614ed3-168c-45df-b901-22b8124df8dc": {"doc_hash": "3fa415d2c48bb1aeebfd9aab95d98d67ce4a001b223db7463a5ea032f9cca103"}, "2edf271d-390b-4239-bdd5-de22b330e740": {"doc_hash": "734ab57b0abd410939ef4e0d42c96770529b06ff2c5b668c0b00f3923457c75b"}, "696c522f-aa8d-441e-8028-8d7c4fd3d027": {"doc_hash": "51de4e46d3ecbee0dff6aa8f85dee638df573f1828bc1342d676cdd866a59251"}, "2b691166-614c-45cc-b393-2262e15ac663": {"doc_hash": "fa76ac2f17f6a5a2c55463cf391209619035747422638d893f9dcfd5af18a398"}, "1ae0dc55-e615-4680-8bb7-d21090f7c034": {"doc_hash": "1db4276b0353f3d0c5550d7606b71115c366f0c8bd80a833a9b873ca6e014c28"}, "ba9a7531-0686-4676-a7c1-2dc95cd32ab3": {"doc_hash": "f75c50c6b1e23c0d1bba2e95f401866ab9c1b5d56a8df5e556c62e3c6c5db6f3", "ref_doc_id": "5b82c9c8-2180-4e66-82e2-241b7c30ec93"}, "e0a67cd4-96c0-49e6-8772-13e5d7719ea1": {"doc_hash": "3598451f64e405a293c2a97d95734ad8898e536c241494ebad83be11969ee240", "ref_doc_id": "c5673611-25e2-41d9-9876-9af11e195cf5"}, "1104a174-6faf-4886-9066-da11f9dd4426": {"doc_hash": "2b86e99cd13f9e12f18842c19c46bea0e42202ae4a253022d04bc9213e3e5e50", "ref_doc_id": "53dcb9dd-469f-49cc-80eb-3206a877b2a0"}, "1621aff0-390d-49fd-8ea1-27bbd7e3ad69": {"doc_hash": "4f410056389307a04c31babb1885b5dec94a36073348d532b54df2e3153cd0f6", "ref_doc_id": "0dc195f2-5f50-4e4f-8d74-fbd2af902028"}, "ab7ef162-cc64-4fe3-828d-f15872a555fe": {"doc_hash": "ea0edfd539890a8c23b4c93cb49d3eaa1547b9cb2d2b389633ee0d875ece06a3", "ref_doc_id": "d79af461-1059-4e52-9556-4891affa01c8"}, "caaa9ccb-2128-4bfc-a889-546596efba36": {"doc_hash": "0d61855e649918a81c7c53bddce7ae8f01a6b8fb61ae86111b84e9b57ffadb64", "ref_doc_id": "eb1f3b57-90f3-49d0-972d-de767ce72e9a"}, "1120dfdf-84d3-45f1-af06-58aaf34db4d8": {"doc_hash": "e167c5123be1a4d7f17c73669e3628ec0272297b9f6b805902fbb9191197a4ab", "ref_doc_id": "c9a4642b-d62e-4ad6-b31d-0062a0ca3a4a"}, "67576b61-fe66-467a-99c4-67b0bf1d8fe7": {"doc_hash": "50558b68bc70409801e420b2497f468695d53270bd3bc7cb7b19999104e0b6bc", "ref_doc_id": "1fcf03cb-ecee-4d5e-b18a-d9ee72a327d0"}, "3343f310-aeb4-47e8-9dbb-eb8f3e685148": {"doc_hash": "5d042c70a36c3bedd3c02841edc7a04d8e5a975ed53ce872354f0ef0cb1e93e5", "ref_doc_id": "786a7d7a-0162-4682-b02b-531e5f4fc69f"}, "57335c00-85a2-4545-9bb3-86cb34df99d4": {"doc_hash": "463f90c31c2ae3fb808a538a30b4623a2173c415a629b77947aa55d87cb293fd", "ref_doc_id": "ea6b23f1-6fd5-4771-882d-3ea60524b2b1"}, "83312263-367a-4824-a734-bf0b4d77dc3d": {"doc_hash": "c384cafec0907f537cb09b33e706c0d8708fd79d5437de865133430e4f14efc5", "ref_doc_id": "db3e17d0-e3f4-4e60-8045-5a737f60f8a2"}, "8800b157-05d6-4a6d-bbce-5d308257cc03": {"doc_hash": "d03933c7630386b94f3a7abc43da489b593f3dcc4fc1458bf3a83c3d31a3f211", "ref_doc_id": "18d99bb5-3e1d-42f9-ba56-97d775b9be75"}, "86b50afc-a925-4111-9456-6a8f7b12989c": {"doc_hash": "806a3e238a24138b3b34e06b3c2c3d13f167b4aa2de457e8724437bfefaa3984", "ref_doc_id": "215fcb91-3729-4a8e-b0c6-fcb94d63c1f9"}, "0f6803b4-62f6-476a-a53a-f5be9db4202f": {"doc_hash": "dc39697b494210dc27de56be0ef60c6f3a1b4cd7965a3480af40b82e1eb64839", "ref_doc_id": "c0e152a5-e5de-469d-8296-e42e4c91ce06"}, "48ed0995-1268-4c5d-b607-bc625ab314d2": {"doc_hash": "7bc0044fb449b19f4bf10b2056e08ec2ab8580c620d31dd4b2b2c12e39ef9a27", "ref_doc_id": "b6dd1d79-b51e-4a4c-a10b-01042ab1231e"}, "88df517c-4cd4-4d2e-8d2a-cd6133369f83": {"doc_hash": "9378b0b3bd5fd8f7fb17273dabd2716c60ec728a48fa8d1aae037edebbcac9bd", "ref_doc_id": "b906dc53-6218-4965-bbee-11ff3773cbc3"}, "f21e204c-75fe-47ce-8d94-2f14e7937b18": {"doc_hash": "b4b82c91069f25ce5a3e4c6aa66bc3a33f4267d13a113558e2c9ac18a63b7bf2", "ref_doc_id": "6aefc6b9-dfc7-4145-8af6-d4cfe1d88b66"}, "6b01e2e3-1673-472e-b23e-23056336a225": {"doc_hash": "859a82fb40eb45ac0d0615c9a7e79d7d40a772ab83a87b4a091333954c1d5287", "ref_doc_id": "395eba3c-e464-4324-91b7-cf394d58ff01"}, "8bf1c777-9a47-43bf-bf10-60255d41a41e": {"doc_hash": "d238709830ea3778055d3c3d940521786770754ff46652fbd48116b62ac1da53", "ref_doc_id": "d9effd90-3af2-4a95-8ad0-0893de9c33d6"}, "d4917204-7877-4c05-897e-0508541366aa": {"doc_hash": "a12516585622db140bfe83020da03492ce11ae946feb5212fcc6d67860bb74dc", "ref_doc_id": "16350240-6b3d-4820-b90a-c8c4fd7914f7"}, "0b515d5b-25f7-4940-a6d4-10998acc2ad5": {"doc_hash": "b0ed1f02dd89fef02d6df88f6e9841b2d5f986ce351582e75692e2ede0b7ffb6", "ref_doc_id": "3b3c553c-e5d5-4856-911b-c7c534ff1862"}, "093f3a55-f88d-4700-a923-4cae145b83f4": {"doc_hash": "eb46bd4390b01073882965c3ff5296d6f8c97f14305bf693a6b80f89e3f9b116", "ref_doc_id": "97ba6cc2-d0ec-458e-bf08-51f1d6f6f23d"}, "9b6457bd-fc86-4c61-8602-f21dc0aa81f9": {"doc_hash": "b3e1168b7ccc237c0b86384bce05f5d7c6a7ce8e1907b33c68853872621e34ca", "ref_doc_id": "76299b89-621f-4bbf-93ad-30aebf63a51c"}, "3d04cc60-492c-4a76-8c69-fbf6547c080e": {"doc_hash": "e5e62b927be6b9752433586cbece97ed9dc2866a981b196b80c289c3d9735413", "ref_doc_id": "5c4bf2ac-c79b-4f64-930e-f6173e1ed4ca"}, "dcaf4562-9459-4354-b610-c84a8c793ff8": {"doc_hash": "18fb0accf5f9b95ca2101f2aabc83b49e654491c8f5b47fd61b637567b41503b", "ref_doc_id": "1e4eee52-55ec-4844-9b25-c1dbaf2dd1ec"}, "674a9836-0f12-4047-a408-4d4f0557d6b1": {"doc_hash": "9fe1ba9706ec7c25aa527a2a5ffa23df28b179e2756160a64fee729464b4fc4c", "ref_doc_id": "c56e98d0-04c6-4b38-9561-f61bcef455b6"}, "fbd5655e-c9d9-427a-868e-5a8b8da8d6d8": {"doc_hash": "3ac8a4fdc6168085b57fe23ba34e86a9a307cb31e3545c44bcbb788456263a97", "ref_doc_id": "93e29045-984c-482e-b950-eb3404307ee8"}, "4eb8d14d-142c-4448-912d-9894392b7d97": {"doc_hash": "884df8b36c34c44cb8ee33e85d958a3b595edbde97afc470caa4af8daed0b77c", "ref_doc_id": "35ca024e-0d5f-4a44-8c30-4da4a10bc5c9"}, "c8f8f369-e67b-40fd-9c8c-e3781dfcb187": {"doc_hash": "7ddfd8caccc6e71aed974b7d5c2ad7bcf978706dd087c29b5a0b2ae95d6c7351", "ref_doc_id": "d9c8293b-e05c-4d6f-85d2-d1a28989434b"}, "37911521-c008-4380-bbc4-3b87b4edf03f": {"doc_hash": "90583d88fc25eed97a18f1be31cc5740586286fdfe27ca0e6f95c8b73b5ed161", "ref_doc_id": "1e93e5ce-8803-4eba-a06a-475d4452b068"}, "51af44e6-3769-46b7-9d21-b00261c0a866": {"doc_hash": "81ab8ff0e6aef024c5fd45d1615d5e3aea16b137d3713fb8cbdf869528865dea", "ref_doc_id": "333ef42d-36fd-47a5-9ec1-69d996c5d8cb"}, "180651cb-4dcd-4d26-8fcb-32a2736ba755": {"doc_hash": "3a4c18081dba23a40bbdf472b1a6eaa5f400e4a4c131ab5e2f828bc66738729e", "ref_doc_id": "cd66a153-e7b6-4868-806c-9c0656c3397b"}, "4413de61-7dde-4956-9882-f2df64df1254": {"doc_hash": "a214e8a2c2fb065d72429fa825bcfeb24a5bd7edf31b147c5bd065b4af1a43ef", "ref_doc_id": "5cc245ff-6233-496b-bb08-15b535ae1ac8"}, "983f1bd7-b6e8-41b3-855b-4f1d0b3e6c7e": {"doc_hash": "9378b0b3bd5fd8f7fb17273dabd2716c60ec728a48fa8d1aae037edebbcac9bd", "ref_doc_id": "4403b0c6-b720-4cc4-a2c1-3257daa22cc6"}, "a9d4c944-0af5-4676-8bfa-467a05654765": {"doc_hash": "b4b82c91069f25ce5a3e4c6aa66bc3a33f4267d13a113558e2c9ac18a63b7bf2", "ref_doc_id": "44ad1a04-e735-4821-ad7a-c69bba1a9be1"}, "f1af9896-a273-4528-a77b-34cc3a58afc2": {"doc_hash": "f9d420d2476882dced17a7e2d49798bedef3cbea3cfe3315b52634decdd27f14", "ref_doc_id": "1b1e80ce-831e-4f58-84b5-d9d2ff22e57d"}, "ad31252d-fced-48ed-9396-87e1bdec871c": {"doc_hash": "be40792aceb07eed952f392ff48631e287ec7daef2d02de73612572a9765c66c", "ref_doc_id": "1b1e80ce-831e-4f58-84b5-d9d2ff22e57d"}, "d75cdc57-282b-4f5f-a685-45947f66feec": {"doc_hash": "115aa35dbd6142e18871fb155306f016fa12ef40adb0cb9d892c015f816dead0", "ref_doc_id": "5531282c-224e-4a4d-a57e-ab7e8088226d"}, "23b800d2-e7f7-45ac-bd2c-84ef31ccf428": {"doc_hash": "4fd273a6e4d6638f7cec3d3c19e4fada575a3f765ec962dc4cdf8275fd980fb2", "ref_doc_id": "c442f20d-9eea-4b17-807f-395b8ca4098f"}, "0cf396a0-1ad0-4fa4-be0a-d0d923279106": {"doc_hash": "460f0e295e758ecf0b9e80294ef5ad7ba5293688c31d4b8a96853c5a2b9333c2", "ref_doc_id": "fd28e723-a1f8-4a41-91ce-023a2b41de59"}, "dfd7af61-33c8-456c-8f3d-24c2125b9c90": {"doc_hash": "41196f8982bea541104d0f141d834895315cf3cb590256211c2261b7c5a697fb", "ref_doc_id": "e716c6ef-b39b-432a-afa0-48e3407dc6ae"}, "a8f25adb-05de-4ab5-8fba-a57b5ec6ffff": {"doc_hash": "2a6bcd07e63dc039286e7c70426dd6a4dc70e095bf42adda90c3dbfdff46cf4e", "ref_doc_id": "e716c6ef-b39b-432a-afa0-48e3407dc6ae"}, "edfddad1-fe34-42c5-96ac-f270e9e40cf8": {"doc_hash": "e2603834d56b123d5d8fd76d5c023c5c82695f33bc5b395c3fe6dfb87a39bce9", "ref_doc_id": "866a1ff1-100d-45c6-86d8-d4a7e7b78dfe"}, "dfbb728c-c6ce-4213-9ed2-8047eeb9a0ba": {"doc_hash": "7f78dc4ab066b46e8a72118f89fded1756a52f920a1b394abaf38439526e6fc4", "ref_doc_id": "2829ca34-f061-428d-abb9-0fd026b6a0d1"}, "80991f3e-b5a8-427f-b66c-a1081f86610c": {"doc_hash": "222fab13c2ed125f3e8708881f9a85d8f129ba71e687ff9c4a6084941451c414", "ref_doc_id": "ce2e6bbc-d494-443a-8484-2d26fafa5653"}, "eb564ce8-4238-4ab9-b47d-77398f6dd043": {"doc_hash": "289a7acb0e983019469936b85e27bcf6c6cef676cb56e66b15174a7d6ee41bd2", "ref_doc_id": "92bec081-db05-4090-83d1-9d0641d2db6a"}, "26aba237-a755-4768-841b-acfc6a55c184": {"doc_hash": "87969dcad03ae305349ed3c73e8f407abe21181c202bfbe0ba8014567cd3ff21", "ref_doc_id": "a0f8b6cf-6b44-4fd4-829f-cbd60e620347"}, "2368aa10-a50e-41c1-83b1-91e5dde747d3": {"doc_hash": "f6728a49e0a359d0ff24abc9d605eef4385e750cecf34667748b93fb2aeced65", "ref_doc_id": "79595773-0b28-409a-b62c-765f018efb84"}, "2959e80a-69a0-4111-9c58-965cfd11c15d": {"doc_hash": "7e19c8b205b79aedd2d9716d08ae268d7637e206cea3c224198dfe8ae8321a9e", "ref_doc_id": "52eab5c2-81f9-4ab3-81f1-1d99b984af5f"}, "2efeffe5-d122-43f5-a1f9-ce026399c4fe": {"doc_hash": "6c47d066a391ffb15b73fc4b8248772bfe65ccd75c8d4862b1dc7883abdc97e9", "ref_doc_id": "a9c5a44c-f72c-4e1d-b94d-c566a05da566"}, "916f9a74-313e-4cf9-8726-1c8942810111": {"doc_hash": "5bee8c661d3df8223d7ad815cf194957954d60d6950ed19ccf47ae614a742fda", "ref_doc_id": "b1490c59-64f6-40f4-9fd2-e059202e30c0"}, "fd15a747-02e9-4d22-8bdc-55b80542d621": {"doc_hash": "3a9c4a6a2636bdf2d849e8de09d57db9f1713200b7a6ae5a81cec457cac29aec", "ref_doc_id": "59751c52-fd4f-4cb5-8aef-62ed442d6dff"}, "b05a9cda-aee6-43b7-8d99-2c06eaa1391c": {"doc_hash": "94933431ed1b0f3ed2635548a937ee4d8a8c282f063557110f4a0474b6f9dd67", "ref_doc_id": "4c3eea78-409b-4958-81ae-21b705391912"}, "41a0db27-ea63-4bd0-8309-f681eccf4930": {"doc_hash": "506fbfdb955625a56799d015f2a76516e54046b67c3b09bf97b14f4876657e36", "ref_doc_id": "7fe19708-d622-44a4-9a7a-786aa51572a3"}, "ecb4a727-3ea5-47c2-9e59-58aad4ef5aaf": {"doc_hash": "01e9ca08e1141265df6bccce025d24ae6b39b7bb52fb23445c9c857428dd792f", "ref_doc_id": "f74d0530-7a58-4130-81b2-b77b6980b4ab"}, "6cbefecd-d8ae-488d-9154-499e72dd457b": {"doc_hash": "1cab24b6c8d4565dcd899d3b03c625508651a56660fe06d09e68439c2370e270", "ref_doc_id": "6af856a7-a11f-414f-8373-a30f3c41256f"}, "1394cf79-1097-4a0a-a125-866bf0cd6ff5": {"doc_hash": "a9206375b8988eb96b7bb9a025d67e0ad082a74d0b89e447614a2cdd18662882", "ref_doc_id": "08155926-75df-419b-9458-caf2c5ecc4b1"}, "d1dbeadf-2aa3-414a-97b3-d141f3b9c3b9": {"doc_hash": "a9a5a54b586deac2e3f4de96fecb83d6801be225db5bd1bf90d2c9c3da970fe5", "ref_doc_id": "1c716923-b0cc-4797-b227-8230b1fd6e3a"}, "e3f1f5a8-3155-4993-87c7-067fdfb085c5": {"doc_hash": "687bfe6c47e0f0c4d8a398bbe5de65e895c981bd7ac1e654b7868beb60367a4b", "ref_doc_id": "1c716923-b0cc-4797-b227-8230b1fd6e3a"}, "96f3f9bf-10de-47e9-8249-6fde48f9efed": {"doc_hash": "f45e88954a7e77d50e23cb2571a04b0366e82d6398116353316c98adeb7c6454", "ref_doc_id": "28f7d049-9981-48cf-84e2-795bf233cf37"}, "7b51c1c9-8766-4bcf-af8d-fc85716382f4": {"doc_hash": "b8531303cc8797d83da2064511d802558b11de309140f98791198731f928eb2f", "ref_doc_id": "7b197ddb-be91-4b3a-a59b-19cffb0b6342"}, "00247de5-53b9-4132-8cf1-1894520eea00": {"doc_hash": "47ab2481e4c96b3159b108a48444e6fa479edde6e0e83a7db8a40424292005bb", "ref_doc_id": "24982706-85ac-42c3-97ac-b4a8c6592e5d"}, "8d6f9167-7136-45fe-86ea-874654f8a1d8": {"doc_hash": "67d3bbeaa6cd79922908b88a6e2de83268e462fff8d881226fd02ca00442b064", "ref_doc_id": "3b4440f3-9ce7-4247-adc0-9b23087c575e"}, "d57fd3e2-50f8-4227-bd65-546f59efac42": {"doc_hash": "c4cc18e4537ee1313a0bd549df32bdfeaeea6cf5d8e5e5d2c308385b41e2f7e9", "ref_doc_id": "176eb101-e2ae-41b1-8a7b-450927351381"}, "f7439589-3c5b-41f2-bdcf-988d4a812554": {"doc_hash": "34891771b09d9f81a51ed7ebe997bf73cfcb93107431b2bf7e6164ce1b72087c", "ref_doc_id": "9d5e8ae6-6752-4f6a-8377-e72ad5638a9b"}, "f2221112-3449-44c6-bab6-aff75f7121e2": {"doc_hash": "dc8365fd5c1fa35f6f3d820dd028b1cb8617a56694fff78f533db74be5fe96b1", "ref_doc_id": "06260f5f-be7b-4e98-9fb3-4c99ea145024"}, "8f8f5849-db4a-42d2-a0b0-6bf40c3b728c": {"doc_hash": "bed800ed6d86becc1ab160d89b8dfa4c7fb1fe7d8426e67b8dc5caa5f2d38cce", "ref_doc_id": "7e21868e-ba9b-4380-a855-202521461f7f"}, "3decb7da-8680-4271-9404-d06f8b3147c6": {"doc_hash": "875d8a27359e69473f1ae3336dae6b488673e711cfbb3ec7636c8e567a4aaf82", "ref_doc_id": "be7eb8e5-f387-49e6-986c-690078e6b936"}, "6f354758-03bd-4f2c-9e7a-eca5fe771af9": {"doc_hash": "684de4861d32006a3fc3199027ee18a59904b1a01dfabb64faea8d39a9ccb269", "ref_doc_id": "aaf0c6f3-3762-4803-9d2c-0132320bbbe7"}, "5ee2bc36-14dc-48e6-8206-fa10b730ea42": {"doc_hash": "0c54f07d35809b7d65c39e1b73a3141a09216c6223a5ed642b59797772a3b05b", "ref_doc_id": "978d0625-cc07-4571-bfe3-0186b76ce3d9"}, "519ee882-f657-417f-8a6f-bd72b5f78e43": {"doc_hash": "1e9a10f538d3c13693825030b76ccb1b396ee03ce6a202d4ae36acea8dc7aa0b", "ref_doc_id": "1e938a27-90ae-4c2b-9c1a-07e6f872155a"}, "202f62ca-3ec0-4749-a3e0-73c17283baa5": {"doc_hash": "0c1d8147f0db56224b5872a9e1fc67afea27c029a568bc7aa5fa750f695b6a07", "ref_doc_id": "b7ffda72-c1af-4db3-9444-f6be67aa1cae"}, "07dc98ef-6c28-4888-96bb-1a4b79631956": {"doc_hash": "740e075166c8def0939fdfe1a1441e9704eb9c14699722efcc044edbbd26321e", "ref_doc_id": "705b6355-14b5-4f65-a675-8df3df6e5a93"}, "238ff9fe-dac6-4210-ab02-ea813497d3b6": {"doc_hash": "e93b1a5f63c0ee3b98062b4c91ad6cf60a1b6bac04462e5178303e946e444f32", "ref_doc_id": "8fa50a61-710c-4afd-8840-c3f3381797df"}, "2a4b99cc-c591-4ea2-b9e9-5a918f72e612": {"doc_hash": "790ec238b9f56ffe0e47a18de2d7ff8b67a1be4f162b552cbca263444db19d4a", "ref_doc_id": "24dd446e-eae0-42f8-9eda-28e3458bb578"}, "37bbecbc-d030-430a-99a3-4af1b0884727": {"doc_hash": "c06d2fbc73e616fde252bdbb062d49b2a784ce9a5224fc05714f6fe235146741", "ref_doc_id": "da610f06-05fe-46f6-bf63-22501ba7af0e"}, "c04489b6-4fdb-4da9-adbf-ddc0d06c2728": {"doc_hash": "0e84d038db07da5d1aea668797bc1485fa4ac4425665718b4e9f7632f501f0ec", "ref_doc_id": "0c0963c2-7f45-4042-888a-9480b7f17784"}, "c79b5fd6-c191-4690-8b2c-c726f518203d": {"doc_hash": "36c0706b56e154f5230ba39ec4d9f069293fe20cc55021376f7264d192ba1b36", "ref_doc_id": "4761dfb3-ae18-4e5c-852a-c3548477a115"}, "5bd6939c-819a-4493-af8d-68dd236485a3": {"doc_hash": "79decbcb8fe8d931f1866a84c611a10416e0b0e2a151ea7132e551abac805e73", "ref_doc_id": "5b70fabd-409d-4e3b-aa8f-14f81ff6d65a"}, "e0d7f6db-080c-4fe0-b843-9fa8d84b4b62": {"doc_hash": "071acdda846c6ba2c63b17d5e23864b08973e2495fdeda2c9c01722cdcc7128a", "ref_doc_id": "cc48af09-46e0-49f4-b5c2-87ff02466785"}, "894bde9d-eafe-44a8-9367-b3099157fbcb": {"doc_hash": "8140e527a96831295d71999867f5974980a430f8afd4ca5d7227822b5e19994a", "ref_doc_id": "53962387-3b3c-446b-ab21-cacf504125b9"}, "1f03a7b6-28ee-4fcd-982c-9a9422754a8c": {"doc_hash": "28b7027bf02dc46da86d027a2c3f38b9acaa1ce37f2aee617343e89f1bb7beeb", "ref_doc_id": "96e9b347-9800-47eb-9399-a007f8745435"}, "324cc595-857f-45ca-8360-4233190e025e": {"doc_hash": "928368eef6e0d7774e486f90ca82a9893665ff2c79269af096c3dad24e02ac1e", "ref_doc_id": "3d2ed38b-83b4-463c-879d-4848c17b90ea"}, "9476e54d-0429-4847-ab4c-b9c5ccf8a46e": {"doc_hash": "0467884e846a6b8a5ca5cfb8cfa873c31d214204a376391f35dac93b58f58b55", "ref_doc_id": "86157561-6dd2-4a14-9bf9-b8e8b375e3d7"}, "99bfb10e-ac7d-4e16-999b-164541594b80": {"doc_hash": "9b5be0eafb698dea57250fca3677f035da0cd22eb66414e3f8f9268e4fa65ab1", "ref_doc_id": "4e1c9e4b-560f-464c-b90d-d1075a93d7bd"}, "5b7ed734-84ff-4de2-9e39-02b5c164a55d": {"doc_hash": "5208a0d9bcd8d391c9c1194b5ddfe9888ac52c9edc528afa3fe142064c5ef39f", "ref_doc_id": "f65ae39d-cc22-4635-bafc-8e425f8d82df"}, "325f3751-529b-4fec-a588-9240fcc269e8": {"doc_hash": "c16f291827be0ed14cb6d31fe0a5001f7115395102bbd11d64d7e60f8638d141", "ref_doc_id": "a72ef4a7-876d-4f9e-8bb5-451205468c25"}, "03aa987c-e625-4aec-b25f-0857d9200065": {"doc_hash": "51e63fa097bf3f1a5501ff66ec57f1724895f3f68f9faebebd3984a6a37de0aa", "ref_doc_id": "f108b656-0942-4bdb-aa15-147e155bcabe"}, "dd9ae3d1-9ac1-488c-b824-1b32a32577ed": {"doc_hash": "b2097e96a6a7304775e8173790d3561d395758f908071e498a1b0f1ab01b8970", "ref_doc_id": "9cf70eb0-ad15-4132-bd17-885ae901cac8"}, "352067db-0ab3-4203-a0f8-a410b6a87035": {"doc_hash": "12d8946419e3bfc04cb4c6335e401460bd4c5e070bd08171fdd93cd7c0967c82", "ref_doc_id": "b524c727-3cf8-4da2-96d6-f6e24845ae2c"}, "ced33566-3104-449d-b02c-99184f97aeeb": {"doc_hash": "ab26a5d46808caac319254678dbc9329d5e93c0f4ee613b534e98288ae0a2a04", "ref_doc_id": "bd593e76-48d0-4dd3-b561-00acf3774855"}, "ccb540b8-d20b-4663-b141-995ac3bf2ecc": {"doc_hash": "b217ef2a9e8084a3478b831a8e5f5be9988368240db51499deb2c3dc6d1667a9", "ref_doc_id": "e1a6c8c7-cc88-4e8f-bb8c-243799aebc29"}, "55c176fd-634f-4495-8a72-161154af928e": {"doc_hash": "eea8fb6d41f5363ed2483b452106ff78284faab746cd58275a24f42abcaecaea", "ref_doc_id": "f3473ea0-1f2c-4e67-8efb-fdfc58dab74f"}, "663c29f8-ba22-4422-9906-22b39ea30d3e": {"doc_hash": "28832e19ffdd9c7eda2e12de6f83a3f2ee55621157400b9f592e3b021fb92580", "ref_doc_id": "2c9b2e2a-f464-43f5-8c41-8f69c2f6033e"}, "34aac729-477d-4c8d-b833-11b53bb44ca2": {"doc_hash": "d9d281084bc02563a7d7532090c37f6bd697ce8fc39654655f10aabf390662aa", "ref_doc_id": "38467dda-af5e-44ec-b279-59183b7c27e1"}, "05ddfff9-d2a5-4972-bba3-0837fda91359": {"doc_hash": "c754007fe04edae7d7085c4ccf1c16d437d9cf773d3f88f94e6684452da4ec9f", "ref_doc_id": "d0c163a5-9633-44e2-a3f3-448fd7cf231e"}, "8516a98f-dd9f-4b63-80fd-c2bd1a26ff9e": {"doc_hash": "218fc2f0ddc6e10ddabff81a944ca917f6d1f9979ea112dde113c2cd0c08a4b2", "ref_doc_id": "b670af70-1630-4f47-a3bc-6dab9c2a37dd"}, "86f26d9b-997a-4ac5-9ac4-18f4879e6538": {"doc_hash": "f21bc86a91fe6e484faab2f4c0cee6563177323d1d5a060e6fa6695e5328bb71", "ref_doc_id": "b46bee36-9570-442d-9993-fd84ea983d3d"}, "0ebde556-153e-40a3-977b-b2c29acdd741": {"doc_hash": "e7404b7b1a93cf8b939fc28e9fa795c88ecd95019686aee01f3bd413359c1136", "ref_doc_id": "9ac93175-0006-4ce3-90d7-2507a4e86108"}, "b993d1b0-3ff7-419e-9062-cdc8f03212de": {"doc_hash": "a84863118ffe0bbf05598e38d70ffef045f60f7c0a4cff7fcc6003771c1dd806", "ref_doc_id": "4059bd20-22f9-416f-afdc-298c74db92a7"}, "10d1d9c5-972f-4791-bacc-27cbd7d13bf0": {"doc_hash": "f8b27b6f8e4eef0af0dce3b70601ad1e42f31d2910dce71b95ae1cbf82ee3426", "ref_doc_id": "57f564f7-c3aa-4562-b2c4-e886a2dcdb53"}, "39009157-471d-48cd-a9b5-eaa31b5f6da2": {"doc_hash": "ccb33730cd6359c372dcc6e09fdfc5b5b948e1e5f729ec6a3eeed8202323baff", "ref_doc_id": "61fa05b9-975c-4b4b-9667-7e3489e10f9f"}, "aa2d68ef-16a9-46fd-8a27-2c9d9cbd9ca8": {"doc_hash": "c4b869ea7d7407cb04952fa5ff6abdbee34662d0e06b881a1f79e94ceda770f8", "ref_doc_id": "19810c6a-0868-4938-ab54-f3b5cc53c9ce"}, "954ff2a0-1196-42f1-983e-6efcdd5d7524": {"doc_hash": "faffd7a6f994952ba43371a96d1568a1df4cd3736e697878c165b2d9449db54f", "ref_doc_id": "d2641fbb-61a7-42a5-836a-171a1b20435f"}, "a0867702-90de-4456-9599-a95f45e14a5a": {"doc_hash": "5d83386ff7970ce55b55045d63bba809d29301c0cfa683da1423081e8b47b523", "ref_doc_id": "cb5857cd-adf9-465f-945d-b7b30c423cb8"}, "ff1d4027-9bf3-4f0d-ab35-23519d1a6d02": {"doc_hash": "195bab2a7ea87ae4d7f396e4f61c8a875f26667702248622f117a9c9f760ce19", "ref_doc_id": "51a81a72-5799-476e-b148-44c937a06617"}, "468749e8-6f0d-4163-b757-b73cc4c4d015": {"doc_hash": "45b3ccdb4e09f2414aedb38277ef398d0f7298126f16b51b130577a378648853", "ref_doc_id": "1fdd6e9a-5056-478f-b748-9ea0a81b8a10"}, "c1f85d04-22fd-4ba1-8aba-a6b59f6c83bf": {"doc_hash": "15d68bf724381b4be87d74b2dd9ed1925f215172ed167335153de727a20861e8", "ref_doc_id": "fd442994-cc71-4b2a-a933-6d3865192a74"}, "a7903ec9-eeff-4e56-8ee4-4f91c7fe78ab": {"doc_hash": "b83d53d49066b28cc7e77b7e8b59215790b2a4241cd74682ba201a95e483f622", "ref_doc_id": "77db2ca6-b087-4cab-93b3-6004dbe062ec"}, "7eef4428-ca99-44e4-aecb-546a397e51a5": {"doc_hash": "2efe225a4bcfd2b4e630f6f018d19c4c542d451345e2395eb05d0110d68b1586", "ref_doc_id": "49ef36e9-1c50-4ae2-a637-6f1c4a417970"}, "8eebda44-6dd5-4a4f-9a23-43113ad2e27d": {"doc_hash": "d797f3930c80317f26b7f4f07b8d2ba82da846b238d7a276c21003c3e9c7e4a0", "ref_doc_id": "d6df3a02-605e-41f1-aa46-38afa2349f49"}, "99a7825e-5144-4be4-908c-df1c76b96807": {"doc_hash": "a2d1033a0f003daa3e67d1a94661c44830a6e9f353a5318ee701ddb65ca23e6f", "ref_doc_id": "d975c688-3148-4d04-b3b5-0178dab9adae"}, "7698812d-4bd2-45f8-82fd-1212f7597c4f": {"doc_hash": "ad7b36579c95a8842f4a665945eafa84786ec7189edc831bde7d28649181ffc2", "ref_doc_id": "3cd81b77-ab85-41ec-9c79-9fb3cc86cf25"}, "5f1094d6-90d6-49c7-8484-e15b969db0b3": {"doc_hash": "595dacd9212f22e67518e6a937def4a48fdb1dcb1c62f6a655bf912155be9596", "ref_doc_id": "0ba565cf-c482-4ae1-a6be-fee70ec18d8c"}, "2ffc7478-010d-486e-acd0-c3e3ba904b5c": {"doc_hash": "a4671d8849d9c7fd4e6ba35c98a2da4e185dc90162b1ce458cb3b47eeb5eb108", "ref_doc_id": "7536941f-493f-4b78-ac96-25be7855a2ea"}, "70311f0c-16e4-4954-91dc-ba07d364b7ba": {"doc_hash": "8596e7cf537395f86b9ae6ebd702b9ace0655cd7840ac470049684626202ede9", "ref_doc_id": "4ef6c73e-70af-45ee-a8a2-31a490be96b1"}, "42963d8c-7fff-4167-81cc-8228376ba834": {"doc_hash": "d82d91a5a101c96c909bffee5b677e944f82302cfe3961c8cac35e779f215ae9", "ref_doc_id": "5bea2810-f0c6-491b-b964-19f7e7b957d3"}, "ec13c61f-3b7b-4921-a8eb-1a61701032f6": {"doc_hash": "bc87671abeb07edb1f3ec49f5d7739110d75d30441d6fdae3fae1fff5f60c218", "ref_doc_id": "38b8056b-31ec-4341-96ea-6db2a7dc416d"}, "5024ec2f-74a6-4f64-b58e-145a3e04e498": {"doc_hash": "9355619cc9b8df7cca7dbbb89a616a3c8979ec1487f3223aa0ba65a6f7b4a371", "ref_doc_id": "28476864-4b3c-413f-a4ee-17f7548f6b89"}, "67955a37-8c5f-4ad8-b2a5-66acddde4c08": {"doc_hash": "2936f8fad8dd0737ba940d9342329a50b92e24657c95ce93a6d7293e72a155b0", "ref_doc_id": "14373e0d-54df-47f1-9d27-d6a254e892d0"}, "ff15c8b5-c807-4d24-8956-9de59c1f5c51": {"doc_hash": "89a8e4addc821be7893c030689ed73821b7ed390ba57c84bfc112afe50a56f54", "ref_doc_id": "3d292e04-cbda-4858-b780-680142b9eaaf"}, "8e496376-68f7-456a-8581-423ed7841e33": {"doc_hash": "0ebe1ceb9babeed0a039ed076d710aa493a401bc0f929055e0971c1928223e50", "ref_doc_id": "b6fbf9e3-e0de-4ad9-8661-c11180333a14"}, "b9e6104d-dd33-49e2-b83b-de85439a33f2": {"doc_hash": "f7517c687a14dfaf920cd2ac36360142b963dd278122014ac1da939715fa598d", "ref_doc_id": "f3614ed3-168c-45df-b901-22b8124df8dc"}, "728dd98c-f5fb-4b88-95a7-8bc9bf2ca3b6": {"doc_hash": "1426148b487e0a59db7c6aaa05b0607f8d5037594107e3061f92537f36732649", "ref_doc_id": "2edf271d-390b-4239-bdd5-de22b330e740"}, "a5a7c01a-96eb-44b0-a364-0e899d1e8fba": {"doc_hash": "677fd07b0dfbcf119aaacc5a392204c3c3d36ac29fd6dbd1097e8c455a6325eb", "ref_doc_id": "696c522f-aa8d-441e-8028-8d7c4fd3d027"}, "400b13c0-f99d-4d35-bbef-35b807682d21": {"doc_hash": "aa2bfd11813cf2ff5790289d26ad4cd3e1dc469cd4e7ac6bac065eca5fb22ff9", "ref_doc_id": "2b691166-614c-45cc-b393-2262e15ac663"}, "f044ad57-dca6-43d8-9517-bb331d26a64b": {"doc_hash": "d7ff2b183c520e217d2c06d94ff7ae8674b6388a95332d45a431ad5360de1084", "ref_doc_id": "1ae0dc55-e615-4680-8bb7-d21090f7c034"}}, "docstore/data": {"ba9a7531-0686-4676-a7c1-2dc95cd32ab3": {"__data__": {"id_": "ba9a7531-0686-4676-a7c1-2dc95cd32ab3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5b82c9c8-2180-4e66-82e2-241b7c30ec93", "node_type": null, "metadata": {}, "hash": "9c3fe7ea69f3c85341c1b6378c01a9b67063dc32436fb1754bea592e61204f4c"}}, "hash": "f75c50c6b1e23c0d1bba2e95f401866ab9c1b5d56a8df5e556c62e3c6c5db6f3", "text": "\ud83d\udc4b Welcome to Portkey!\n\nPortkey is a comprehensive, ambitious, and innovative solution designed to facilitate the seamless deployment of Generative AI applications.&#x20;\n\nIt serves as a robust platform for launching production-ready applications using the cutting-edge LMOps stack. This sophisticated technology stack includes crucial components for monitoring, model management, and various other features to enhance and optimize your AI application's performance.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e0a67cd4-96c0-49e6-8772-13e5d7719ea1": {"__data__": {"id_": "e0a67cd4-96c0-49e6-8772-13e5d7719ea1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c5673611-25e2-41d9-9876-9af11e195cf5", "node_type": null, "metadata": {}, "hash": "b631a67f97299d2ebe112fe018d9cff8b48e36b22681fb576b29f57f47a6891a"}}, "hash": "3598451f64e405a293c2a97d95734ad8898e536c241494ebad83be11969ee240", "text": "Quick links\n\n{% content-ref url=\"overview/introduction.md\" %}\nintroduction.md\n{% endcontent-ref %}\n\n{% content-ref url=\"overview/features-overview.md\" %}\nfeatures-overview.md\n{% endcontent-ref %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1104a174-6faf-4886-9066-da11f9dd4426": {"__data__": {"id_": "1104a174-6faf-4886-9066-da11f9dd4426", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "53dcb9dd-469f-49cc-80eb-3206a877b2a0", "node_type": null, "metadata": {}, "hash": "76b587e877ce9d2f7ee8a418a4fb3d0f9817d90be1af24bddbad2ad26eceb4d3"}}, "hash": "2b86e99cd13f9e12f18842c19c46bea0e42202ae4a253022d04bc9213e3e5e50", "text": "Table of contents\n\n* \ud83d\udc4b Welcome to Portkey!", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1621aff0-390d-49fd-8ea1-27bbd7e3ad69": {"__data__": {"id_": "1621aff0-390d-49fd-8ea1-27bbd7e3ad69", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0dc195f2-5f50-4e4f-8d74-fbd2af902028", "node_type": null, "metadata": {}, "hash": "761f8ce0cb8eb9ba64285469d48c5fb284949c76c850a42c2ca930a9537c2a4a"}}, "hash": "4f410056389307a04c31babb1885b5dec94a36073348d532b54df2e3153cd0f6", "text": "Overview\n\n* \u2139 Introduction\n* \u2728 Features Overview", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ab7ef162-cc64-4fe3-828d-f15872a555fe": {"__data__": {"id_": "ab7ef162-cc64-4fe3-828d-f15872a555fe", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d79af461-1059-4e52-9556-4891affa01c8", "node_type": null, "metadata": {}, "hash": "6d9df816311071ef43c0c673d65b923d685e3d1fff63dee3c721d9af59443757"}}, "hash": "ea0edfd539890a8c23b4c93cb49d3eaa1547b9cb2d2b389633ee0d875ece06a3", "text": "Getting Started\n\n* \ud83d\udcea Setup Your Account\n* \ud83d\udcce Quick Integration", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "caaa9ccb-2128-4bfc-a889-546596efba36": {"__data__": {"id_": "caaa9ccb-2128-4bfc-a889-546596efba36", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "eb1f3b57-90f3-49d0-972d-de767ce72e9a", "node_type": null, "metadata": {}, "hash": "9d122fb7d1a23c0b0c927bb9d3466908e3aff5c8919ba53d90d21ef3b37482cd"}}, "hash": "0d61855e649918a81c7c53bddce7ae8f01a6b8fb61ae86111b84e9b57ffadb64", "text": "How Portkey Works\n\n* \ud83d\udcea Portkey Modes\n* \ud83d\udcce Portkey Headers\n* \ud83c\udf08 Supported LLMs", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1120dfdf-84d3-45f1-af06-58aaf34db4d8": {"__data__": {"id_": "1120dfdf-84d3-45f1-af06-58aaf34db4d8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c9a4642b-d62e-4ad6-b31d-0062a0ca3a4a", "node_type": null, "metadata": {}, "hash": "770189f91c5c4f49e6ec23bc1e7a5b243272f4a401728709e218bc824d5b1045"}}, "hash": "e167c5123be1a4d7f17c73669e3628ec0272297b9f6b805902fbb9191197a4ab", "text": "Key Features\n\n* \ud83d\ude80 Request Caching\n* \u23ee Request Tracing\n* \ud83d\udcab Automatic Retries\n* \ud83d\udcc3 Custom Metadata\n* \ud83e\udd16 Fallbacks on LLMs\n* \ud83e\ude9d Load Balancing\n* \ud83d\udcdd Feedback API\n* \ud83d\udcca Logs & Analytics\n* \ud83d\udd11 AI Provider Keys\n* \u26a1 Prompt Management\n  * Few-Shot Prompting", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "67576b61-fe66-467a-99c4-67b0bf1d8fe7": {"__data__": {"id_": "67576b61-fe66-467a-99c4-67b0bf1d8fe7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1fcf03cb-ecee-4d5e-b18a-d9ee72a327d0", "node_type": null, "metadata": {}, "hash": "24289008825ce08b7658534bac1b79fddf2af4bccb7f66b00cf598b6b372aeb7"}}, "hash": "50558b68bc70409801e420b2497f468695d53270bd3bc7cb7b19999104e0b6bc", "text": "Integration Guides\n\n* \u27a1 Open AI SDK\n* \u27a1 Langchain\n* \u27a1 Cohere\n* \u27a1 Anthropic SDK\n* \u27a1 Microsoft Guidance\n* \u27a1 Rest API", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3343f310-aeb4-47e8-9dbb-eb8f3e685148": {"__data__": {"id_": "3343f310-aeb4-47e8-9dbb-eb8f3e685148", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "786a7d7a-0162-4682-b02b-531e5f4fc69f", "node_type": null, "metadata": {}, "hash": "ec4cb1f7d06bdd8d591fed3c07ccd7675eb5719372fa92a9ba4b3348f45afbf9"}}, "hash": "5d042c70a36c3bedd3c02841edc7a04d8e5a975ed53ce872354f0ef0cb1e93e5", "text": "Why Portkey\n\n* \ud83d\udc40 Observability\n* \ud83c\udfad Lower Cost & Latency\n* \u26c5 Improve LLM success rate\n* \u2705 Optimise generation quality\n* \ud83d\udeab Hide PII from LLMs", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "57335c00-85a2-4545-9bb3-86cb34df99d4": {"__data__": {"id_": "57335c00-85a2-4545-9bb3-86cb34df99d4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ea6b23f1-6fd5-4771-882d-3ea60524b2b1", "node_type": null, "metadata": {}, "hash": "0ae1ba583f78b6f2aa6593a266c0778208097fa9f158eb7991396a3d8ebe05fd"}}, "hash": "463f90c31c2ae3fb808a538a30b4623a2173c415a629b77947aa55d87cb293fd", "text": "Troubleshooting & Support\n\n* \u2049 Common Errors and Resolutions\n* \ud83d\udce5 Reporting Issues\n* \ud83d\udce7 Contacting Support", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "83312263-367a-4824-a734-bf0b4d77dc3d": {"__data__": {"id_": "83312263-367a-4824-a734-bf0b4d77dc3d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "db3e17d0-e3f4-4e60-8045-5a737f60f8a2", "node_type": null, "metadata": {}, "hash": "1e9fbd5c5b5e3f004dc9a37ac4af7f8f8920a1b5ce690a5f7345245b1d4e3589"}}, "hash": "c384cafec0907f537cb09b33e706c0d8708fd79d5437de865133430e4f14efc5", "text": "\ud83d\udcce Quick Integration\n\nYou can integrate Portkey to your LLM provider via REST APIs, the provider's SDKs and even via Langchain. We'll take an example of an OpenAI request, and show you how to route it through Portkey using different methods. (Click here for integration examples with other providers like Anthropic, Cohere etc.)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8800b157-05d6-4a6d-bbce-5d308257cc03": {"__data__": {"id_": "8800b157-05d6-4a6d-bbce-5d308257cc03", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "18d99bb5-3e1d-42f9-ba56-97d775b9be75", "node_type": null, "metadata": {}, "hash": "951b5ea15bb0150dd07ec79a9c0ccb5a8889d812ed0fa54ee4334ad12d6129da"}}, "hash": "d03933c7630386b94f3a7abc43da489b593f3dcc4fc1458bf3a83c3d31a3f211", "text": "**Rest API**\n\n{% tabs %}\n{% tab title=\"cURL - Chat Completion\" %}\n```powershell\ncurl --location 'https://api.portkey.ai/v1/complete' \\\n    --header 'x-portkey-api-key: PORTKEY_API_KEY' \\\n    --header 'Content-Type: application/json' \\\n    --data '{ \n        \"config\": { \n            provider: \"openai\",\n            apiKey: \"OPENAI_API_KEY\", # Needs apiKey or providerKey\n            providerKey: \"PROVIDER_KEY\"\n        }, \n        \"params\": {\n            \"messages\": [{\"role\": \"user\",\"content\":\"What are the ten tallest buildings in India?\"}],\n            \"max_tokens\": 100,\n            \"user\": \"jbu3470\",\n            \"model\": \"gpt-3.5-turbo\"\n        }\n    }'\n```\n{% endtab %}\n\n{% tab title=\"cURL - Completion\" %}\n{% code overflow=\"wrap\" %}\n```powershell\ncurl --location 'https://api.portkey.ai/v1/complete' \\\n    --header 'x-portkey-api-key: PORTKEY_API_KEY' \\\n    --header 'Content-Type: application/json' \\\n    --data '{ \n        \"config\": { \n            provider: \"openai\",\n            apiKey: \"OPENAI_API_KEY\", # Needs apiKey or providerKey\n            providerKey: \"PROVIDER_KEY\"\n        }, \n        \"params\": { \n            \"prompt\": \"What are the top 10 tallest buildings in Bhutan?\",                 \n            \"max_tokens\": 50, \n            \"model\": \"text-davinci-003\", \n            \"user\": \"jbu749\" \n        } \n    }'\n```\n{% endcode %}\n{% endtab %}\n\n{% tab title=\"curl - Proxy\" %}\n```powershell\ncurl --location 'http://api.portkey.ai/v1/proxy/completions' \\\n    --header 'x-portkey-api-key: ' \\\n    --header 'x-portkey-mode: proxy openai' \\\n    --header 'Authorization: ' \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"n\": 1,\n        \"model\": \"text-davinci-003\",\n        \"prompt\": \"Top 20 tallest buildings in the world\"\n    }'\n```\n{% endtab %}\n{% endtabs %}\n\nIn the above cURL requests replace&#x20;\n\n1. `PORTKEY_API_KEY` with Portkey's API Key (Found in your account dashboard)\n2. `OPENAI_API_KEY` with your OpenAI API key (Optional, not recommended)\n3. `PROVIDER_KEY` with the AI provider's key created through Portkey (Optional, recommended)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "86b50afc-a925-4111-9456-6a8f7b12989c": {"__data__": {"id_": "86b50afc-a925-4111-9456-6a8f7b12989c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "215fcb91-3729-4a8e-b0c6-fcb94d63c1f9", "node_type": null, "metadata": {}, "hash": "70ee743701db2d2c125a6aaffadba4498a8e7735cbde2f073d6c80f65fec4126"}}, "hash": "806a3e238a24138b3b34e06b3c2c3d13f167b4aa2de457e8724437bfefaa3984", "text": "**OpenAI SDK**\n\n{% tabs %}\n{% tab title=\"Python\" %}\nimport openai", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0f6803b4-62f6-476a-a53a-f5be9db4202f": {"__data__": {"id_": "0f6803b4-62f6-476a-a53a-f5be9db4202f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c0e152a5-e5de-469d-8296-e42e4c91ce06", "node_type": null, "metadata": {}, "hash": "8c690bb42a26dccbd08fee8dc46646be3bda7b3118c24e29208e9b790ee558a9"}}, "hash": "dc39697b494210dc27de56be0ef60c6f3a1b4cd7965a3480af40b82e1eb64839", "text": "Set Portkey as the base path\nopenai.api_base = \"https://api.portkey.ai/v1/proxy\"\n\nresponse = openai.Completion.create(\n  model=\"text-davinci-003\",\n  prompt=\"Translate the following English text to French: '{}'\",\n  temperature=0.5,\n  headers={\n    \"x-portkey-api-key\": \"&#x3C;PORTKEY_API_KEY>\",\n    \"x-portkey-mode\": \"proxy openai\"\n  }\n)\n\nprint(response.choices[0].text.strip())\n\n{% endtab %}\n\n{% tab title=\"NodeJS\" %}\n```javascript\nconst { Configuration, OpenAIApi } = require(\"openai\");\nconst configuration = new Configuration({\n  apiKey: \"\",\n  basePath: \"https://api.portkey.ai/v1/proxy\",\n    baseOptions: {\n      headers: {\n        \"x-portkey-api-key\": \"\",\n        \"x-portkey-mode\": \"proxy openai\"\n      }\n    }\n});\n\nconst openai = new OpenAIApi(configuration);\n\nasync function generateCompletion() {\n  const response = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt: \"Two roads diverged in the yellow woods\",\n    max_tokens: 512,\n    temperature: 0,\n  });\n\n  console.log(response.data.choices[0].text);\n}\n\ngenerateCompletion();\n```\n{% endtab %}\n{% endtabs %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "48ed0995-1268-4c5d-b607-bc625ab314d2": {"__data__": {"id_": "48ed0995-1268-4c5d-b607-bc625ab314d2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b6dd1d79-b51e-4a4c-a10b-01042ab1231e", "node_type": null, "metadata": {}, "hash": "8e790e397a42292ff9a476edc6837e421476260e0ba0ee490376049169f3c6c2"}}, "hash": "7bc0044fb449b19f4bf10b2056e08ec2ab8580c620d31dd4b2b2c12e39ef9a27", "text": "**Langchain**\n\n{% tabs %}\n{% tab title=\"Python\" %}\n```python\nimport os\nfrom langchain.llms import OpenAI\nfrom langchain.utilities import Portkey\n\nos.environ[\"OPENAI_API_KEY\"] = \"\"\nPORTKEY_API_KEY = \"\" # Set Portkey API key here\nTRACE_ID = \"portkey_langchain_demo\"  # Set trace id here", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "88df517c-4cd4-4d2e-8d2a-cd6133369f83": {"__data__": {"id_": "88df517c-4cd4-4d2e-8d2a-cd6133369f83", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b906dc53-6218-4965-bbee-11ff3773cbc3", "node_type": null, "metadata": {}, "hash": "4b6f0381517ca1b91fe78f8c3e948711a74236bcbd3d4fa93040efd5de6b4b48"}}, "hash": "9378b0b3bd5fd8f7fb17273dabd2716c60ec728a48fa8d1aae037edebbcac9bd", "text": "Since Portkey is integrated with Langchain, Portkey.Config() takes care of defining headers\n\nheaders = Portkey.Config(\n    api_key=PORTKEY_API_KEY,\n    trace_id=TRACE_ID,\n)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f21e204c-75fe-47ce-8d94-2f14e7937b18": {"__data__": {"id_": "f21e204c-75fe-47ce-8d94-2f14e7937b18", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6aefc6b9-dfc7-4145-8af6-d4cfe1d88b66", "node_type": null, "metadata": {}, "hash": "dcb54571ff57041e6afefd05d9fbaa5d4a1d3ba695b6c5c47d15ef253cc70680"}}, "hash": "b4b82c91069f25ce5a3e4c6aa66bc3a33f4267d13a113558e2c9ac18a63b7bf2", "text": "Now, let's pass these headers\n\nllm = OpenAI(headers=headers)\n\ntools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\nagent = initialize_agent(\n    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6b01e2e3-1673-472e-b23e-23056336a225": {"__data__": {"id_": "6b01e2e3-1673-472e-b23e-23056336a225", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "395eba3c-e464-4324-91b7-cf394d58ff01", "node_type": null, "metadata": {}, "hash": "8b84967c6fecc833800280d65580ba58e703a0f08ac5b0157fe0fe3f46efa0ad"}}, "hash": "859a82fb40eb45ac0d0615c9a7e79d7d40a772ab83a87b4a091333954c1d5287", "text": "Let's test it out!\nagent.run(\n    \"What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\"\n)\n```\n{% endtab %}\n\n{% tab title=\"NodeJS\" %}\n```typescript\nimport { OpenAI } from \"langchain/llms/openai\";\n\nconst model = new OpenAI({\n  modelName: \"text-davinci-003\", \n  temperature: 0.9,\n  openAIApiKey: \"\",\n  configuration: {\n    basePath: \"https://api.portkey.ai/v1/proxy\",\n    baseOptions: {\n      headers: {\n        'x-portkey-api-key': '',\n        'x-portkey-mode': 'proxy openai',\n        'x-portkey-trace-id' : 'langchain_demo'\n      }\n    }\n  }\n});\n\nasync function main() {\n  const res = await model.call(\"Describe the world as written by Herodotus.\");\n  console.log(res);\n}\nmain();\n```\n{% endtab %}\n{% endtabs %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8bf1c777-9a47-43bf-bf10-60255d41a41e": {"__data__": {"id_": "8bf1c777-9a47-43bf-bf10-60255d41a41e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d9effd90-3af2-4a95-8ad0-0893de9c33d6", "node_type": null, "metadata": {}, "hash": "7a7201b6e12ffd4a663e1a22ca29838b41cea1bf1625aeafcf5c097a1299a406"}}, "hash": "d238709830ea3778055d3c3d940521786770754ff46652fbd48116b62ac1da53", "text": "\ud83d\udcea Setup Your Account\n\nGetting Started\n\nWelcome to Portkey! This guide will walk you through the steps to create your account, retrieve your API key, and perform a quick integration using Middleware Mode.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d4917204-7877-4c05-897e-0508541366aa": {"__data__": {"id_": "d4917204-7877-4c05-897e-0508541366aa", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "16350240-6b3d-4820-b90a-c8c4fd7914f7", "node_type": null, "metadata": {}, "hash": "6e98153abc046bbc36685c494d95130e764957915c9d9fcaba51290f5b99fb1e"}}, "hash": "a12516585622db140bfe83020da03492ce11ae946feb5212fcc6d67860bb74dc", "text": "Setup Your Account\n\nCreating your account on Portkey is easy:\n\n1. Visit app.portkey.ai\n2. Click on \"Sign Up\"\n3. Follow the sign-up flow to create your account", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0b515d5b-25f7-4940-a6d4-10998acc2ad5": {"__data__": {"id_": "0b515d5b-25f7-4940-a6d4-10998acc2ad5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3b3c553c-e5d5-4856-911b-c7c534ff1862", "node_type": null, "metadata": {}, "hash": "be838ad06135c9f04c99420f6fce7b11b59bd93d2affa4839f35780192b13799"}}, "hash": "b0ed1f02dd89fef02d6df88f6e9841b2d5f986ce351582e75692e2ede0b7ffb6", "text": "Retrieve Your API Key\n\nTo interact with Portkey's API, you'll need your unique API key. Here's how you get it:\n\n1. Click on your profile icon on the top left\n2. From the dropdown menu, click on \"Copy API Key\"\n\nYour API key should now be copied to your clipboard.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "093f3a55-f88d-4700-a923-4cae145b83f4": {"__data__": {"id_": "093f3a55-f88d-4700-a923-4cae145b83f4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "97ba6cc2-d0ec-458e-bf08-51f1d6f6f23d", "node_type": null, "metadata": {}, "hash": "18288d4b615cb0a5957bacfb5bd54bfc0535199af32a899f147bd0e527afcf96"}}, "hash": "eb46bd4390b01073882965c3ff5296d6f8c97f14305bf693a6b80f89e3f9b116", "text": "\ud83d\udcce Portkey Headers\n\nPortkey uses request headers to enable, disable, or configure various features at the request level. These headers give you granular control over your interaction with Portkey's API, allowing you to tailor the behavior of specific requests to fit your needs.\n\nAll Portkey-specific headers begin with the prefix `x-portkey-`.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9b6457bd-fc86-4c61-8602-f21dc0aa81f9": {"__data__": {"id_": "9b6457bd-fc86-4c61-8602-f21dc0aa81f9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "76299b89-621f-4bbf-93ad-30aebf63a51c", "node_type": null, "metadata": {}, "hash": "e7c2090cb4a02095c6941ad3b14a6a3551c237bb6f0900be087b96a8e9f90260"}}, "hash": "b3e1168b7ccc237c0b86384bce05f5d7c6a7ce8e1907b33c68853872621e34ca", "text": "Headers Overview\n\nPortkey headers are part of the HTTP request sent to Portkey's API. They are used to pass additional information with the HTTP request or response. Portkey-specific headers provide directives to control various Portkey features and are prefixed with `x-portkey-`.\n\nHere's an example of how headers can be used to configure a feature - enabling automatic retries:\n\n```python\ncodeheaders = {\n    \"x-portkey-api-key\": \"\",\n    \"x-portkey-retry-count\" : \"4\"\n}\n\nresponse = requests.post('https://api.portkey.ai/v1/models', headers=headers, data=payload)\n```\n\nIn this example, if the request fails due to an LLM error, Portkey will automatically retry the request up to four times before returning an error.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3d04cc60-492c-4a76-8c69-fbf6547c080e": {"__data__": {"id_": "3d04cc60-492c-4a76-8c69-fbf6547c080e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5c4bf2ac-c79b-4f64-930e-f6173e1ed4ca", "node_type": null, "metadata": {}, "hash": "ee72a5b96a7cd656684f9dac93371e34cc8907bbb4027ed0214e02ff73632816"}}, "hash": "e5e62b927be6b9752433586cbece97ed9dc2866a981b196b80c289c3d9735413", "text": "Mandatory Headers\n\nThe only mandatory header is `x-portkey-api-key`. Without this header all requests would return with 401 error.\n\nIf you're using Middleware mode, `x-portkey-mode` header with the appropriate value is required. To understand the value of mode, please refer to the integration guides.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "dcaf4562-9459-4354-b610-c84a8c793ff8": {"__data__": {"id_": "dcaf4562-9459-4354-b610-c84a8c793ff8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1e4eee52-55ec-4844-9b25-c1dbaf2dd1ec", "node_type": null, "metadata": {}, "hash": "8d1c7fb0c14f4c7f91b9b3bc7c22a4121a3cac682bd17bd7ecbaf16bd1cbe9d9"}}, "hash": "18fb0accf5f9b95ca2101f2aabc83b49e654491c8f5b47fd61b637567b41503b", "text": "Further Reading\n\nEach feature documentation provides specific details on the headers associated with the feature and how to use them to configure the behavior of the feature.\n\nRemember, incorrect usage of headers could lead to unexpected behavior, so it's crucial to understand their purpose and usage before implementation. Feel free to consult the documentation or contact support if you have any questions.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "674a9836-0f12-4047-a408-4d4f0557d6b1": {"__data__": {"id_": "674a9836-0f12-4047-a408-4d4f0557d6b1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c56e98d0-04c6-4b38-9561-f61bcef455b6", "node_type": null, "metadata": {}, "hash": "523bfe41daea5ddbce007a4bedc9367a9c5520f06fdef0dbe9a5c49f99aa69c1"}}, "hash": "9fe1ba9706ec7c25aa527a2a5ffa23df28b179e2756160a64fee729464b4fc4c", "text": "\ud83d\udcea Portkey Modes\n\nPortkey simplifies your experience when deploying and managing Generative AI applications. It can be integrated in two ways:\n\n1.  **Middleware Mode**: This mode is ideal if you want to maintain your existing LLM setup, while adding the robust capabilities that Portkey provides. Here's how it works:\n\n    * Modify your LLM base path to route all requests via Portkey.\n    * Once a request is received, Portkey forwards it to the original LLM with an extremely low latency (\\~20ms)\n    * Throughout this process, Portkey offers its extensive suite of features such as request tracing, caching, automatic retries, custom metadata, load balancing, and observability.\n\n\n2. **Managed Models Mode**: This mode is for customers who prefer a hands-off approach, allowing Portkey to handle the intricacies of managing the LLMs:\n   * Customers define and save their LLM prompts and all the associated parameters on the Portkey UI.\n   * Portkey then creates an API endpoint specific to this model.\n   * Users can directly call this API, which handles all the interactions with the LLM behind the scenes.\n   * This model not only simplifies the process of working with LLMs but also ensures that the customers can leverage all the features of Portkey without worrying about the complexities of directly handling the LLM.\n\nThese integration methods have been designed to offer flexibility and ease of use, ensuring that you can make the most of your Generative AI applications with minimal hassle.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fbd5655e-c9d9-427a-868e-5a8b8da8d6d8": {"__data__": {"id_": "fbd5655e-c9d9-427a-868e-5a8b8da8d6d8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "93e29045-984c-482e-b950-eb3404307ee8", "node_type": null, "metadata": {}, "hash": "b2cd9d606f80fca81830e5ba6bdb7ef9e6fbc90a71413f3c4ea4d86d805f7570"}}, "hash": "3ac8a4fdc6168085b57fe23ba34e86a9a307cb31e3545c44bcbb788456263a97", "text": "\ud83c\udf08 Supported LLMs", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4eb8d14d-142c-4448-912d-9894392b7d97": {"__data__": {"id_": "4eb8d14d-142c-4448-912d-9894392b7d97", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "35ca024e-0d5f-4a44-8c30-4da4a10bc5c9", "node_type": null, "metadata": {}, "hash": "5494be0141160b2d1bdeb79db50de4afc36a2159d31238d4c9159db99132039d"}}, "hash": "884df8b36c34c44cb8ee33e85d958a3b595edbde97afc470caa4af8daed0b77c", "text": "Supported LLM Providers\n\n| Provider                   |\n| -------------------------- |\n| OpenAI                     |\n| Azure OpenAI               |\n| Anthropic                  |\n| Cohere                     |\n| Hugging Face (invite-only) |", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c8f8f369-e67b-40fd-9c8c-e3781dfcb187": {"__data__": {"id_": "c8f8f369-e67b-40fd-9c8c-e3781dfcb187", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d9c8293b-e05c-4d6f-85d2-d1a28989434b", "node_type": null, "metadata": {}, "hash": "80264cc76d2fad124f28fa340b04a2543a5da7ab2f2c8a0ca1a03b3bcbb2f1ed"}}, "hash": "7ddfd8caccc6e71aed974b7d5c2ad7bcf978706dd087c29b5a0b2ae95d6c7351", "text": "Detailed Overview of LLM Functions by Provider\n\nThe table below provides a more detailed look at which functions (generate, embed, classify, etc.) are supported by each LLM provider against each Portkey mode (middleware or managed models).\n\n| Provider     | Middleware Mode                                                                            | Managed Models Mode |\n| ------------ | ------------------------------------------------------------------------------------------ | ------------------- |\n| OpenAI       | Chat, Completions, Embed, Images, Embeddings, Audio, Files, Fine-tunes, Moderations, Edits | Chat, Completions   |\n| Azure OpenAI | Chat, Completions, Embed, Images, Embeddings, Audio, Files, Fine-tunes, Moderations, Edits | (coming soon)       |\n| Anthropic    | Completions                                                                                | Completions         |\n| Cohere       | Generate, Embed, Classify, Tokenize, Detokenize, Detect-language, Summarise, Rerank        | (coming soon)       |\n| Hugging Face | Inference                                                                                  | (coming soon)       |\n\n\n\n{% hint style=\"info\" %}\n**Please Note**: This table will be regularly updated as we continue to expand our support for various LLM providers and their functions. Some of the unavailable functions might already be in beta. Do reach out our support if you need something which is missing here.\n{% endhint %}\n\nIf you have any questions about LLM support or if you're interested in a provider or function that's not currently listed, please reach out to our support team. We're always looking to enhance our offerings based on your needs.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "37911521-c008-4380-bbc4-3b87b4edf03f": {"__data__": {"id_": "37911521-c008-4380-bbc4-3b87b4edf03f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1e93e5ce-8803-4eba-a06a-475d4452b068", "node_type": null, "metadata": {}, "hash": "64197174f277691c3e6681a16629adc6f03c072c2bf01d50d71aa4ec89248d9d"}}, "hash": "90583d88fc25eed97a18f1be31cc5740586286fdfe27ca0e6f95c8b73b5ed161", "text": "\u27a1 Anthropic SDK\n\nIn the following code snippets, the `base_url` is changed to Portkey's base path.\n\nThe Portkey API key and mode are passed in the request headers. You need to replace `` with your actual Portkey API key. The mode is set as **`proxy anthropic`** which is the Portkey middleware mode for Anthropic.\n\n{% tabs %}\n{% tab title=\"Python\" %}\n```python\nfrom anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n\nheaders = {\n    \"x-portkey-api-key\": ,\n    \"x-portkey-mode\": \"proxy anthropic\",\n}\n\nanthropic = Anthropic(\n    api_key=,\n    default_headers=headers,\n    base_url=\"https://api.portkey.ai/v1/proxy\",\n)\n\ncompletion = anthropic.completions.create(\n    model=\"claude-2\",\n    max_tokens_to_sample=300,\n    prompt=f\"{HUMAN_PROMPT} how does a court case get to the Supreme Court? {AI_PROMPT}\",\n)\n\nprint(completion.completion)\n```\n{% endtab %}\n\n{% tab title=\"NodeJS\" %}\n```typescript\nimport Anthropic from '@anthropic-ai/sdk';\n\nconst headers = {\n    \"x-portkey-api-key\": ,\n    \"x-portkey-mode\": \"proxy anthropic\",\n    \"x-portkey-cache\": \"semantic\"\n};\n\n\nconst anthropic = new Anthropic({\n  apiKey: ,\n  defaultHeaders: headers,\n  baseURL: 'https://api.portkey.ai/v1/proxy'\n});\n\n\nasync function main() {\n  const completion = await anthropic.completions.create({\n    model: 'claude-2',\n    max_tokens_to_sample: 300,\n    prompt: `${Anthropic.HUMAN_PROMPT} why did the chicken cross the road? ${Anthropic.AI_PROMPT}`,\n  });\n  console.log(completion);    \n}\n  \nmain().catch(console.error);  \n```\n{% endtab %}\n{% endtabs %}\n\nRemember, you can leverage more Portkey features by including appropriate headers in your requests. For instance, you can enable request caching by adding the `\"x-portkey-cache\": \"simple\"` or `\"x-portkey-cache\": \"semantic\"` header, depending on the caching mechanism you want to use.\n\nLikewise, you can enable request retries by adding the `\"x-portkey-retry-count\": ` header, and so on. Refer to the Portkey Headers document for more details on enabling/disabling different features using headers.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "51af44e6-3769-46b7-9d21-b00261c0a866": {"__data__": {"id_": "51af44e6-3769-46b7-9d21-b00261c0a866", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "333ef42d-36fd-47a5-9ec1-69d996c5d8cb", "node_type": null, "metadata": {}, "hash": "c47863698e9978f0b860354f0d556f6a01f70f363c3ad3edf185a01fbb6dedf0"}}, "hash": "81ab8ff0e6aef024c5fd45d1615d5e3aea16b137d3713fb8cbdf869528865dea", "text": "\u27a1 Cohere\n\nFor Cohere, Portkey provides complete integration with all of Cohere's endpoints using HTTP-based requests. For Python, you can use the popular Requests library, and in Node.js, Axios is a common choice.\n\n{% tabs %}\n{% tab title=\"Python\" %}\n```python\nimport requests\n\nurl = \"https://api.portkey.ai/v1/proxy/generate\"\n\npayload = { \"prompt\": \"Tell me a joke.\" }\nheaders = {\n    \"accept\": \"application/json\",\n    \"content-type\": \"application/json\",\n    \"authorization\": \"Bearer g6nKXKAh07io48RPqFZNicCj6oQQ7kl9KN8PqdcA\",\n    \"x-portkey-api-key\" : \"\",\n    \"x-portkey-cache\" : \"semantic\",\n    \"x-portkey-mode\" : \"proxy cohere\",\n}\n\nresponse = requests.post(url, json=payload, headers=headers)\n\nprint(response.text)\n```\n{% endtab %}\n\n{% tab title=\"NodeJS\" %}\n```typescript\nimport axios, { AxiosRequestConfig, AxiosResponse, AxiosError } from 'axios';\n\nconst options: AxiosRequestConfig = {\n  method: 'POST',\n  url: 'https://api.portkey.ai/v1/proxy/generate',\n  headers: {\n    'accept': 'application/json',\n    'content-type': 'application/json',\n    'authorization': 'Bearer ',\n    \"x-portkey-api-key\": \"\",\n    \"x-portkey-mode\": \"proxy cohere\",\n    \"x-portkey-trace-id\": \"demo_cohere\"\n  },\n  data: {prompt: 'O Captain! my Captain! our fearful trip is done'}\n};\n\naxios\n  .request(options)\n  .then((response: AxiosResponse) => {\n    console.log(response.data);\n  })\n  .catch((error: AxiosError) => {\n    console.error(error);\n  });\n\n```\n{% endtab %}\n{% endtabs %}\n\n{% hint style=\"danger\" %}\n**Note - Cohere SDK Integration**\n\nAt present, Portkey's integration is not directly compatible with Cohere's official SDKs due to their current lack of support for custom headers. However, we're actively working on this and will provide SDK compatibility as soon as possible.\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "180651cb-4dcd-4d26-8fcb-32a2736ba755": {"__data__": {"id_": "180651cb-4dcd-4d26-8fcb-32a2736ba755", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "cd66a153-e7b6-4868-806c-9c0656c3397b", "node_type": null, "metadata": {}, "hash": "261099be162bf43bf518ed0a6773837a6fcd6d8389ad1f1c539ea596e9f86056"}}, "hash": "3a4c18081dba23a40bbdf472b1a6eaa5f400e4a4c131ab5e2f828bc66738729e", "text": "\u27a1 Langchain\n\n**Open AI**\n\nUsing Portkey with Langchain is as simple as just choosing which Portkey features you want, enabling them via `headers=Portkey.Config` and passing it in your LLM calls.\n\n{% tabs %}\n{% tab title=\"Python\" %}\n```python", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4413de61-7dde-4956-9882-f2df64df1254": {"__data__": {"id_": "4413de61-7dde-4956-9882-f2df64df1254", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5cc245ff-6233-496b-bb08-15b535ae1ac8", "node_type": null, "metadata": {}, "hash": "a8b98d8dd596982a93df524f24a459f7d848dce5f5c4e5d9bb21559b40d5620d"}}, "hash": "a214e8a2c2fb065d72429fa825bcfeb24a5bd7edf31b147c5bd065b4af1a43ef", "text": "Tracing agent calls across different requests\n\nimport os\nfrom langchain.llms import OpenAI\nfrom langchain.utilities import Portkey\n\nos.environ[\"OPENAI_API_KEY\"] = \"\"\nPORTKEY_API_KEY = \"\" # Set Portkey API key here\nTRACE_ID = \"portkey_langchain_demo\"  # Set trace id here", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "983f1bd7-b6e8-41b3-855b-4f1d0b3e6c7e": {"__data__": {"id_": "983f1bd7-b6e8-41b3-855b-4f1d0b3e6c7e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4403b0c6-b720-4cc4-a2c1-3257daa22cc6", "node_type": null, "metadata": {}, "hash": "4b6f0381517ca1b91fe78f8c3e948711a74236bcbd3d4fa93040efd5de6b4b48"}}, "hash": "9378b0b3bd5fd8f7fb17273dabd2716c60ec728a48fa8d1aae037edebbcac9bd", "text": "Since Portkey is integrated with Langchain, Portkey.Config() takes care of defining headers\n\nheaders = Portkey.Config(\n    api_key=PORTKEY_API_KEY,\n    trace_id=TRACE_ID,\n)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a9d4c944-0af5-4676-8bfa-467a05654765": {"__data__": {"id_": "a9d4c944-0af5-4676-8bfa-467a05654765", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "44ad1a04-e735-4821-ad7a-c69bba1a9be1", "node_type": null, "metadata": {}, "hash": "dcb54571ff57041e6afefd05d9fbaa5d4a1d3ba695b6c5c47d15ef253cc70680"}}, "hash": "b4b82c91069f25ce5a3e4c6aa66bc3a33f4267d13a113558e2c9ac18a63b7bf2", "text": "Now, let's pass these headers\n\nllm = OpenAI(headers=headers)\n\ntools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\nagent = initialize_agent(\n    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f1af9896-a273-4528-a77b-34cc3a58afc2": {"__data__": {"id_": "f1af9896-a273-4528-a77b-34cc3a58afc2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1b1e80ce-831e-4f58-84b5-d9d2ff22e57d", "node_type": null, "metadata": {}, "hash": "17042a59b63f98604e99678a2e3b7c20c6eb9ddb84275147941beb800cdb73c6"}, "3": {"node_id": "ad31252d-fced-48ed-9396-87e1bdec871c", "node_type": null, "metadata": {}, "hash": "be40792aceb07eed952f392ff48631e287ec7daef2d02de73612572a9765c66c"}}, "hash": "f9d420d2476882dced17a7e2d49798bedef3cbea3cfe3315b52634decdd27f14", "text": "Let's test it out!agent.run(\n    \"What was the high temperature in SF yesterday in Fahrenheit?What is that number raised to the .023 power?\")\n```\n{% endtab %}\n\n{% tab title=\"NodeJS\" %}\n```typescript\nimport { OpenAI } from \"langchain/llms/openai\";\n\nconst model = new OpenAI({\n  modelName: \"text-davinci-003\", \n  temperature: 0.9,\n  openAIApiKey: \"\",\n  configuration: {\n    basePath: \"https://api.portkey.ai/v1/proxy\",\n    baseOptions: {\n      headers: {\n        'x-portkey-api-key': '',\n        'x-portkey-mode': 'proxy openai',\n        'x-portkey-trace-id' : 'langchain_demo'\n      }\n    }\n  }\n});\n\nasync function main() {\n  const res = await model.call(\"Describe the world as written by Herodotus.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ad31252d-fced-48ed-9396-87e1bdec871c": {"__data__": {"id_": "ad31252d-fced-48ed-9396-87e1bdec871c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1b1e80ce-831e-4f58-84b5-d9d2ff22e57d", "node_type": null, "metadata": {}, "hash": "17042a59b63f98604e99678a2e3b7c20c6eb9ddb84275147941beb800cdb73c6"}, "2": {"node_id": "f1af9896-a273-4528-a77b-34cc3a58afc2", "node_type": null, "metadata": {}, "hash": "f9d420d2476882dced17a7e2d49798bedef3cbea3cfe3315b52634decdd27f14"}}, "hash": "be40792aceb07eed952f392ff48631e287ec7daef2d02de73612572a9765c66c", "text": "\");\n  console.log(res);\n}\nmain();\n```\n{% endtab %}\n{% endtabs %}\n\n**Check out the list of config keys you can set with `Portkey.Config` on Langchain:**\n\nFeatureConfig KeyValue (Type)Required/OptionalAPI Keyapi_keyAPI Key (string)\u2705 RequiredTracing Requeststrace_idCustom string\u2754 OptionalAutomatic Retriesretry_countinteger [1,2,3,4,5]\u2754 OptionalEnabling Cachecachesimple OR semantic\u2754 OptionalCache Force Refreshcache_force_refreshTrue\u2754 OptionalSet Cache Expirycache_ageinteger (in seconds)\u2754 OptionalAdd Useruserstring\u2754 OptionalAdd Organisationorganisationstring\u2754 OptionalAdd Environmentenvironmentstring\u2754 OptionalAdd Prompt (version/id/string)promptstring\u2754 Optional\n\n**Azure Open AI**\n\n{% tabs %}\n{% tab title=\"Python\" %}\n```python\nimport os\n\nos.environ[\"OPENAI_API_TYPE\"] = \"azure\"\nos.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\"\nos.environ[\"OPENAI_API_BASE\"] = \"https://api.portkey.ai/v1/proxy/RESOURCE_NAME.openai.azure.com/\"\nos.environ[\"OPENAI_API_KEY\"] = \"AZURE_API_KEY\"\n\nfrom langchain.llms import AzureOpenAI\n\nllm = AzureOpenAI(\n    headers = {\n        \"x-portkey-api-key\": \"\",\n        \"x-portkey-mode\": \"proxy azure-openai\"\n    },\n    deployment_name=\"DEPLOYMENT_NAME\",\n    model_name=\"MODEL_NAME\",\n)\n\nllm(\"Tell me a joke\")\n```\n{% endtab %}\n\n{% tab title=\"NodeJS\" %}\n```typescript\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\n\nconst model = new ChatOpenAI({\n  azureOpenAIApiKey: process.env.AZURE_OPENAI_API_KEY\n  azureOpenAIApiVersion: process.env.AZURE_OPENAI_API_VERSION\n  azureOpenAIApiInstanceName: process.env.AZURE_OPENAI_API_INSTANCE_NAME\n  azureOpenAIApiDeploymentName: process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME\n  azureOpenAIBasePath: \"https://api.portkey.ai/v1/proxy/${process.env.AZURE_OPENAI_API_INSTANCE_NAME}.openai.azure.com/openai/deployments\",\n},\n{\n    baseOptions: {\n        headers: {\n            \"x-portkey-api-key\": \"\",\n            \"x-portkey-mode\": \"proxy azure-openai\"\n        },\n      },\n}\n);\n\nasync function main() {\n  const message = await model.invoke(\"Tell me a joke\");\n  console.log(message);\n}\n\nmain();\n```\n{% endtab %}\n{% endtabs %}\n\nFor more, checkout Portkey's Langchain documentation for Python.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d75cdc57-282b-4f5f-a685-45947f66feec": {"__data__": {"id_": "d75cdc57-282b-4f5f-a685-45947f66feec", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5531282c-224e-4a4d-a57e-ab7e8088226d", "node_type": null, "metadata": {}, "hash": "093092112155d07dc30969e5e93980781dc98dfab87c608a8410d5f83e3e1abd"}}, "hash": "115aa35dbd6142e18871fb155306f016fa12ef40adb0cb9d892c015f816dead0", "text": "\u27a1 Microsoft Guidance\n\n{% hint style=\"warning\" %}\n**TBD**\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "23b800d2-e7f7-45ac-bd2c-84ef31ccf428": {"__data__": {"id_": "23b800d2-e7f7-45ac-bd2c-84ef31ccf428", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c442f20d-9eea-4b17-807f-395b8ca4098f", "node_type": null, "metadata": {}, "hash": "4db1f84d1c35a3b282f03e32cd8ce18358ffe5de257a4b7b399e8a436226bf6c"}}, "hash": "4fd273a6e4d6638f7cec3d3c19e4fada575a3f765ec962dc4cdf8275fd980fb2", "text": "\u27a1 Open AI SDK\n\nIn the following code snippets, the `api_base` is changed to Portkey's base path.\n\nThe Portkey API key and mode are passed in the request headers. You need to replace `` with your actual Portkey API key. The mode is set as **`proxy openai`** which is the Portkey middleware mode for OpenAI.\n\n{% tabs %}\n{% tab title=\"Python\" %}\n```python\nimport openai", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0cf396a0-1ad0-4fa4-be0a-d0d923279106": {"__data__": {"id_": "0cf396a0-1ad0-4fa4-be0a-d0d923279106", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fd28e723-a1f8-4a41-91ce-023a2b41de59", "node_type": null, "metadata": {}, "hash": "fd9246903b21c8674aa50f082d66526c6761a8abefec52f9c0097a54dda54840"}}, "hash": "460f0e295e758ecf0b9e80294ef5ad7ba5293688c31d4b8a96853c5a2b9333c2", "text": "Set Portkey as the base path\nopenai.api_base = \"https://api.portkey.ai/v1/proxy\"\n\nresponse = openai.Completion.create(\n  model=\"text-davinci-003\",\n  prompt=\"Translate the following English text to French: '{}'\",\n  temperature=0.5,\n  headers={\n    \"x-portkey-api-key\": \"\",\n    \"x-portkey-mode\": \"proxy openai\"\n  }\n)\n\nprint(response.choices[0].text.strip())\n```\n{% endtab %}\n\n{% tab title=\"NodeJS\" %}\n```typescript\nconst { Configuration, OpenAIApi } = require(\"openai\");\nconst configuration = new Configuration({\n  apiKey: \"\",\n  basePath: \"https://api.portkey.ai/v1/proxy\",\n    baseOptions: {\n      headers: {\n        \"x-portkey-api-key\": \"\",\n        \"x-portkey-mode\": \"proxy openai\"\n      }\n    }\n});\n\nconst openai = new OpenAIApi(configuration);\n\nasync function generateCompletion() {\n  const response = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt: \"Two roads diverged in the yellow woods\",\n    max_tokens: 512,\n    temperature: 0,\n  });\n\n  console.log(response.data.choices[0].text);\n}\n\ngenerateCompletion();\n```\n{% endtab %}\n{% endtabs %}\n\nEach of the above code snippets perform the same operation - generating text based on a prompt using OpenAI's API via Portkey's middleware.\n\nRemember, you can leverage more Portkey features by including appropriate headers in your requests. For instance, you can enable request caching by adding the `\"x-portkey-cache\": \"simple\"` or `\"x-portkey-cache\": \"semantic\"` header, depending on the caching mechanism you want to use.\n\nLikewise, you can enable request retries by adding the `\"x-portkey-retry-count\": ` header, and so on. Refer to the Portkey Headers document for more details on enabling/disabling different features using headers.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "dfd7af61-33c8-456c-8f3d-24c2125b9c90": {"__data__": {"id_": "dfd7af61-33c8-456c-8f3d-24c2125b9c90", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e716c6ef-b39b-432a-afa0-48e3407dc6ae", "node_type": null, "metadata": {}, "hash": "042e78cda250fd261159fa79858b3ea45b2e5185cc1ac0273314c42fb41795ad"}, "3": {"node_id": "a8f25adb-05de-4ab5-8fba-a57b5ec6ffff", "node_type": null, "metadata": {}, "hash": "2a6bcd07e63dc039286e7c70426dd6a4dc70e095bf42adda90c3dbfdff46cf4e"}}, "hash": "41196f8982bea541104d0f141d834895315cf3cb590256211c2261b7c5a697fb", "text": "\u27a1 Rest API\n\n**Open AI**\n\nFor OpenAI, change the API basepath according to the OpenAI endpoint you are calling, and add the `x-portkey-api-key` & `x-portkey-mode` headers. Mode value for OpenAI should **`proxy openai`**\n\nReplace `` & `` with actual values from the following snippet.\n\n{% tabs %}\n{% tab title=\"cURL\" %}\n```bash\ncurl --location 'http://api.portkey.ai/v1/proxy/completions' \\\n--header 'x-portkey-api-key: ' \\\n--header 'x-portkey-mode: proxy openai' \\\n--header 'Authorization: Bearer ' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"n\": 1,\n    \"model\": \"text-davinci-003\",\n    \"prompt\": \"Top 20 tallest buildings in the world\"\n}'\n```\n{% endtab %}\n{% endtabs %}\n\n**Azure Open AI**\n\nFor Azure OpenAI, change the basepath by prefixing the Portkey's base URL followed by the Azure deployment endpoint.&#x20;\n\nFor example, a typical azure endpoint looks like this:\\\n`https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/completions?api-version=202305-15`\\\n\\\nAfter adding the prefix it should change to:\\\n`https://api.portkey.ai/v1/proxy/YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/completions?api-version=2023-05-15`\\", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a8f25adb-05de-4ab5-8fba-a57b5ec6ffff": {"__data__": {"id_": "a8f25adb-05de-4ab5-8fba-a57b5ec6ffff", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e716c6ef-b39b-432a-afa0-48e3407dc6ae", "node_type": null, "metadata": {}, "hash": "042e78cda250fd261159fa79858b3ea45b2e5185cc1ac0273314c42fb41795ad"}, "2": {"node_id": "dfd7af61-33c8-456c-8f3d-24c2125b9c90", "node_type": null, "metadata": {}, "hash": "41196f8982bea541104d0f141d834895315cf3cb590256211c2261b7c5a697fb"}}, "hash": "2a6bcd07e63dc039286e7c70426dd6a4dc70e095bf42adda90c3dbfdff46cf4e", "text": "Add the  `x-portkey-api-key` & `x-portkey-mode` headers. Mode value for Azure OpenAI should **`proxy azure-openai`**\n\nReplace ``,``, ``,  ``  with actual values from the following snippet.\n\n{% tabs %}\n{% tab title=\"cURL\" %}\n```bash\ncurl --location 'https://api.portkey.ai/v1/proxy/.openai.azure.com/openai/deployments//completions?api-version=2023-05-15' \\\n--header 'api-key: ' \\\n--header 'x-portkey-api-key: ' \\\n--header 'x-portkey-mode: proxy azure-openai' \\\n--header 'Content-Type: application/json' \\\n--data '{        \n    \"prompt\":\"Once upon a time\"\n}'\n```\n{% endtab %}\n{% endtabs %}\n\n**Cohere**\n\nFor Cohere, change the API basepath according to the Cohere endpoint you are calling, and add the `x-portkey-api-key` & `x-portkey-mode` headers. Mode value for Cohere should **`proxy cohere`**\n\nReplace `` & `` with actual values from the following snippet.\n\n{% tabs %}\n{% tab title=\"cURL\" %}\n````bash\n```powershell\ncurl --location 'http://portkey.ai/v1/proxy/generate' \\\n--header 'x-portkey-api-key: ' \\\n--header 'Authorization: Bearer ' \\\n--header 'x-portkey-mode: proxy cohere' \\\n--header 'Content-Type: application/json' \\\n--header 'x-portkey-cache: true' \\\n--data '{\n  \"max_tokens\": 10,\n  \"return_likelihoods\": \"NONE\",\n  \"truncate\": \"END\",\n  \"prompt\": \"Once upon a time in a magical land called\"\n}'\n```\n````\n{% endtab %}\n{% endtabs %}\n\n**Anthropic**\n\nFor Anthropic, change the API basepath and add the `x-portkey-api-key` & `x-portkey-mode` headers. Mode value for OpenAI should **`proxy anthropic.`** Anthropic only supports `/complete` end point as of now.&#x20;\n\nReplace `` & `` with actual values from the following snippet.\n\n{% tabs %}\n{% tab title=\"cURL\" %}\n```bash\ncurl --location 'https://api.portkey.ai/v1/proxy/complete' \\\n--header 'x-portkey-api-key: ' \\\n--header 'x-api-key: ' \\\n--header 'x-portkey-mode: proxy anthropic' \\\n--header 'Content-Type: application/json' \\\n--header 'x-portkey-cache: true' \\\n--data '{\n    \"prompt\": \"\\n\\nHuman: Tell me a haiku about trees\\n\\nAssistant: \",\n    \"model\": \"claude-v1\",\n    \"max_tokens_to_sample\": 300,\n    \"stop_sequences\": [\n        \"\\n\\nHuman:\"\n    ]\n}'\n```\n{% endtab %}\n{% endtabs %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "edfddad1-fe34-42c5-96ac-f270e9e40cf8": {"__data__": {"id_": "edfddad1-fe34-42c5-96ac-f270e9e40cf8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "866a1ff1-100d-45c6-86d8-d4a7e7b78dfe", "node_type": null, "metadata": {}, "hash": "d6d8b3ba0036083babc7c3924c29ee73bc81185b78bc6508464623dc3e78ef17"}}, "hash": "e2603834d56b123d5d8fd76d5c023c5c82695f33bc5b395c3fe6dfb87a39bce9", "text": "\ud83d\udd11 AI Provider Keys\n\nDeploy your prompt templates through Portkey and seamlessly integrate with your preferred AI provider. Simply add your API keys to Portkey, and you're ready to roll!", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "dfbb728c-c6ce-4213-9ed2-8047eeb9a0ba": {"__data__": {"id_": "dfbb728c-c6ce-4213-9ed2-8047eeb9a0ba", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2829ca34-f061-428d-abb9-0fd026b6a0d1", "node_type": null, "metadata": {}, "hash": "d1011bbb8dc0d5b1b2b26141c59ca6f4fb2c5d08fefc9d0995d43d345acabf22"}}, "hash": "7f78dc4ab066b46e8a72118f89fded1756a52f920a1b394abaf38439526e6fc4", "text": "How to Add Provider Keys\n\n* **Step 1**: Navigate to the \"Virtual Keys\" page and hit the \"Add Key\" button located at the top right corner.\n* **Step 2**: Choose your AI provider, assign a unique name to your key, and, if needed, jot down any relevant usage notes.\n\n\n\n**Did You Know?** You can add multiple keys for the same provider **and** also add the same key under different names for ease of identification.\n\nCurrently, Portkey supports:\n\n* OpenAI\n* Anthropic\n* Cohere\n* Azure OpenAI\n* **Coming Soon**: HuggingFace \ud83d\ude80", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "80991f3e-b5a8-427f-b66c-a1081f86610c": {"__data__": {"id_": "80991f3e-b5a8-427f-b66c-a1081f86610c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce2e6bbc-d494-443a-8484-2d26fafa5653", "node_type": null, "metadata": {}, "hash": "e4897479ef33e43208cee14ba6ce70ac34269c8fd848d5df69029f2bafc82962"}}, "hash": "222fab13c2ed125f3e8708881f9a85d8f129ba71e687ff9c4a6084941451c414", "text": "**Understanding Virtual Keys:**\n\nSafety first! Portkey transforms your provider key into a virtual key to use within the Portkey ecosystem. This ensures that your original provider keys remain secure and untouched.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "eb564ce8-4238-4ab9-b47d-77398f6dd043": {"__data__": {"id_": "eb564ce8-4238-4ab9-b47d-77398f6dd043", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "92bec081-db05-4090-83d1-9d0641d2db6a", "node_type": null, "metadata": {}, "hash": "b8df4788e92aa19b3731924efdb5b0164fbf71f13c2030d419e6b0935fb2965c"}}, "hash": "289a7acb0e983019469936b85e27bcf6c6cef676cb56e66b15174a7d6ee41bd2", "text": "What's on the Horizon?\n\nPortkey's virtual keys are about to get even more powerful:\n\n* **Cost Limits**: Set expenditure caps on each virtual key. Once the limit's hit, the key deactivates.\n* **Role-Based Access**: Define who in your organization gets to use which key. Keep everything in the right hands.\n* **Usage Settings**: Want a key for a specific function? You'll soon be able to define exact use cases for each key.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "26aba237-a755-4768-841b-acfc6a55c184": {"__data__": {"id_": "26aba237-a755-4768-841b-acfc6a55c184", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a0f8b6cf-6b44-4fd4-829f-cbd60e620347", "node_type": null, "metadata": {}, "hash": "9ff3b1763ad62fbce73bd5f2db83f77332786c3c022721412594bad70ccd3de3"}}, "hash": "87969dcad03ae305349ed3c73e8f407abe21181c202bfbe0ba8014567cd3ff21", "text": "\ud83d\udcab Automatic Retries\n\nPortkey has an in-built retry mechanism that makes sure your requests get fulfilled. We implement a retry mechanism with exponential backoff. This can be managed by the `x-portkey-retry-count` header.\n\n```\n{\n    \"x-portkey-retry-count\": 4\n}\n```\n\n{% hint style=\"info\" %}\nThe max value of retry-count is 5\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2368aa10-a50e-41c1-83b1-91e5dde747d3": {"__data__": {"id_": "2368aa10-a50e-41c1-83b1-91e5dde747d3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "79595773-0b28-409a-b62c-765f018efb84", "node_type": null, "metadata": {}, "hash": "8093e195edf85c7254fc9fc3622c7c8874f8826eca5c9713be2bcd92dd77ae5c"}}, "hash": "f6728a49e0a359d0ff24abc9d605eef4385e750cecf34667748b93fb2aeced65", "text": "\ud83d\udcc3 Custom Metadata\n\nYou can send custom metadata along with your API requests in Portkey, which can be later used for auditing or filtering logs. Portkey provides four predefined keys: `_environment`, `_user`, `_organisation`, and `_prompt`. These predefined keys are indexed and allow for filtering data in Portkey analytics and logs sections. You can still pass any other metadata key you desire, but these four predefined keys will be indexed and will be available for filtering data in Portkey.\n\n{% hint style=\"info\" %}\nAll predefined keys should be of type String, with max-length as 128 characters.\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2959e80a-69a0-4111-9c58-965cfd11c15d": {"__data__": {"id_": "2959e80a-69a0-4111-9c58-965cfd11c15d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "52eab5c2-81f9-4ab3-81f1-1d99b984af5f", "node_type": null, "metadata": {}, "hash": "e7af29e5f78e7c02adbf7b0055d023480f538e2a0d9568fab4b85c5ed4a4bf82"}}, "hash": "7e19c8b205b79aedd2d9716d08ae268d7637e206cea3c224198dfe8ae8321a9e", "text": "Proxy Metadata\n\nTo include metadata in the proxy requests, you can add an `x-portkey-metadata` header with a JSON string containing your metadata. Portkey will parse the JSON object and make it available for filtering.\n\n```\n{    \n    \"x-portkey-metadata\": JSON.stringify({\n        \"_environment\": \"production\",\n        \"_user\": \"userid123\",\n        \"_organisation\": \"orgid123\",\n        \"_prompt\": \"summarisationPrompt\",\n        \"foo\": \"abc\",\n        \"bar\": \"def\"\n    })\n}\n```\n\n\n\n{% hint style=\"info\" %}\n**When using the \\_user predefined key, the following behavior applies:**\n\nIf you pass the `user` key in the OpenAI request body, it will be automatically stored in `_user`. If both the OpenAI request body `user` key and the metadata `_user` key are passed, the metadata `_user` key will be stored.\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2efeffe5-d122-43f5-a1f9-ce026399c4fe": {"__data__": {"id_": "2efeffe5-d122-43f5-a1f9-ce026399c4fe", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a9c5a44c-f72c-4e1d-b94d-c566a05da566", "node_type": null, "metadata": {}, "hash": "5a1e0a842e627d7f2cf27abf8cdf0bc410d0cb5c4d7306b13a6d02c38890ce10"}}, "hash": "6c47d066a391ffb15b73fc4b8248772bfe65ccd75c8d4862b1dc7883abdc97e9", "text": "**\ud83d\udda5\ufe0f Portkey Dashboard Guide**\n\nYou can filter your logs with the predefined keys (`_environment`, `_user`, `_organisation`, `_prompt)` easily on the Portkey logs.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "916f9a74-313e-4cf9-8726-1c8942810111": {"__data__": {"id_": "916f9a74-313e-4cf9-8726-1c8942810111", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b1490c59-64f6-40f4-9fd2-e059202e30c0", "node_type": null, "metadata": {}, "hash": "c4733e39d19c9276c888f3274ca447563c4850fefb3a46c2187996e1b9e2cc18"}}, "hash": "5bee8c661d3df8223d7ad815cf194957954d60d6950ed19ccf47ae614a742fda", "text": "\ud83e\udd16 Fallbacks on LLMs\n\nWith an array of Language Model APIs available on the market, each with its own strengths and specialties, wouldn't it be great if you could seamlessly switch between them based on their performance or availability? Portkey's Fallback capability is designed to do exactly that.\n\nThe Fallback feature allows you to specify a list of Language Model APIs (LLMs) in a prioritized order. If the primary LLM fails to respond or encounters an error, Portkey will automatically fallback to the next LLM in the list, ensuring your application's robustness and reliability.\n\n{% hint style=\"danger\" %}\n**Please note:** As of now, the Fallback on LLMs feature is in beta, please reach out to Portkey support if you face issues or have questions.\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fd15a747-02e9-4d22-8bdc-55b80542d621": {"__data__": {"id_": "fd15a747-02e9-4d22-8bdc-55b80542d621", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "59751c52-fd4f-4cb5-8aef-62ed442d6dff", "node_type": null, "metadata": {}, "hash": "94e2dc43bd4bdf03fc90d990f0665d65aed8c659bd8e0479b6fa5ba9234d6d58"}}, "hash": "3a9c4a6a2636bdf2d849e8de09d57db9f1713200b7a6ae5a81cec457cac29aec", "text": "Enabling Fallback on LLMs\n\nTo enable Load Balancing, you can modify the `config` object of your `complete` or `chatComplete` API request to include the `fallback` mode.\n\nHere's a quick example to **fallback** to Anthropic's `claude-v1` if OpenAI's `gpt-3.5-turbo` fails.\n\n```powershell", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b05a9cda-aee6-43b7-8d99-2c06eaa1391c": {"__data__": {"id_": "b05a9cda-aee6-43b7-8d99-2c06eaa1391c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4c3eea78-409b-4958-81ae-21b705391912", "node_type": null, "metadata": {}, "hash": "73db6d17f95493b7d008bc28168217e80a94901cb559fd55bffe6219ed4d298e"}}, "hash": "94933431ed1b0f3ed2635548a937ee4d8a8c282f063557110f4a0474b6f9dd67", "text": "Fallback to claude-v1 if gpt-3.5-turbo fails\ncurl --location 'https://api.portkey.ai/v1/chatComplete' \\\n--header 'Content-Type: application/json' \\\n--header 'x-portkey-api-key: ' \\\n--data '{\n    \"config\": {\n        \"mode\": \"fallback\",\n        \"options\": [{\n            \"provider\": \"openai\",\n            \"apiKey\": \"\",\n            \"override_params\": { \"model\": \"gpt-3.5-turbo\" }\n        }, {\n            \"provider\": \"anthropic\",\n            \"apiKey\": \"\",\n            \"override_params\": { \"model\": \"claude-v1\" }\n        }]\n    },\n    \"params\": {\n        \"messages\": [{\"role\": \"user\",\"content\":\"What are the top 10 happiest countries in the world?\"}],\n        \"max_tokens\": 50,\n        \"user\": \"jbu3470\"\n    }\n}'\n```\n\nIn this scenario, if the OpenAI model encounters an error or fails to respond, Portkey will automatically retry the request with Anthropic.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "41a0db27-ea63-4bd0-8309-f681eccf4930": {"__data__": {"id_": "41a0db27-ea63-4bd0-8309-f681eccf4930", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7fe19708-d622-44a4-9a7a-786aa51572a3", "node_type": null, "metadata": {}, "hash": "5fac918b14fe43bbacb62206aea41ec0c431b36d1c419b3adfe98c3fed1a2664"}}, "hash": "506fbfdb955625a56799d015f2a76516e54046b67c3b09bf97b14f4876657e36", "text": "Caveats and Considerations\n\nWhile the Fallback on LLMs feature greatly enhances the reliability and resilience of your application, there are a few things to consider:\n\n1. Ensure the LLMs in your fallback list are compatible with your use case. Not all LLMs offer the same capabilities.\n2. Keep an eye on your usage with each LLM. Depending on your fallback list, a single request could result in multiple LLM invocations.\n3. Understand that each LLM has its own latency and pricing. Falling back to a different LLM could have implications on the cost and response time.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ecb4a727-3ea5-47c2-9e59-58aad4ef5aaf": {"__data__": {"id_": "ecb4a727-3ea5-47c2-9e59-58aad4ef5aaf", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f74d0530-7a58-4130-81b2-b77b6980b4ab", "node_type": null, "metadata": {}, "hash": "07ed089568de7d9e643d2cd8ef0c90d0f2f3ed17f6c7148ccd669a4e47ca00f9"}}, "hash": "01e9ca08e1141265df6bccce025d24ae6b39b7bb52fb23445c9c857428dd792f", "text": "\ud83d\udcdd Feedback API\n\nFeedback API provides a simple way to get weighted feedback from customers on any request you served, at any stage in your app. You can capture this feedback on a generation or conversation level and analyze it based on custom tags by adding meta data to the relevant request.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6cbefecd-d8ae-488d-9154-499e72dd457b": {"__data__": {"id_": "6cbefecd-d8ae-488d-9154-499e72dd457b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6af856a7-a11f-414f-8373-a30f3c41256f", "node_type": null, "metadata": {}, "hash": "31fb164d010ada6cb5ca66dd6aa0cf2d6898f058795e3e2e37a742b5c69df558"}}, "hash": "1cab24b6c8d4565dcd899d3b03c625508651a56660fe06d09e68439c2370e270", "text": "**\ud83d\udd11 Two Steps to Add Feedback**", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1394cf79-1097-4a0a-a125-866bf0cd6ff5": {"__data__": {"id_": "1394cf79-1097-4a0a-a125-866bf0cd6ff5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "08155926-75df-419b-9458-caf2c5ecc4b1", "node_type": null, "metadata": {}, "hash": "53fb64cf97a4c847c5d24f3e06774f06f83afe4614fea1c79e485f7e5f2c8574"}}, "hash": "a9206375b8988eb96b7bb9a025d67e0ad082a74d0b89e447614a2cdd18662882", "text": "**1\ufe0f\u20e3 Adding trace-id**\n\nPass the following param in your request header. Add any string for the `trace_id` you would like. We will append feedback to all requests with the same trace-id.\n\n```sh\n\"x-portkey-trace-id\": \"\"\n```", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d1dbeadf-2aa3-414a-97b3-d141f3b9c3b9": {"__data__": {"id_": "d1dbeadf-2aa3-414a-97b3-d141f3b9c3b9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1c716923-b0cc-4797-b227-8230b1fd6e3a", "node_type": null, "metadata": {}, "hash": "48509ad97b1ca5bfb400104f8d69af3d3cf175c61febc404c4cdfcfe8f2202a6"}, "3": {"node_id": "e3f1f5a8-3155-4993-87c7-067fdfb085c5", "node_type": null, "metadata": {}, "hash": "687bfe6c47e0f0c4d8a398bbe5de65e895c981bd7ac1e654b7868beb60367a4b"}}, "hash": "a9a5a54b586deac2e3f4de96fecb83d6801be225db5bd1bf90d2c9c3da970fe5", "text": "**2\ufe0f\u20e3 Passing feedback**\n\nYou can append feedback to a request with the `/feedback` endpoint like this:\n\n```sh\ncurl --location 'https://api.portkey.ai/v1/feedback' \\\n--header 'x-portkey-api-key: ' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"trace_id\": \"insert_trace_id_here\",\n    \"value\": -10,\n    \"weight\": 0.5,\n    \"metadata\": '{\"text\" : \"title was irrelevant\", \"_user\": \"fef653\", \"_organisation\": \"o9876\", \"_prompt\": \"test_prompt\", \"_environment\": \"production\"}'\n}'\n```\n\nThe **Payload** takes the following keys: `trace_id, value, weight, metadata`\n\n| Key        | Required?| Description                                                                                                                                                                                                                  | Type                                     |\n| ---------- | ---------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------- |\n| `trace_id` | \u2705 Required | The trace\\_id on which the feedback will be logged                                                                                                                                                                           | `string`                                 |\n| `value`    | \u2705 Required | Feedback value                                                                                                                                                                                                               | `integer` between `[-10,10]`             |\n| `weight`   | \u2754 Optional | Add weight value to feedback value.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e3f1f5a8-3155-4993-87c7-067fdfb085c5": {"__data__": {"id_": "e3f1f5a8-3155-4993-87c7-067fdfb085c5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1c716923-b0cc-4797-b227-8230b1fd6e3a", "node_type": null, "metadata": {}, "hash": "48509ad97b1ca5bfb400104f8d69af3d3cf175c61febc404c4cdfcfe8f2202a6"}, "2": {"node_id": "d1dbeadf-2aa3-414a-97b3-d141f3b9c3b9", "node_type": null, "metadata": {}, "hash": "a9a5a54b586deac2e3f4de96fecb83d6801be225db5bd1bf90d2c9c3da970fe5"}}, "hash": "687bfe6c47e0f0c4d8a398bbe5de65e895c981bd7ac1e654b7868beb60367a4b", "text": "Helpful if you're collecting multiple feedback for a single `trace_id`                                                                                                                   | `float` between `[0,1]`, Default = `1.0` |\n| `metadata` | \u2754 Optional | JSON string of any metadata you want to send along with the feedback._user, _organisation, _prompt and _environment are special fields indexed by default | `string`                                 |", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "96f3f9bf-10de-47e9-8249-6fde48f9efed": {"__data__": {"id_": "96f3f9bf-10de-47e9-8249-6fde48f9efed", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "28f7d049-9981-48cf-84e2-795bf233cf37", "node_type": null, "metadata": {}, "hash": "7d8e49173d0768995e6b29bac8b4247ff5a86525e9084d9617d1d3248b81dd6a"}}, "hash": "f45e88954a7e77d50e23cb2571a04b0366e82d6398116353316c98adeb7c6454", "text": "**\ud83d\udca1 Examples**\n\nOne simple & effective feedback you can get from the user is a simple thumbs up or thumbs down. Just set `value` to `1` for \ud83d\udc4d and `0` for \ud83d\udc4e. `Weight` would be default `1.0`.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7b51c1c9-8766-4bcf-af8d-fc85716382f4": {"__data__": {"id_": "7b51c1c9-8766-4bcf-af8d-fc85716382f4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7b197ddb-be91-4b3a-a59b-19cffb0b6342", "node_type": null, "metadata": {}, "hash": "af9b0ac7f199da2d2d82b646186db484f607f811b75cf7f853bb3349113af2a3"}}, "hash": "b8531303cc8797d83da2064511d802558b11de309140f98791198731f928eb2f", "text": "**Implementing \ud83d\udc4d\ud83c\udffb / \ud83d\udc4e\ud83c\udffb Feedback with `cURL`**\n\n```sh\ncurl --location 'https://api.portkey.ai/v1/feedback' \\\n--header 'x-portkey-api-key: ' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    'trace_id': 'REQUEST_TRACE_ID',\n    'value': 1\n}'\n```", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "00247de5-53b9-4132-8cf1-1894520eea00": {"__data__": {"id_": "00247de5-53b9-4132-8cf1-1894520eea00", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "24982706-85ac-42c3-97ac-b4a8c6592e5d", "node_type": null, "metadata": {}, "hash": "d5c45ace0f9088d500a2014a73f54c723c33c78d229de58c22119b217a1f15fc"}}, "hash": "47ab2481e4c96b3159b108a48444e6fa479edde6e0e83a7db8a40424292005bb", "text": "**Implementing \ud83d\udc4d\ud83c\udffb / \ud83d\udc4e\ud83c\udffb Feedback with `Python`**\n\n```py\nimport requests\n\nportkey_feedback_header = {\n    'x-portkey-api-key' : 'PORTKEY_API_KEY',\n    'Content-Type': 'application/json',\n}\n\nfeedback_data = {\n    'trace_id': 'REQUEST_TRACE_ID',\n    'value': 0, #For thumbs down\n}\n\nresponse = requests.post('https://api.portkey.ai/v1/feedback/', headers=portkey_feedback_header, json=feedback_data)\n```", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8d6f9167-7136-45fe-86ea-874654f8a1d8": {"__data__": {"id_": "8d6f9167-7136-45fe-86ea-874654f8a1d8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3b4440f3-9ce7-4247-adc0-9b23087c575e", "node_type": null, "metadata": {}, "hash": "f9b278271342632cce5dd3a5cac603b29de16d40d112a048f3228c4369f72d08"}}, "hash": "67d3bbeaa6cd79922908b88a6e2de83268e462fff8d881226fd02ca00442b064", "text": "**\ud83d\udda5\ufe0f Portkey Dashboard Guide**\n\nYou can see the `Feedback Count` and `Value: Weight` pairs for each `trace-id` on the logs page.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d57fd3e2-50f8-4227-bd65-546f59efac42": {"__data__": {"id_": "d57fd3e2-50f8-4227-bd65-546f59efac42", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "176eb101-e2ae-41b1-8a7b-450927351381", "node_type": null, "metadata": {}, "hash": "dc5dd4dbf693efa122637841bd845f19d9a3dfcd4b99fcd4dadd62c375379dc9"}}, "hash": "c4cc18e4537ee1313a0bd549df32bdfeaeea6cf5d8e5e5d2c308385b41e2f7e9", "text": "\ud83e\ude9d Load Balancing\n\nPortkey's Load Balancing feature is designed to efficiently distribute network traffic across multiple Language Model APIs (LLMs). This ensures high availability and optimal performance of your generative AI apps, preventing any single LLM from becoming a performance bottleneck.\n\nThe Load Balancing feature allows you to specify a list of Language Model APIs (LLMs) and a corresponding list of weights. Portkey will then distribute the requests among these LLMs based on the given weights.\n\n{% hint style=\"danger\" %}\n**Please note:** As of now, the Load Balancing feature is in beta. Please reach out to Portkey support, if you face any issues.\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f7439589-3c5b-41f2-bdcf-988d4a812554": {"__data__": {"id_": "f7439589-3c5b-41f2-bdcf-988d4a812554", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9d5e8ae6-6752-4f6a-8377-e72ad5638a9b", "node_type": null, "metadata": {}, "hash": "9ca3aea90c3b3880314590de3c16db821ff069f0ca95bd761b8cb3d044d8d5ab"}}, "hash": "34891771b09d9f81a51ed7ebe997bf73cfcb93107431b2bf7e6164ce1b72087c", "text": "Enabling Load Balancing\n\nTo enable Load Balancing, you can modify the `config` object of your `complete` or `chatComplete` API request to include the `loadbalance` mode.\n\nHere's a quick example to **load balance equally** between OpenAI's `gpt-3.5-turbo` and Anthropic's `claude-v1`\n\n```powershell", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f2221112-3449-44c6-bab6-aff75f7121e2": {"__data__": {"id_": "f2221112-3449-44c6-bab6-aff75f7121e2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "06260f5f-be7b-4e98-9fb3-4c99ea145024", "node_type": null, "metadata": {}, "hash": "d9f4b1627be78fed97105391f4eb8d3c41b5ef7c39c7268c913da5a5c481961a"}}, "hash": "dc8365fd5c1fa35f6f3d820dd028b1cb8617a56694fff78f533db74be5fe96b1", "text": "Load balance 50-50 between text-davinci-003 and claude-v1\ncurl --location 'https://api.portkey.ai/v1/chatComplete' \\\n--header 'Content-Type: application/json' \\\n--header 'x-portkey-api-key: ' \\\n--data '{\n    \"config\": {\n        \"mode\": \"loadbalance\",\n        \"options\": [{\n            \"provider\": \"openai\",\n            \"apiKey\": \"\",\n            \"weight\": 0.5,\n            \"override_params\": { \"model\": \"gpt-3.5-turbo\" }\n        }, {\n            \"provider\": \"anthropic\",\n            \"apiKey\": \"\",\n            \"weight\": 0.5,\n            \"override_params\": { \"model\": \"claude-v1\" }\n        }]\n    },\n    \"params\": {\n        \"messages\": [{\"role\": \"user\",\"content\":\"What are the top 10 happiest countries in the world?\"}],\n        \"max_tokens\": 50,\n        \"user\": \"jbu3470\"\n    }\n}'\n```\n\nHere's another example to load balance between **OpenAI and an Azure deployment**.\n\n```powershell", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8f8f5849-db4a-42d2-a0b0-6bf40c3b728c": {"__data__": {"id_": "8f8f5849-db4a-42d2-a0b0-6bf40c3b728c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7e21868e-ba9b-4380-a855-202521461f7f", "node_type": null, "metadata": {}, "hash": "408413b6d0a68efcc3f9907fe2f681f481cf225f0079c5f4a698b35e40dd3413"}}, "hash": "bed800ed6d86becc1ab160d89b8dfa4c7fb1fe7d8426e67b8dc5caa5f2d38cce", "text": "Load balance 70-30 between azure and openai\ncurl --location 'https://api.portkey.ai/v1/chatComplete' \\\n--header 'Content-Type: application/json' \\\n--header 'x-portkey-api-key: ' \\\n--data '{\n    \"config\": {\n        \"mode\": \"loadbalance\",\n        \"options\": [{\n            \"provider\": \"azure-openai\",\n\t    \"apiKey\": \"\",\n\t    \"resourceName\": \"\",\n\t    \"deploymentId\": \"\",\n\t    \"apiVersion\": \"\",\n\t    \"weight\": 0.7\n        }, {\n            \"provider\": \"openai\",\n            \"apiKey\": \"\",\n            \"weight\": 0.3\n        }]\n    },\n    \"params\": {\n        \"messages\": [{\"role\": \"user\",\"content\":\"What are the top 10 happiest countries in the world?\"}],\n        \"max_tokens\": 50,\n        \"user\": \"jbu3470\",\n        \"model\": \"gpt-3.5-turbo\"\n    }\n}'\n```", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3decb7da-8680-4271-9404-d06f8b3147c6": {"__data__": {"id_": "3decb7da-8680-4271-9404-d06f8b3147c6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "be7eb8e5-f387-49e6-986c-690078e6b936", "node_type": null, "metadata": {}, "hash": "4e0c57df8b4de8bcbaef304da6fce2699be958cd1d8dcd343782381c12b8585f"}}, "hash": "875d8a27359e69473f1ae3336dae6b488673e711cfbb3ec7636c8e567a4aaf82", "text": "Caveats and Considerations\n\nWhile the Load Balancing feature offers numerous benefits, there are a few things to consider:\n\n1. Ensure the LLMs in your list are compatible with your use case. Not all LLMs offer the same capabilities or respond in the same format.\n2. Be aware of your usage with each LLM. Depending on your weight distribution, your usage with each LLM could vary significantly.\n3. Keep in mind that each LLM has its own latency and pricing. Diversifying your traffic could have implications on the cost and response time.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6f354758-03bd-4f2c-9e7a-eca5fe771af9": {"__data__": {"id_": "6f354758-03bd-4f2c-9e7a-eca5fe771af9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aaf0c6f3-3762-4803-9d2c-0132320bbbe7", "node_type": null, "metadata": {}, "hash": "9ff9fab4db751c49645de89455625da610f71b921b348f846d407ade49348886"}}, "hash": "684de4861d32006a3fc3199027ee18a59904b1a01dfabb64faea8d39a9ccb269", "text": "\ud83d\udcca Logs & Analytics\n\nOne of the many advantages of integrating with Portkey is the detailed logs and analytics provided directly on the Portkey dashboard. Once your application is integrated with Portkey, this feature is enabled automatically, providing you with valuable insights into your application's usage patterns and performance.\n\nThis feature does not require any additional headers to be passed in your requests. As soon as the Portkey integration is done, all logs and analytics will begin to appear in the Portkey dashboard.\n\nThe Logs and Analytics section is split into two parts:", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5ee2bc36-14dc-48e6-8206-fa10b730ea42": {"__data__": {"id_": "5ee2bc36-14dc-48e6-8206-fa10b730ea42", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "978d0625-cc07-4571-bfe3-0186b76ce3d9", "node_type": null, "metadata": {}, "hash": "5dcbfadf1ecca523d7ab1a0c8bab459c21aec2e1f73a09ac0c5e6e4493776dc8"}}, "hash": "0c54f07d35809b7d65c39e1b73a3141a09216c6223a5ed642b59797772a3b05b", "text": "1. Analytics\n\nThe Analytics section of the Portkey dashboard provides a visual and interactive interface for understanding your LLM application  Here, you can see various graphs and metrics related to requests to different LLMs, costs, latencies, tokens, user activity, feedback, cache hits, errors, and much more.\n\nThe metrics in the Analytics section can help you understand the overall efficiency of your application, discover patterns, identify areas of optimization, and much more.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "519ee882-f657-417f-8a6f-bd72b5f78e43": {"__data__": {"id_": "519ee882-f657-417f-8a6f-bd72b5f78e43", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1e938a27-90ae-4c2b-9c1a-07e6f872155a", "node_type": null, "metadata": {}, "hash": "166a622da18b9518a93136ee8bc969546b4fd1e889e2092bd5e1a035114fe362"}}, "hash": "1e9a10f538d3c13693825030b76ccb1b396ee03ce6a202d4ae36acea8dc7aa0b", "text": "2. Logs\n\nThe Logs section presents a chronological list of all the requests processed through Portkey. Each log entry provides useful data such as the timestamp, request type, LLM used, tokens generated, and cost. By clicking on an entry, a side panel opens up, revealing the entire raw data with the request and response objects.\n\nThis detailed log can be invaluable when troubleshooting issues or understanding specific interactions. It provides full transparency into each request and response, enabling you to see exactly what data was sent and received.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "202f62ca-3ec0-4749-a3e0-73c17283baa5": {"__data__": {"id_": "202f62ca-3ec0-4749-a3e0-73c17283baa5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b7ffda72-c1af-4db3-9444-f6be67aa1cae", "node_type": null, "metadata": {}, "hash": "bef0c70f2ab51f0f37e56dcf285b0ad52c2de2933b0e411f5d6ded5e0bf99549"}}, "hash": "0c1d8147f0db56224b5872a9e1fc67afea27c029a568bc7aa5fa750f695b6a07", "text": "\u26a1 Prompt Management\n\nPortkey's Prompt Management is the user interface arm of the Managed Model feature, which allows you to define, save, and manage model prompts along with all of its parameters. It acts as a playground for you to try different combinations of parameters, see the output, and iterate on your prompts.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "07dc98ef-6c28-4888-96bb-1a4b79631956": {"__data__": {"id_": "07dc98ef-6c28-4888-96bb-1a4b79631956", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "705b6355-14b5-4f65-a675-8df3df6e5a93", "node_type": null, "metadata": {}, "hash": "a39766a9bd339b63437a5dd13ae63719a19c2c8a8c21a66963b1e21cf72ff5ab"}}, "hash": "740e075166c8def0939fdfe1a1441e9704eb9c14699722efcc044edbbd26321e", "text": "Setting Up AI Providers\n\nBefore you can create and manage prompts, you'll need to set up your AI providers. Under \"Settings\", in the \"Provider API Keys\" section, you need to save the respective provider's API Key. This key will enable the AI provider to be used in your prompt management. After saving the key, the respective AI provider can be used to run and manage prompts.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "238ff9fe-dac6-4210-ab02-ea813497d3b6": {"__data__": {"id_": "238ff9fe-dac6-4210-ab02-ea813497d3b6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8fa50a61-710c-4afd-8840-c3f3381797df", "node_type": null, "metadata": {}, "hash": "a54408ce6b87a506414a873fb6fcc6c299863cbbd275f2ac4dfb75681cc8a4ba"}}, "hash": "e93b1a5f63c0ee3b98062b4c91ad6cf60a1b6bac04462e5178303e946e444f32", "text": "Defining and Saving Prompts\n\nThe UI allows you to input your model prompt, set various parameters like model type, temperature, max tokens, and so on. Once you're happy with the prompt and its parameters, you can save it. Portkey's UI makes it easy for you to test and modify your prompts before saving.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2a4b99cc-c591-4ea2-b9e9-5a918f72e612": {"__data__": {"id_": "2a4b99cc-c591-4ea2-b9e9-5a918f72e612", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "24dd446e-eae0-42f8-9eda-28e3458bb578", "node_type": null, "metadata": {}, "hash": "7e49226ca395dd360d696dece841971f2fec0892c6f9d76482d69c6260e11839"}}, "hash": "790ec238b9f56ffe0e47a18de2d7ff8b67a1be4f162b552cbca263444db19d4a", "text": "Versioning of Prompts\n\nPortkey provides versioning of prompts, so any update on the saved prompt will create a new version. You can switch back to an older version anytime. This feature allows you to experiment with changes to your prompts, while always having the option to revert to a previous version if needed.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "37bbecbc-d030-430a-99a3-4af1b0884727": {"__data__": {"id_": "37bbecbc-d030-430a-99a3-4af1b0884727", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "da610f06-05fe-46f6-bf63-22501ba7af0e", "node_type": null, "metadata": {}, "hash": "69e9c3beda2adf873b444924e1596fe4255966db4abf35c40ffc6d12f40d9870"}}, "hash": "c06d2fbc73e616fde252bdbb062d49b2a784ce9a5224fc05714f6fe235146741", "text": "Prompt Templating\n\nPortkey supports variables inside prompts to allow for prompt templating. This enables you to create dynamic prompts that can change based on the variables passed in. You can add as many variables as you need, but note that all variables should be strictly string. This powerful feature allows you to reuse and personalize your prompts for different use cases or users.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c04489b6-4fdb-4da9-adbf-ddc0d06c2728": {"__data__": {"id_": "c04489b6-4fdb-4da9-adbf-ddc0d06c2728", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0c0963c2-7f45-4042-888a-9480b7f17784", "node_type": null, "metadata": {}, "hash": "a494d4adc91a960f949b08a2839b5b03585be50f7e77e75c54d8b55543b81a6b"}}, "hash": "0e84d038db07da5d1aea668797bc1485fa4ac4425665718b4e9f7632f501f0ec", "text": "API Endpoint for Saved Models\n\nFor each saved prompt, there is a tab called \"API\" which shows the API endpoint for the saved model. Users can directly call this API and pass the variables required in their prompt template. This makes it easy to integrate your saved prompts into your application or service.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c79b5fd6-c191-4690-8b2c-c726f518203d": {"__data__": {"id_": "c79b5fd6-c191-4690-8b2c-c726f518203d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4761dfb3-ae18-4e5c-852a-c3548477a115", "node_type": null, "metadata": {}, "hash": "d59792953cdeba1986724823fd1de8e625c65030ec112c1690aff2e663809829"}}, "hash": "36c0706b56e154f5230ba39ec4d9f069293fe20cc55021376f7264d192ba1b36", "text": "Few-Shot Prompting\n\nLLMs are highly capable of following a given structure. By providing a few examples of how the assistant should respond to a given prompt, the LLM can generate responses that closely follow the format of these examples.\n\nPortkey enhances this capability with the _raw prompt_ feature of prompt templates. You can easily add few-shot learning examples to your templates with _raw prompt_ and dynamically update them whenever you want, without needing to modify the prompt templates!", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5bd6939c-819a-4493-af8d-68dd236485a3": {"__data__": {"id_": "5bd6939c-819a-4493-af8d-68dd236485a3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5b70fabd-409d-4e3b-aa8f-14f81ff6d65a", "node_type": null, "metadata": {}, "hash": "3cd06d9706be8d117604d1543d048db6ac847ba82cc78cfa604d19ef194d839f"}}, "hash": "79decbcb8fe8d931f1866a84c611a10416e0b0e2a151ea7132e551abac805e73", "text": "How does it work?\n\nLet's consider a use case where, given a candidate profile and a job description, the LLM is expected to output candidate notes in a specific JSON format.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e0d7f6db-080c-4fe0-b843-9fa8d84b4b62": {"__data__": {"id_": "e0d7f6db-080c-4fe0-b843-9fa8d84b4b62", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "cc48af09-46e0-49f4-b5c2-87ff02466785", "node_type": null, "metadata": {}, "hash": "eb241f507c2dde2a45dbdafd0cc0cb7b342410625edfeed27fe211ef0b29e8bd"}}, "hash": "071acdda846c6ba2c63b17d5e23864b08973e2495fdeda2c9c01722cdcc7128a", "text": "This is how our raw prompt would look:\n\n{% code overflow=\"wrap\" fullWidth=\"false\" %}\n```json\n[\n    { \n        \"role\": \"system\", \n        \"message\": \"You output candidate notes in JSON format when given a candidate profile and a job description.\",\n    },\n    {{few_shot_examples}},\n    {\n        \"role\": \"user\",\n        \"message\": \"Candidate Profile: {{profile}} \\n Job Description: {{jd}}\"\n    },\n]\n```\n{% endcode %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "894bde9d-eafe-44a8-9367-b3099157fbcb": {"__data__": {"id_": "894bde9d-eafe-44a8-9367-b3099157fbcb", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "53962387-3b3c-446b-ab21-cacf504125b9", "node_type": null, "metadata": {}, "hash": "1a7e63f6261af5e185868672ae868db1fca2de25b682748f30ae09b69abb4ad1"}}, "hash": "8140e527a96831295d71999867f5974980a430f8afd4ca5d7227822b5e19994a", "text": "Let's define our variables:\n\nAs you can see, we have added variables `few_shot_examples`, `profile`, and `jd` in the above examples.\n\n```\nprofile = \"An experienced data scientist with a PhD in Computer Science and 5 years of experience working with machine learning models in the healthcare industry.\"\njd = \"We are seeking a seasoned data scientist with a strong background in machine learning, ideally with experience in the healthcare sector. The ideal candidate should have a PhD or Master's degree in a relevant field and a minimum of 5 years of industry experience.\"\n```", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1f03a7b6-28ee-4fcd-982c-9a9422754a8c": {"__data__": {"id_": "1f03a7b6-28ee-4fcd-982c-9a9422754a8c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "96e9b347-9800-47eb-9399-a007f8745435", "node_type": null, "metadata": {}, "hash": "28d6242c15af974c9e7340ebb44fffe7095d0b3c036b8947ecf8cbbb2201e238"}}, "hash": "28b7027bf02dc46da86d027a2c3f38b9acaa1ce37f2aee617343e89f1bb7beeb", "text": "And now let's add some examples with the expected JSON structure:\n\nfew_shot_examples = \n[\n {\n  \"role\": \"user\",\n  \"content\": \"Candidate Profile: Experienced software engineer with a background in developing scalable web applications using Python. Job Description: We\u2019re looking for a Python developer to help us build and scale our web platform.\",\n },\n {\n  \"role\": \"assistant\",\n  \"content\": \"{'one-line-intro': 'Experienced Python developer with a track record of building scalable web applications.', 'move-forward': 'Yes', 'priority': 'P1', 'pros': '1. Relevant experience in Python. 2. Has built and scaled web applications. 3. Likely to fit well with the job requirements.', 'cons': 'None apparent from the provided profile.'}\",\n },\n { \n  \"role\": \"user\",\n  \"content\": \"Candidate Profile: Recent graduate with a degree in computer science and a focus on data analysis. Job Description: Seeking a seasoned data scientist to analyze large data sets and derive insights.\"\n },\n {\n  \"role\": \"assistant\",\n  \"content\": \"{'one-line-intro': 'Recent computer science graduate with a focus on data analysis.', 'move-forward': 'Maybe', 'priority': 'P2', 'pros': '1. Has a strong educational background in computer science. 2. Specialized focus on data analysis.', 'cons': '1. Lack of professional experience. 2. Job requires a seasoned data scientist.' }\"\n  }\n]\n\n\nIn this configuration, `{{few_shot_examples}}` is a placeholder for the few-shot learning examples, which are dynamically provided and can be updated as needed. This allows the LLM to adapt its responses to the provided examples, facilitating versatile and context-aware outputs.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "324cc595-857f-45ca-8360-4233190e025e": {"__data__": {"id_": "324cc595-857f-45ca-8360-4233190e025e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3d2ed38b-83b4-463c-879d-4848c17b90ea", "node_type": null, "metadata": {}, "hash": "1db4e3efc845aad285871a357c080b3606e2a8dbce1800e9a983b33981586006"}}, "hash": "928368eef6e0d7774e486f90ca82a9893665ff2c79269af096c3dad24e02ac1e", "text": "Putting it all together in Portkey's prompt manager:\n\n1. Go to \"Models\" page on https://app.portkey.ai/ and **Create** a new prompt template with **AI org** as OpenAI and **Mode** as Chat.&#x20;\n2. Selecting Chat mode will enable the Raw Prompt feature:\n\n\n\n3. Click on it and paste the raw prompt code from above. And that's it! You have your **dynamically updatable** few shot learning prompt template ready to deploy.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9476e54d-0429-4847-ab4c-b9c5ccf8a46e": {"__data__": {"id_": "9476e54d-0429-4847-ab4c-b9c5ccf8a46e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "86157561-6dd2-4a14-9bf9-b8e8b375e3d7", "node_type": null, "metadata": {}, "hash": "3e0cf9f85abdf1d6f5b938439af5ade12daa49bcfaa7ed522e1a32908227cfd0"}}, "hash": "0467884e846a6b8a5ca5cfb8cfa873c31d214204a376391f35dac93b58f58b55", "text": "Deploying the Prompt with Portkey\n\nDeploying your prompt template to an API is extremely easy with Portkey. Head over to the API tab and copy the code. It will look something like this:\n\n```javascript\naxios.post('https://api.portkey.ai/v1/prompts//generate', {\n  \"variables\": {\n    \"few_shot_examples\": \"\",\n    \"profile\": \"\",\n    \"jd\": \"\"\n  }\n},{\n  \"headers\": {\n    \"x-portkey-api-key\": \"\"\n  }\n}) \n```\n\nYou can pass your dynamic few shot learning examples with the `few_shot_examples` variable, and start using the prompt template in production!", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "99bfb10e-ac7d-4e16-999b-164541594b80": {"__data__": {"id_": "99bfb10e-ac7d-4e16-999b-164541594b80", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4e1c9e4b-560f-464c-b90d-d1075a93d7bd", "node_type": null, "metadata": {}, "hash": "3dff0ae660a39feff1573f9922effcf16c50eeb79b404589a73bd52d96c472e3"}}, "hash": "9b5be0eafb698dea57250fca3677f035da0cd22eb66414e3f8f9268e4fa65ab1", "text": "Detailed Guide on Few-Shot Prompting\n\nWe recommend this guide detailing the research as well as edge cases for few-shot prompting.&#x20;", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5b7ed734-84ff-4de2-9e39-02b5c164a55d": {"__data__": {"id_": "5b7ed734-84ff-4de2-9e39-02b5c164a55d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f65ae39d-cc22-4635-bafc-8e425f8d82df", "node_type": null, "metadata": {}, "hash": "db73eb348311d82134814abdbf117feb9a8719687a8e4a6b20b6e898f0942d9e"}}, "hash": "5208a0d9bcd8d391c9c1194b5ddfe9888ac52c9edc528afa3fe142064c5ef39f", "text": "Support\n\nFacing an issue? Reach out on support@portkey.ai for a quick resolution.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "325f3751-529b-4fec-a588-9240fcc269e8": {"__data__": {"id_": "325f3751-529b-4fec-a588-9240fcc269e8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a72ef4a7-876d-4f9e-8bb5-451205468c25", "node_type": null, "metadata": {}, "hash": "cfeecafd1736ec91e5d865a32872da6420cf0d76b5f6e4d66ab611e0840ff467"}}, "hash": "c16f291827be0ed14cb6d31fe0a5001f7115395102bbd11d64d7e60f8638d141", "text": "\ud83d\ude80 Request Caching\n\nIn the quest for enhancing performance and optimizing response retrieval, Portkey offers two unique types of caching - Fixed String Matching Cache (Simple Cache) and Semantic Cache.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "03aa987c-e625-4aec-b25f-0857d9200065": {"__data__": {"id_": "03aa987c-e625-4aec-b25f-0857d9200065", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f108b656-0942-4bdb-aa15-147e155bcabe", "node_type": null, "metadata": {}, "hash": "dcf9dd34ae610fdc0cfcf6d86a74946d8ba643e4425c311b6533dd75f8fbd012"}}, "hash": "51e63fa097bf3f1a5501ff66ec57f1724895f3f68f9faebebd3984a6a37de0aa", "text": "Fixed String Matching Cache\n\nFixed String Matching Cache, also known as a simple cache, performs an exact match on the input prompts. If the exact same request is received again, Portkey retrieves the response directly from the cache, bypassing the model execution. This approach is straightforward and effective for repeated identical requests.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "dd9ae3d1-9ac1-488c-b824-1b32a32577ed": {"__data__": {"id_": "dd9ae3d1-9ac1-488c-b824-1b32a32577ed", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9cf70eb0-ad15-4132-bd17-885ae901cac8", "node_type": null, "metadata": {}, "hash": "097e4bcf7d8b13b84c860f3e7bdb3f9ef831e2d8b440e33f94e940c8675d23a3"}}, "hash": "b2097e96a6a7304775e8173790d3561d395758f908071e498a1b0f1ab01b8970", "text": "Enabling Fixed String Matching Cache\n\nTo enable this cache, include the following headers in your requests:\n\n```json\n{\n    \"x-portkey-cache\": \"simple\"\n}\n```", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "352067db-0ab3-4203-a0f8-a410b6a87035": {"__data__": {"id_": "352067db-0ab3-4203-a0f8-a410b6a87035", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b524c727-3cf8-4da2-96d6-f6e24845ae2c", "node_type": null, "metadata": {}, "hash": "ce332d0a85d2f9e6144da3f87854bcf8006241043ef092bb7a8c9dc596b17901"}}, "hash": "12d8946419e3bfc04cb4c6335e401460bd4c5e070bd08171fdd93cd7c0967c82", "text": "Semantic Cache\n\nPortkey's Semantic Cache extends beyond exact string matching. This advanced caching mechanism considers the contextual similarity between input prompts. It uses cosine similarity to ascertain if the similarity between the input and a cached request exceeds a specific threshold. If the similarity threshold is met, Portkey retrieves the response from the cache, saving model execution time.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ced33566-3104-449d-b02c-99184f97aeeb": {"__data__": {"id_": "ced33566-3104-449d-b02c-99184f97aeeb", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bd593e76-48d0-4dd3-b561-00acf3774855", "node_type": null, "metadata": {}, "hash": "2f70f13a55031125cedb8830ed220752db10050df52078c971cb77a259d2a4b2"}}, "hash": "ab26a5d46808caac319254678dbc9329d5e93c0f4ee613b534e98288ae0a2a04", "text": "Enabling Semantic Cache\n\nTo enable the Semantic Cache, use the `x-portkey-cache` header in your requests, and set it to `semantic`.\n\n```json\n{\n    \"x-portkey-cache\": \"semantic\"\n}\n```\n\n\n\n**Cache TTL**\n\nThe `Cache-Control` header specifies the maximum age of the cached response in seconds. If the `Cache-Control` header is not provided, Portkey automatically caches requests for 604800 seconds (7 days). Minimum max-age allowed is 60 seconds.\n\n```json\n{\n    \"Cache-Control\": \"max-age=1000\"\n}\n```", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ccb540b8-d20b-4663-b141-995ac3bf2ecc": {"__data__": {"id_": "ccb540b8-d20b-4663-b141-995ac3bf2ecc", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e1a6c8c7-cc88-4e8f-bb8c-243799aebc29", "node_type": null, "metadata": {}, "hash": "88752cdcfce4591f22c6a82fd79e079c9cd1ea60443b70802e75b61daee6ff9e"}}, "hash": "b217ef2a9e8084a3478b831a8e5f5be9988368240db51499deb2c3dc6d1667a9", "text": "Invalidating Fixed String Matching Cache\n\nIf you need to force a cache refresh, use the `x-portkey-cache-force-refresh` header. Setting this to `true` ensures the cache is invalidated, and a new value is stored in the cache.\n\n```json\n{\n    \"x-portkey-cache-force-refresh\": true\n}\n```\n\nBy using Semantic Cache, you can optimize the caching process by considering the contextual similarity of input prompts, leading to more efficient response retrieval.\n\nChoosing the right caching mechanism based on your specific use case can greatly enhance performance and minimize unnecessary model executions, making Portkey an effective tool for managing your Generative AI applications.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "55c176fd-634f-4495-8a72-161154af928e": {"__data__": {"id_": "55c176fd-634f-4495-8a72-161154af928e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f3473ea0-1f2c-4e67-8efb-fdfc58dab74f", "node_type": null, "metadata": {}, "hash": "b49313231efb9b1eab85742fd4879996c588d8f66abe026852c7ef85c4058904"}}, "hash": "eea8fb6d41f5363ed2483b452106ff78284faab746cd58275a24f42abcaecaea", "text": "**\ud83d\udda5\ufe0f Portkey Dashboard Guide**\n\nSimple cache hits will show up as **\"HIT\"** & semantic cache hits will show up as **\"SEMANTIC HIT\"** on your Portkey logs. We also calculate and show the response time and how much money you saved with each hit.\n\nSee cache status directly on your Portkey logs\n\nEach log also shows the response time for cache hit", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "663c29f8-ba22-4422-9906-22b39ea30d3e": {"__data__": {"id_": "663c29f8-ba22-4422-9906-22b39ea30d3e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2c9b2e2a-f464-43f5-8c41-8f69c2f6033e", "node_type": null, "metadata": {}, "hash": "cd3fe8cbe547f1f7075cb3f0b876de2ccb0ca06e199d331156dca13350fce092"}}, "hash": "28832e19ffdd9c7eda2e12de6f83a3f2ee55621157400b9f592e3b021fb92580", "text": "\u23ee Request Tracing\n\nHaving end-to-end visibility of your requests is crucial. Portkey supports request tracing to help you monitor your applications throughout the lifecycle of a request.\n\nTo enable tracing, you can pass a `trace-id` in the header of any request made via Portkey. This trace ID will be associated with the journey of the request, from initiation to completion, providing insights into the entire process.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "34aac729-477d-4c8d-b833-11b53bb44ca2": {"__data__": {"id_": "34aac729-477d-4c8d-b833-11b53bb44ca2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38467dda-af5e-44ec-b279-59183b7c27e1", "node_type": null, "metadata": {}, "hash": "a9478112311dc22e2ed202e6122de6c9e09bbd7b2bbb863779313f2ad6c39d02"}}, "hash": "d9d281084bc02563a7d7532090c37f6bd697ce8fc39654655f10aabf390662aa", "text": "How to Enable Request Tracing\n\nTo enable tracing, include the `x-portkey-trace-id` in your request header.\n\n```javascript\n{\n    \"x-portkey-trace-id\": \"\"\n}\n```", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "05ddfff9-d2a5-4972-bba3-0837fda91359": {"__data__": {"id_": "05ddfff9-d2a5-4972-bba3-0837fda91359", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d0c163a5-9633-44e2-a3f3-448fd7cf231e", "node_type": null, "metadata": {}, "hash": "7802dc0f655e971ba86825db6b9873515301c44f650c302f422c34cc553f2c79"}}, "hash": "c754007fe04edae7d7085c4ccf1c16d437d9cf773d3f88f94e6684452da4ec9f", "text": "Tracing and User Feedback\n\nTrace IDs can also be used to link user feedback to specific generations. This can be used in a system where users provide feedback, like a thumbs up or thumbs down, or something more complex via our feedback APIs. This feedback can be linked to traces which can span over a single generation or multiple ones.\n\nYou can read more about implementing user feedback in Portkey here.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8516a98f-dd9f-4b63-80fd-c2bd1a26ff9e": {"__data__": {"id_": "8516a98f-dd9f-4b63-80fd-c2bd1a26ff9e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b670af70-1630-4f47-a3bc-6dab9c2a37dd", "node_type": null, "metadata": {}, "hash": "fa0b32c3d6112c6415e5fb5f6bb7c7078aa50134aa48f4f781ecf23419c7b299"}}, "hash": "218fc2f0ddc6e10ddabff81a944ca917f6d1f9979ea112dde113c2cd0c08a4b2", "text": "**\ud83d\udda5\ufe0f Portkey Dashboard Guide**\n\nYou can view all the requests with a common `trace-id` easily on the logs page.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "86f26d9b-997a-4ac5-9ac4-18f4879e6538": {"__data__": {"id_": "86f26d9b-997a-4ac5-9ac4-18f4879e6538", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b46bee36-9570-442d-9993-fd84ea983d3d", "node_type": null, "metadata": {}, "hash": "dd1ce3243b9b860e407bacd7d48d4611b6d884271677c92275517fcffe9507cd"}}, "hash": "f21bc86a91fe6e484faab2f4c0cee6563177323d1d5a060e6fa6695e5328bb71", "text": "\u2728 Features Overview\n\n* **Request Tracing**: Monitor the journey of your requests to identify potential issues and bottlenecks.\n* **Caching**: Improve your application's response time and LLM costs with Simple and Semantic Cache.\n* **Custom Metadata**: Filter through logs with custom metadata for better insights.\n* **Automatic Retries**: In case of an LLM failure, Portkey automatically retries to ensure uninterrupted service.\n* **Fallbacks on LLMs**: In case of failures, Portkey can automatically switch to a fallback LLM.\n* **Load Balancing**: Distribute network traffic efficiently across multiple LLMs or multiple API Keys to ensure high availability and reliability.\n* **Observability****:** Gain deep insights into the performance and health of your AI applications. Monitor tokens, cost, latency for each LLM request.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0ebde556-153e-40a3-977b-b2c29acdd741": {"__data__": {"id_": "0ebde556-153e-40a3-977b-b2c29acdd741", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9ac93175-0006-4ce3-90d7-2507a4e86108", "node_type": null, "metadata": {}, "hash": "a86689939adc1bd9a0a38f664164c8d7fc09812a222fc3a7b57b6fa66fa35587"}}, "hash": "e7404b7b1a93cf8b939fc28e9fa795c88ecd95019686aee01f3bd413359c1136", "text": "\u2139 Introduction\n\nPortkey is a platform designed to streamline the deployment and management of Generative AI applications. It provides comprehensive features for **monitoring**, **managing models**, and **improving the performance** of your AI applications.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b993d1b0-3ff7-419e-9062-cdc8f03212de": {"__data__": {"id_": "b993d1b0-3ff7-419e-9062-cdc8f03212de", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4059bd20-22f9-416f-afdc-298c74db92a7", "node_type": null, "metadata": {}, "hash": "d9b10e6bba050b2ddd89942c46ac6e2002098c0f416b82f9a84a6a104acd88c5"}}, "hash": "a84863118ffe0bbf05598e38d70ffef045f60f7c0a4cff7fcc6003771c1dd806", "text": "Product Introduction\n\nPortkey leverages a cutting-edge LLMOps stack to launch production-ready applications. It aims to optimize your AI application's performance with critical components like monitoring and model management. It also includes other essential features such as **Request Tracing**, Request **Caching**, **Automatic Retries** in case of LLM failure, Custom **Metadata**, **Fallbacks** on LLMs, **Load Balancing,** and **more**.\n\nMoreover, Portkey ensures compliance with GDPR, SOC2 and ISO standards, making it a reliable choice for businesses.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "10d1d9c5-972f-4791-bacc-27cbd7d13bf0": {"__data__": {"id_": "10d1d9c5-972f-4791-bacc-27cbd7d13bf0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "57f564f7-c3aa-4562-b2c4-e886a2dcdb53", "node_type": null, "metadata": {}, "hash": "6201f0c75fc35a7ffd50c7cea624c186e4c66da5995461b9d169b807fdf6fd9a"}}, "hash": "f8b27b6f8e4eef0af0dce3b70601ad1e42f31d2910dce71b95ae1cbf82ee3426", "text": "\u2049 Common Errors and Resolutions\n\nWhile using Portkey, you may encounter various types of errors. An essential part of troubleshooting is to accurately identify the source of the error.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "39009157-471d-48cd-a9b5-eaa31b5f6da2": {"__data__": {"id_": "39009157-471d-48cd-a9b5-eaa31b5f6da2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "61fa05b9-975c-4b4b-9667-7e3489e10f9f", "node_type": null, "metadata": {}, "hash": "75b2edcbe4317cd853824de73dc5c7444751257bce9d176fd0fc92b2cc9f006a"}}, "hash": "ccb33730cd6359c372dcc6e09fdfc5b5b948e1e5f729ec6a3eeed8202323baff", "text": "Identifying Source of Error\n\nErrors can originate either from the Portkey platform itself or from the Language Learning Models (LLMs) provider. **To make this distinction, remember that any error originating from Portkey is prefixed with \"Portkey Error:\".** If you encounter an error message without this prefix, it is likely that the error has occurred at the LLM provider's end.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "aa2d68ef-16a9-46fd-8a27-2c9d9cbd9ca8": {"__data__": {"id_": "aa2d68ef-16a9-46fd-8a27-2c9d9cbd9ca8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "19810c6a-0868-4938-ab54-f3b5cc53c9ce", "node_type": null, "metadata": {}, "hash": "fd557cbe5ba07833de7287a3525df993e85477daaebdb4c895641ef89494080c"}}, "hash": "c4b869ea7d7407cb04952fa5ff6abdbee34662d0e06b881a1f79e94ceda770f8", "text": "Troubleshooting Tip for Middleware Mode\n\nIf you are facing issues specifically when using the middleware mode, a good troubleshooting step would be to try running the same request without Portkey. If the request executes successfully without Portkey, then the error is likely due to the integration with Portkey.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "954ff2a0-1196-42f1-983e-6efcdd5d7524": {"__data__": {"id_": "954ff2a0-1196-42f1-983e-6efcdd5d7524", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2641fbb-61a7-42a5-836a-171a1b20435f", "node_type": null, "metadata": {}, "hash": "a0523de28d90a7f8ab02524756c161f31e172f1d4bd148a06f2f2ab19ef052d7"}}, "hash": "faffd7a6f994952ba43371a96d1568a1df4cd3736e697878c165b2d9449db54f", "text": "Common Portkey Errors\n\nWhile the nature of errors could be quite diverse, we'll focus on a couple of common errors that users encounter:\n\n1. **Errors related to Missing Mandatory Headers**: This is a common error where certain mandatory headers might be missing from the request. Make sure that all the necessary headers as specified in the respective feature documentation are included in your requests.\n2. **Errors related to Invalid Header Values**: At times, an incorrect or unsupported value might be passed in a header, causing this error. Cross-check the values provided against the allowed ones mentioned in our documentation.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a0867702-90de-4456-9599-a95f45e14a5a": {"__data__": {"id_": "a0867702-90de-4456-9599-a95f45e14a5a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "cb5857cd-adf9-465f-945d-b7b30c423cb8", "node_type": null, "metadata": {}, "hash": "c037684158751c528e889576efaec5113639fbdef5ce04835f2f3a8d6799d5a5"}}, "hash": "5d83386ff7970ce55b55045d63bba809d29301c0cfa683da1423081e8b47b523", "text": "\ud83d\udce7 Contacting Support\n\nWhen you need assistance with Portkey, whether it's troubleshooting an issue, clarifying documentation, or requesting new features, our support team is here to help. Here are the ways you can reach us:", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ff1d4027-9bf3-4f0d-ab35-23519d1a6d02": {"__data__": {"id_": "ff1d4027-9bf3-4f0d-ab35-23519d1a6d02", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "51a81a72-5799-476e-b148-44c937a06617", "node_type": null, "metadata": {}, "hash": "d34918f0c46dd2e88214df391cdee4006896cd73b0ae2c5142cb09f53e40b56c"}}, "hash": "195bab2a7ea87ae4d7f396e4f61c8a875f26667702248622f117a9c9f760ce19", "text": "Email Support\n\nThe easiest way to get in touch with us is via email. You can send your queries to **support@portkey.ai**. Please make sure to provide as much context as possible about your issue, including any error messages, screenshots, and steps to reproduce the issue. The more information you provide, the easier it will be for us to assist you.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "468749e8-6f0d-4163-b757-b73cc4c4d015": {"__data__": {"id_": "468749e8-6f0d-4163-b757-b73cc4c4d015", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1fdd6e9a-5056-478f-b748-9ea0a81b8a10", "node_type": null, "metadata": {}, "hash": "f9c90aabe1c507fb6b80f716c2ae822a3abeca1d3c17cf5385f557aaaef4f7ef"}}, "hash": "45b3ccdb4e09f2414aedb38277ef398d0f7298126f16b51b130577a378648853", "text": "\ud83d\udce5 Reporting Issues\n\nDespite your best troubleshooting efforts and our own testing efforts, there may be times when you come across an issue that isn't resolved. When this happens, it's time to report the problem to our Portkey support team. Here's a quick guide on how to do this effectively:", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c1f85d04-22fd-4ba1-8aba-a6b59f6c83bf": {"__data__": {"id_": "c1f85d04-22fd-4ba1-8aba-a6b59f6c83bf", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fd442994-cc71-4b2a-a933-6d3865192a74", "node_type": null, "metadata": {}, "hash": "58e6e54db37f16e3704fedba404a5e97d00a6c50944e075954d6c091774cdcf9"}}, "hash": "15d68bf724381b4be87d74b2dd9ed1925f215172ed167335153de727a20861e8", "text": "1. Gather Relevant Information\n\nTo help our team address your issue swiftly and accurately, please gather as much of the following information as possible:\n\n* **Description of the issue**: Include any error messages you are seeing and describe the behavior you're experiencing and how it differs from your expectations.\n* **Steps to reproduce the issue**: Provide clear steps on how we can reproduce the issue on our end.\n* **Code Samples**: If possible, share code snippets that are causing the error. Ensure you've removed any sensitive data before sharing.\n* **Request and Response Data**: If applicable, include the request you're making and the response you're receiving. Ensure any sensitive data is redacted.\n* **Screenshots or Screen Recordings**: Visuals can help us understand and diagnose issues faster. If possible, include screenshots or screen recordings.\n* **Environment Details**: Share details about your environment. For example, are you using a specific programming language or library? What's the version? Are you seeing the issue in all environments (development, production, etc.)?", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a7903ec9-eeff-4e56-8ee4-4f91c7fe78ab": {"__data__": {"id_": "a7903ec9-eeff-4e56-8ee4-4f91c7fe78ab", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "77db2ca6-b087-4cab-93b3-6004dbe062ec", "node_type": null, "metadata": {}, "hash": "e657c54399b6f392b31f4fc858cff8ee0088b0e8f521d10fc214d78403e54d80"}}, "hash": "b83d53d49066b28cc7e77b7e8b59215790b2a4241cd74682ba201a95e483f622", "text": "2. Contact Our Support Team\n\nOnce you've gathered this information, it's time to reach out to our support team. You can contact us through the following channels:\n\n* **Email**: You can email us at support@portkey.ai.\n* **Github**: If you're using one of our open-source projects and believe the issue lies there, you can create an issue directly on the relevant Github repository.\n* **Enterprise Customers** can directly reach out to our team via slack connect.\n\nWhen describing your issue, please be as detailed as possible. Include all of the information you gathered in step 1. The more details you provide, the easier it will be for us to understand and resolve your issue.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7eef4428-ca99-44e4-aecb-546a397e51a5": {"__data__": {"id_": "7eef4428-ca99-44e4-aecb-546a397e51a5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "49ef36e9-1c50-4ae2-a637-6f1c4a417970", "node_type": null, "metadata": {}, "hash": "e1c2e70fd6a31e4c3dafb706d8f5565cd6b22be5ef26e7fb12341668455aae01"}}, "hash": "2efe225a4bcfd2b4e630f6f018d19c4c542d451345e2395eb05d0110d68b1586", "text": "3. Await Our Response\n\nAfter you've submitted your issue, please be patient as we investigate. We understand that dealing with technical issues can be frustrating and we appreciate your understanding. We aim to respond to all inquiries as quickly as possible and will work with you until your issue is resolved.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8eebda44-6dd5-4a4f-9a23-43113ad2e27d": {"__data__": {"id_": "8eebda44-6dd5-4a4f-9a23-43113ad2e27d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d6df3a02-605e-41f1-aa46-38afa2349f49", "node_type": null, "metadata": {}, "hash": "fc9bea4e98a38fb4d2ac09770a304d306af608799c63567787374bba5622e9a0"}}, "hash": "d797f3930c80317f26b7f4f07b8d2ba82da846b238d7a276c21003c3e9c7e4a0", "text": "\ud83d\udeab Hide PII form LLMs\n\nWhen working with Large Language Models (LLMs), it's crucial to respect and protect users' Personal Identifiable Information (PII). Often, users may unknowingly or unintentionally input PII into a prompt, which is then sent to the LLM for processing. This information can include names, addresses, contact details, and more. Sending such data directly to the LLMs for processing can present serious privacy and compliance issues.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "99a7825e-5144-4be4-908c-df1c76b96807": {"__data__": {"id_": "99a7825e-5144-4be4-908c-df1c76b96807", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d975c688-3148-4d04-b3b5-0178dab9adae", "node_type": null, "metadata": {}, "hash": "7226cb1a54a785b102c151dab4f292b215008fa57014756f94d6d1a1c6c59b64"}}, "hash": "a2d1033a0f003daa3e67d1a94661c44830a6e9f353a5318ee701ddb65ca23e6f", "text": "The Solution: Portkey's Redaction Engine\n\nPortkey provides an effective and efficient solution to this challenge with its redaction engine. This powerful tool preprocesses requests, identifies potential PII within the prompt string, and redacts it before the request is sent to the LLM.\n\nThis way, the information processed by the LLM never contains any personal data, helping ensure user privacy and maintain compliance with data protection regulations.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7698812d-4bd2-45f8-82fd-1212f7597c4f": {"__data__": {"id_": "7698812d-4bd2-45f8-82fd-1212f7597c4f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3cd81b77-ab85-41ec-9c79-9fb3cc86cf25", "node_type": null, "metadata": {}, "hash": "1f979bc0903bbf3d19be9b5424ce542431757474277881ba2949af326d9960cc"}}, "hash": "ad7b36579c95a8842f4a665945eafa84786ec7189edc831bde7d28649181ffc2", "text": "How the Redaction Engine Works\n\nThe redaction engine employs advanced pattern recognition and machine learning techniques to identify PII within the user's input. It can recognize a variety of PII types, including:\n\n* Names\n* Addresses\n* Phone numbers\n* Email addresses\n* Social Security numbers\n* Credit card numbers\n\nOnce potential PII is identified, the engine replaces it with generic placeholders, effectively \"redacting\" the sensitive information from the prompt. The redacted prompt is then passed to the LLM for processing, ensuring that no PII ever reaches the LLM.\n\n\n\nWith Portkey's redaction engine, you can significantly enhance the privacy and security of your generative AI applications. By ensuring that no PII is sent to the LLM, you can maintain user trust, achieve regulatory compliance, and avoid potential data breaches.\n\n{% hint style=\"info\" %}\n**Please note:** that PII redaction is currently a custom enterprise features. If you're interested in deploying it, reach out to our support team for a discussion.\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5f1094d6-90d6-49c7-8484-e15b969db0b3": {"__data__": {"id_": "5f1094d6-90d6-49c7-8484-e15b969db0b3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0ba565cf-c482-4ae1-a6be-fee70ec18d8c", "node_type": null, "metadata": {}, "hash": "9a24a2ed3f3fd2a2c2adb6c615b8be8dc07cfaca30062bc19e3c713a73e9e427"}}, "hash": "595dacd9212f22e67518e6a937def4a48fdb1dcb1c62f6a655bf912155be9596", "text": "\u26c5 Improve LLM success rate\n\nWorking with Large Language Models (LLMs) often presents unique challenges. When dealing with LLMs at scale, you may encounter various operational issues. These might include:\n\n1. **Timeouts:** A request to an LLM may not receive a response within the expected timeframe, causing a timeout.\n2. **Rate Limiting Errors:** When the number of requests from a specific source exceeds the limit defined by the LLM provider, it results in rate limiting errors.\n3. **Random 500s:** Server-side issues can cause random 500 error responses, disrupting the service flow.\n\nThese issues pose significant challenges for businesses and developers relying on LLMs for their operations.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2ffc7478-010d-486e-acd0-c3e3ba904b5c": {"__data__": {"id_": "2ffc7478-010d-486e-acd0-c3e3ba904b5c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7536941f-493f-4b78-ac96-25be7855a2ea", "node_type": null, "metadata": {}, "hash": "56b32b0417391c990c829c618b3b1a4dc62e3d499ba171d1398ac018720e61c2"}}, "hash": "a4671d8849d9c7fd4e6ba35c98a2da4e185dc90162b1ce458cb3b47eeb5eb108", "text": "The Solution: Portkey's Automatic Retries\n\nPortkey provides a powerful feature to combat these challenges \u2013 automatic retries. By implementing this, Portkey will automatically retry failed requests, applying exponential backoff between retries to distribute the load and avoid hammering the server, thus increasing the chances of request success.\n\nThe implementation of automatic retries can have a dramatic impact on the success rate of your LLM requests. Our data has shown that by using this feature, you can see up to a 30% reduction in rate limit errors, timeouts, and random 500s.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "70311f0c-16e4-4954-91dc-ba07d364b7ba": {"__data__": {"id_": "70311f0c-16e4-4954-91dc-ba07d364b7ba", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4ef6c73e-70af-45ee-a8a2-31a490be96b1", "node_type": null, "metadata": {}, "hash": "a9a8bbdc294eb07b7ba70f7ee642a1eea8f8b3fc6158ce587ce851ccf572584c"}}, "hash": "8596e7cf537395f86b9ae6ebd702b9ace0655cd7840ac470049684626202ede9", "text": "\ud83c\udfad Lower Cost & Latency\n\nThe operational expenses associated with Large Language Models (LLMs) can quickly escalate as the number of requests and scale of operations increase. Similarly, with the growing scale, ensuring rapid response times to maintain a smooth user experience is critical. Portkey offers comprehensive caching capabilities that directly address these challenges, aiding in reducing costs and minimizing latency.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "42963d8c-7fff-4167-81cc-8228376ba834": {"__data__": {"id_": "42963d8c-7fff-4167-81cc-8228376ba834", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5bea2810-f0c6-491b-b964-19f7e7b957d3", "node_type": null, "metadata": {}, "hash": "eff58b5617b567ea97e06b1bb7c05169584223491e37bbcca89674af38b680a9"}}, "hash": "d82d91a5a101c96c909bffee5b677e944f82302cfe3961c8cac35e779f215ae9", "text": "Impact of Caching on Cost and Latency\n\nCaching plays a significant role in controlling the costs associated with LLMs. Our statistics have shown that using Portkey's caching mechanism, you can achieve up to 5% cost savings with Fixed String Matching Cache and up to 20% savings with Semantic Cache.\n\nHere's why:\n\n1. **Reduced Redundant Requests:** Many application scenarios, especially in chatbots, educational platforms, or customer support systems, can involve repeated requests. Such redundant requests, when handled via caching, result in substantial cost savings.\n2. **Lower Latency:** By serving responses from the cache, you can significantly decrease response times. This results in a more seamless and responsive user experience, especially critical in interactive applications such as conversational AI systems.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ec13c61f-3b7b-4921-a8eb-1a61701032f6": {"__data__": {"id_": "ec13c61f-3b7b-4921-a8eb-1a61701032f6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "38b8056b-31ec-4341-96ea-6db2a7dc416d", "node_type": null, "metadata": {}, "hash": "c623fa0568a85447f84ecf4a6258d3dfebad285232a0f8ad6685234ffa425668"}}, "hash": "bc87671abeb07edb1f3ec49f5d7739110d75d30441d6fdae3fae1fff5f60c218", "text": "Real-World Use Cases\n\nLet's look at a few examples to illustrate how caching can be beneficial.\n\n**Knowledge Base Chat Applications:** In these applications, many queries are often repetitive with minor variations in wording or phrasing. Leveraging Semantic Cache can be highly beneficial in this scenario. It can match the input prompt with previously cached requests based on contextual similarity, thereby avoiding the need to make a costly API call. The cache can serve the response instantly, reducing latency and saving costs.\n\n**Retrieval Augmented Generations (RAGs):** RAGs often involve making repeated API calls to retrieve relevant documents or pieces of information. Caching can play a significant role in reducing these redundant calls, especially when a similar question or document retrieval request is made.\n\nBy implementing Portkey's caching feature, you're not only optimizing costs but also improving the performance and responsiveness of your AI-powered applications. This double advantage can be a significant factor in enhancing your application's scalability and user experience.\n\n\\", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5024ec2f-74a6-4f64-b58e-145a3e04e498": {"__data__": {"id_": "5024ec2f-74a6-4f64-b58e-145a3e04e498", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "28476864-4b3c-413f-a4ee-17f7548f6b89", "node_type": null, "metadata": {}, "hash": "12e4fb6dbab269d938841543b7a7a71fdc77f89da02fc8c4601563d17f3d80b3"}}, "hash": "9355619cc9b8df7cca7dbbb89a616a3c8979ec1487f3223aa0ba65a6f7b4a371", "text": "\ud83d\udc40 Observability\n\nGenerative AI applications often have numerous moving parts and dependencies, making it crucial to have a way to monitor and understand system behavior and performance. Observability allows you to get insights into what is happening inside your application and can help identify issues or opportunities for optimization.\n\nHere's how Portkey can enhance the observability of your AI applications:", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "67955a37-8c5f-4ad8-b2a5-66acddde4c08": {"__data__": {"id_": "67955a37-8c5f-4ad8-b2a5-66acddde4c08", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "14373e0d-54df-47f1-9d27-d6a254e892d0", "node_type": null, "metadata": {}, "hash": "eaa8eba7a74ea435a1e27dc2c1eaa5062f85afb64d885e637ac7ef4e121109f2"}}, "hash": "2936f8fad8dd0737ba940d9342329a50b92e24657c95ce93a6d7293e72a155b0", "text": "Detailed Analytics\n\nPortkey offers a comprehensive analytics dashboard with detailed metrics on various aspects of your application. These metrics include:\n\n* **Request count:** Monitor the total number of requests made to different Large Language Models (LLMs).\n* **Cost:** Keep track of the expenses associated with each LLM.\n* **Latency:** Understand the time taken to process requests, which can help identify performance bottlenecks.\n* **Tokens:** Monitor the token consumption per request.\n* **Cache hits:** Understand the efficiency of caching strategies by monitoring the cache hit rate.\n\nThese metrics provide a wealth of information that allows you to gain valuable insights into your application's behavior and performance, enabling you to make data-driven decisions.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ff15c8b5-c807-4d24-8956-9de59c1f5c51": {"__data__": {"id_": "ff15c8b5-c807-4d24-8956-9de59c1f5c51", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3d292e04-cbda-4858-b780-680142b9eaaf", "node_type": null, "metadata": {}, "hash": "3b8c54f03adab33f1eb3155209716301adfaaab8bed14c611bc3f0eb81c1022f"}}, "hash": "89a8e4addc821be7893c030689ed73821b7ed390ba57c84bfc112afe50a56f54", "text": "Comprehensive Logging\n\nPortkey offers robust logging, which can be incredibly useful for debugging and optimizing your AI applications. The logging feature keeps track of all requests passed through Portkey in chronological order. It acts as a managed data store, storing all raw request data which can exported anytime.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8e496376-68f7-456a-8581-423ed7841e33": {"__data__": {"id_": "8e496376-68f7-456a-8581-423ed7841e33", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b6fbf9e3-e0de-4ad9-8661-c11180333a14", "node_type": null, "metadata": {}, "hash": "627a8eec6ba569a9907630290146d2fc9f190c618ef2319ee070fa2170b9eaf2"}}, "hash": "0ebe1ceb9babeed0a039ed076d710aa493a401bc0f929055e0971c1928223e50", "text": "Segmenting and Analyzing LLM Spends\n\nPortkey's custom metadata properties allow you to segment, filter, and analyze your LLM spends in a granular way. This is particularly useful for multi-tenant systems or SaaS companies, which often need to understand usage and costs on a per-customer basis.\n\nFor instance, if you run a SaaS company with multiple customers, you can pass customer-specific identifiers as metadata in your Portkey requests. These identifiers then appear in the Portkey dashboard, where you can filter and segment costs, tokens used, request count, and latency by customer. This feature gives you insights into the usage patterns of individual customers and allows you to attribute costs accurately.\n\n\\", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b9e6104d-dd33-49e2-b83b-de85439a33f2": {"__data__": {"id_": "b9e6104d-dd33-49e2-b83b-de85439a33f2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f3614ed3-168c-45df-b901-22b8124df8dc", "node_type": null, "metadata": {}, "hash": "3fa415d2c48bb1aeebfd9aab95d98d67ce4a001b223db7463a5ea032f9cca103"}}, "hash": "f7517c687a14dfaf920cd2ac36360142b963dd278122014ac1da939715fa598d", "text": "\u2705 Optimise generation quality\n\nLarge Language Models (LLMs) have become increasingly powerful tools, capable of generating content with human-like fluency. However, ensuring that the generated content adheres to specific quality standards or conforms to a desired format can be challenging. This inconsistency can pose a significant challenge, especially for businesses that rely on these models for customer interaction or content generation.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "728dd98c-f5fb-4b88-95a7-8bc9bf2ca3b6": {"__data__": {"id_": "728dd98c-f5fb-4b88-95a7-8bc9bf2ca3b6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2edf271d-390b-4239-bdd5-de22b330e740", "node_type": null, "metadata": {}, "hash": "734ab57b0abd410939ef4e0d42c96770529b06ff2c5b668c0b00f3923457c75b"}}, "hash": "1426148b487e0a59db7c6aaa05b0607f8d5037594107e3061f92537f36732649", "text": "The Solution: Advanced Quality Control with Portkey\n\nPortkey provides several advanced features and tools to ensure the quality and consistency of the output generated by LLMs.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a5a7c01a-96eb-44b0-a364-0e899d1e8fba": {"__data__": {"id_": "a5a7c01a-96eb-44b0-a364-0e899d1e8fba", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "696c522f-aa8d-441e-8028-8d7c4fd3d027", "node_type": null, "metadata": {}, "hash": "51de4e46d3ecbee0dff6aa8f85dee638df573f1828bc1342d676cdd866a59251"}}, "hash": "677fd07b0dfbcf119aaacc5a392204c3c3d36ac29fd6dbd1097e8c455a6325eb", "text": "Schema Validation\n\nPortkey can apply schema validation to the output of an LLM. With this feature, the generated text is checked against predefined patterns or formats, ensuring the output adheres to a certain standard or structure. This is particularly useful for use-cases where specific formatting or data structures are crucial.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "400b13c0-f99d-4d35-bbef-35b807682d21": {"__data__": {"id_": "400b13c0-f99d-4d35-bbef-35b807682d21", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2b691166-614c-45cc-b393-2262e15ac663", "node_type": null, "metadata": {}, "hash": "fa76ac2f17f6a5a2c55463cf391209619035747422638d893f9dcfd5af18a398"}}, "hash": "aa2bfd11813cf2ff5790289d26ad4cd3e1dc469cd4e7ac6bac065eca5fb22ff9", "text": "Rule Engines\n\nAnother powerful tool at your disposal is the Rule Engine. This tool allows you to define specific rules that the LLM output must comply with. The rules can be defined based on the context of your application, ensuring that the output meets the required criteria, thus improving the quality and usefulness of the generated text.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f044ad57-dca6-43d8-9517-bb331d26a64b": {"__data__": {"id_": "f044ad57-dca6-43d8-9517-bb331d26a64b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1ae0dc55-e615-4680-8bb7-d21090f7c034", "node_type": null, "metadata": {}, "hash": "1db4276b0353f3d0c5550d7606b71115c366f0c8bd80a833a9b873ca6e014c28"}}, "hash": "d7ff2b183c520e217d2c06d94ff7ae8674b6388a95332d45a431ad5360de1084", "text": "Evaluation Models (Evals Framework)\n\nPortkey also supports the implementation of evaluation models. In this setup, the output from one LLM is evaluated by another, acting as a sort of 'double-check' on the initial model's output. This can be a powerful tool for improving the quality and accuracy of LLM outputs, especially in complex or high-stakes use-cases.\n\n{% hint style=\"info\" %}\n**Please note:** that schema validation, rule engines, and the Evals framework are currently custom enterprise features. If you're interested in deploying these advanced quality control features, reach out to our support team for a discussion.\n{% endhint %}", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}}, "docstore/ref_doc_info": {"5b82c9c8-2180-4e66-82e2-241b7c30ec93": {"node_ids": ["ba9a7531-0686-4676-a7c1-2dc95cd32ab3"], "metadata": {}}, "c5673611-25e2-41d9-9876-9af11e195cf5": {"node_ids": ["e0a67cd4-96c0-49e6-8772-13e5d7719ea1"], "metadata": {}}, "53dcb9dd-469f-49cc-80eb-3206a877b2a0": {"node_ids": ["1104a174-6faf-4886-9066-da11f9dd4426"], "metadata": {}}, "0dc195f2-5f50-4e4f-8d74-fbd2af902028": {"node_ids": ["1621aff0-390d-49fd-8ea1-27bbd7e3ad69"], "metadata": {}}, "d79af461-1059-4e52-9556-4891affa01c8": {"node_ids": ["ab7ef162-cc64-4fe3-828d-f15872a555fe"], "metadata": {}}, "eb1f3b57-90f3-49d0-972d-de767ce72e9a": {"node_ids": ["caaa9ccb-2128-4bfc-a889-546596efba36"], "metadata": {}}, "c9a4642b-d62e-4ad6-b31d-0062a0ca3a4a": {"node_ids": ["1120dfdf-84d3-45f1-af06-58aaf34db4d8"], "metadata": {}}, "1fcf03cb-ecee-4d5e-b18a-d9ee72a327d0": {"node_ids": ["67576b61-fe66-467a-99c4-67b0bf1d8fe7"], "metadata": {}}, "786a7d7a-0162-4682-b02b-531e5f4fc69f": {"node_ids": ["3343f310-aeb4-47e8-9dbb-eb8f3e685148"], "metadata": {}}, "ea6b23f1-6fd5-4771-882d-3ea60524b2b1": {"node_ids": ["57335c00-85a2-4545-9bb3-86cb34df99d4"], "metadata": {}}, "db3e17d0-e3f4-4e60-8045-5a737f60f8a2": {"node_ids": ["83312263-367a-4824-a734-bf0b4d77dc3d"], "metadata": {}}, "18d99bb5-3e1d-42f9-ba56-97d775b9be75": {"node_ids": ["8800b157-05d6-4a6d-bbce-5d308257cc03"], "metadata": {}}, "215fcb91-3729-4a8e-b0c6-fcb94d63c1f9": {"node_ids": ["86b50afc-a925-4111-9456-6a8f7b12989c"], "metadata": {}}, "c0e152a5-e5de-469d-8296-e42e4c91ce06": {"node_ids": ["0f6803b4-62f6-476a-a53a-f5be9db4202f"], "metadata": {}}, "b6dd1d79-b51e-4a4c-a10b-01042ab1231e": {"node_ids": ["48ed0995-1268-4c5d-b607-bc625ab314d2"], "metadata": {}}, "b906dc53-6218-4965-bbee-11ff3773cbc3": {"node_ids": ["88df517c-4cd4-4d2e-8d2a-cd6133369f83"], "metadata": {}}, "6aefc6b9-dfc7-4145-8af6-d4cfe1d88b66": {"node_ids": ["f21e204c-75fe-47ce-8d94-2f14e7937b18"], "metadata": {}}, "395eba3c-e464-4324-91b7-cf394d58ff01": {"node_ids": ["6b01e2e3-1673-472e-b23e-23056336a225"], "metadata": {}}, "d9effd90-3af2-4a95-8ad0-0893de9c33d6": {"node_ids": ["8bf1c777-9a47-43bf-bf10-60255d41a41e"], "metadata": {}}, "16350240-6b3d-4820-b90a-c8c4fd7914f7": {"node_ids": ["d4917204-7877-4c05-897e-0508541366aa"], "metadata": {}}, "3b3c553c-e5d5-4856-911b-c7c534ff1862": {"node_ids": ["0b515d5b-25f7-4940-a6d4-10998acc2ad5"], "metadata": {}}, "97ba6cc2-d0ec-458e-bf08-51f1d6f6f23d": {"node_ids": ["093f3a55-f88d-4700-a923-4cae145b83f4"], "metadata": {}}, "76299b89-621f-4bbf-93ad-30aebf63a51c": {"node_ids": ["9b6457bd-fc86-4c61-8602-f21dc0aa81f9"], "metadata": {}}, "5c4bf2ac-c79b-4f64-930e-f6173e1ed4ca": {"node_ids": ["3d04cc60-492c-4a76-8c69-fbf6547c080e"], "metadata": {}}, "1e4eee52-55ec-4844-9b25-c1dbaf2dd1ec": {"node_ids": ["dcaf4562-9459-4354-b610-c84a8c793ff8"], "metadata": {}}, "c56e98d0-04c6-4b38-9561-f61bcef455b6": {"node_ids": ["674a9836-0f12-4047-a408-4d4f0557d6b1"], "metadata": {}}, "93e29045-984c-482e-b950-eb3404307ee8": {"node_ids": ["fbd5655e-c9d9-427a-868e-5a8b8da8d6d8"], "metadata": {}}, "35ca024e-0d5f-4a44-8c30-4da4a10bc5c9": {"node_ids": ["4eb8d14d-142c-4448-912d-9894392b7d97"], "metadata": {}}, "d9c8293b-e05c-4d6f-85d2-d1a28989434b": {"node_ids": ["c8f8f369-e67b-40fd-9c8c-e3781dfcb187"], "metadata": {}}, "1e93e5ce-8803-4eba-a06a-475d4452b068": {"node_ids": ["37911521-c008-4380-bbc4-3b87b4edf03f"], "metadata": {}}, "333ef42d-36fd-47a5-9ec1-69d996c5d8cb": {"node_ids": ["51af44e6-3769-46b7-9d21-b00261c0a866"], "metadata": {}}, "cd66a153-e7b6-4868-806c-9c0656c3397b": {"node_ids": ["180651cb-4dcd-4d26-8fcb-32a2736ba755"], "metadata": {}}, "5cc245ff-6233-496b-bb08-15b535ae1ac8": {"node_ids": ["4413de61-7dde-4956-9882-f2df64df1254"], "metadata": {}}, "4403b0c6-b720-4cc4-a2c1-3257daa22cc6": {"node_ids": ["983f1bd7-b6e8-41b3-855b-4f1d0b3e6c7e"], "metadata": {}}, "44ad1a04-e735-4821-ad7a-c69bba1a9be1": {"node_ids": ["a9d4c944-0af5-4676-8bfa-467a05654765"], "metadata": {}}, "1b1e80ce-831e-4f58-84b5-d9d2ff22e57d": {"node_ids": ["f1af9896-a273-4528-a77b-34cc3a58afc2", "ad31252d-fced-48ed-9396-87e1bdec871c"], "metadata": {}}, "5531282c-224e-4a4d-a57e-ab7e8088226d": {"node_ids": ["d75cdc57-282b-4f5f-a685-45947f66feec"], "metadata": {}}, "c442f20d-9eea-4b17-807f-395b8ca4098f": {"node_ids": ["23b800d2-e7f7-45ac-bd2c-84ef31ccf428"], "metadata": {}}, "fd28e723-a1f8-4a41-91ce-023a2b41de59": {"node_ids": ["0cf396a0-1ad0-4fa4-be0a-d0d923279106"], "metadata": {}}, "e716c6ef-b39b-432a-afa0-48e3407dc6ae": {"node_ids": ["dfd7af61-33c8-456c-8f3d-24c2125b9c90", "a8f25adb-05de-4ab5-8fba-a57b5ec6ffff"], "metadata": {}}, "866a1ff1-100d-45c6-86d8-d4a7e7b78dfe": {"node_ids": ["edfddad1-fe34-42c5-96ac-f270e9e40cf8"], "metadata": {}}, "2829ca34-f061-428d-abb9-0fd026b6a0d1": {"node_ids": ["dfbb728c-c6ce-4213-9ed2-8047eeb9a0ba"], "metadata": {}}, "ce2e6bbc-d494-443a-8484-2d26fafa5653": {"node_ids": ["80991f3e-b5a8-427f-b66c-a1081f86610c"], "metadata": {}}, "92bec081-db05-4090-83d1-9d0641d2db6a": {"node_ids": ["eb564ce8-4238-4ab9-b47d-77398f6dd043"], "metadata": {}}, "a0f8b6cf-6b44-4fd4-829f-cbd60e620347": {"node_ids": ["26aba237-a755-4768-841b-acfc6a55c184"], "metadata": {}}, "79595773-0b28-409a-b62c-765f018efb84": {"node_ids": ["2368aa10-a50e-41c1-83b1-91e5dde747d3"], "metadata": {}}, "52eab5c2-81f9-4ab3-81f1-1d99b984af5f": {"node_ids": ["2959e80a-69a0-4111-9c58-965cfd11c15d"], "metadata": {}}, "a9c5a44c-f72c-4e1d-b94d-c566a05da566": {"node_ids": ["2efeffe5-d122-43f5-a1f9-ce026399c4fe"], "metadata": {}}, "b1490c59-64f6-40f4-9fd2-e059202e30c0": {"node_ids": ["916f9a74-313e-4cf9-8726-1c8942810111"], "metadata": {}}, "59751c52-fd4f-4cb5-8aef-62ed442d6dff": {"node_ids": ["fd15a747-02e9-4d22-8bdc-55b80542d621"], "metadata": {}}, "4c3eea78-409b-4958-81ae-21b705391912": {"node_ids": ["b05a9cda-aee6-43b7-8d99-2c06eaa1391c"], "metadata": {}}, "7fe19708-d622-44a4-9a7a-786aa51572a3": {"node_ids": ["41a0db27-ea63-4bd0-8309-f681eccf4930"], "metadata": {}}, "f74d0530-7a58-4130-81b2-b77b6980b4ab": {"node_ids": ["ecb4a727-3ea5-47c2-9e59-58aad4ef5aaf"], "metadata": {}}, "6af856a7-a11f-414f-8373-a30f3c41256f": {"node_ids": ["6cbefecd-d8ae-488d-9154-499e72dd457b"], "metadata": {}}, "08155926-75df-419b-9458-caf2c5ecc4b1": {"node_ids": ["1394cf79-1097-4a0a-a125-866bf0cd6ff5"], "metadata": {}}, "1c716923-b0cc-4797-b227-8230b1fd6e3a": {"node_ids": ["d1dbeadf-2aa3-414a-97b3-d141f3b9c3b9", "e3f1f5a8-3155-4993-87c7-067fdfb085c5"], "metadata": {}}, "28f7d049-9981-48cf-84e2-795bf233cf37": {"node_ids": ["96f3f9bf-10de-47e9-8249-6fde48f9efed"], "metadata": {}}, "7b197ddb-be91-4b3a-a59b-19cffb0b6342": {"node_ids": ["7b51c1c9-8766-4bcf-af8d-fc85716382f4"], "metadata": {}}, "24982706-85ac-42c3-97ac-b4a8c6592e5d": {"node_ids": ["00247de5-53b9-4132-8cf1-1894520eea00"], "metadata": {}}, "3b4440f3-9ce7-4247-adc0-9b23087c575e": {"node_ids": ["8d6f9167-7136-45fe-86ea-874654f8a1d8"], "metadata": {}}, "176eb101-e2ae-41b1-8a7b-450927351381": {"node_ids": ["d57fd3e2-50f8-4227-bd65-546f59efac42"], "metadata": {}}, "9d5e8ae6-6752-4f6a-8377-e72ad5638a9b": {"node_ids": ["f7439589-3c5b-41f2-bdcf-988d4a812554"], "metadata": {}}, "06260f5f-be7b-4e98-9fb3-4c99ea145024": {"node_ids": ["f2221112-3449-44c6-bab6-aff75f7121e2"], "metadata": {}}, "7e21868e-ba9b-4380-a855-202521461f7f": {"node_ids": ["8f8f5849-db4a-42d2-a0b0-6bf40c3b728c"], "metadata": {}}, "be7eb8e5-f387-49e6-986c-690078e6b936": {"node_ids": ["3decb7da-8680-4271-9404-d06f8b3147c6"], "metadata": {}}, "aaf0c6f3-3762-4803-9d2c-0132320bbbe7": {"node_ids": ["6f354758-03bd-4f2c-9e7a-eca5fe771af9"], "metadata": {}}, "978d0625-cc07-4571-bfe3-0186b76ce3d9": {"node_ids": ["5ee2bc36-14dc-48e6-8206-fa10b730ea42"], "metadata": {}}, "1e938a27-90ae-4c2b-9c1a-07e6f872155a": {"node_ids": ["519ee882-f657-417f-8a6f-bd72b5f78e43"], "metadata": {}}, "b7ffda72-c1af-4db3-9444-f6be67aa1cae": {"node_ids": ["202f62ca-3ec0-4749-a3e0-73c17283baa5"], "metadata": {}}, "705b6355-14b5-4f65-a675-8df3df6e5a93": {"node_ids": ["07dc98ef-6c28-4888-96bb-1a4b79631956"], "metadata": {}}, "8fa50a61-710c-4afd-8840-c3f3381797df": {"node_ids": ["238ff9fe-dac6-4210-ab02-ea813497d3b6"], "metadata": {}}, "24dd446e-eae0-42f8-9eda-28e3458bb578": {"node_ids": ["2a4b99cc-c591-4ea2-b9e9-5a918f72e612"], "metadata": {}}, "da610f06-05fe-46f6-bf63-22501ba7af0e": {"node_ids": ["37bbecbc-d030-430a-99a3-4af1b0884727"], "metadata": {}}, "0c0963c2-7f45-4042-888a-9480b7f17784": {"node_ids": ["c04489b6-4fdb-4da9-adbf-ddc0d06c2728"], "metadata": {}}, "4761dfb3-ae18-4e5c-852a-c3548477a115": {"node_ids": ["c79b5fd6-c191-4690-8b2c-c726f518203d"], "metadata": {}}, "5b70fabd-409d-4e3b-aa8f-14f81ff6d65a": {"node_ids": ["5bd6939c-819a-4493-af8d-68dd236485a3"], "metadata": {}}, "cc48af09-46e0-49f4-b5c2-87ff02466785": {"node_ids": ["e0d7f6db-080c-4fe0-b843-9fa8d84b4b62"], "metadata": {}}, "53962387-3b3c-446b-ab21-cacf504125b9": {"node_ids": ["894bde9d-eafe-44a8-9367-b3099157fbcb"], "metadata": {}}, "96e9b347-9800-47eb-9399-a007f8745435": {"node_ids": ["1f03a7b6-28ee-4fcd-982c-9a9422754a8c"], "metadata": {}}, "3d2ed38b-83b4-463c-879d-4848c17b90ea": {"node_ids": ["324cc595-857f-45ca-8360-4233190e025e"], "metadata": {}}, "86157561-6dd2-4a14-9bf9-b8e8b375e3d7": {"node_ids": ["9476e54d-0429-4847-ab4c-b9c5ccf8a46e"], "metadata": {}}, "4e1c9e4b-560f-464c-b90d-d1075a93d7bd": {"node_ids": ["99bfb10e-ac7d-4e16-999b-164541594b80"], "metadata": {}}, "f65ae39d-cc22-4635-bafc-8e425f8d82df": {"node_ids": ["5b7ed734-84ff-4de2-9e39-02b5c164a55d"], "metadata": {}}, "a72ef4a7-876d-4f9e-8bb5-451205468c25": {"node_ids": ["325f3751-529b-4fec-a588-9240fcc269e8"], "metadata": {}}, "f108b656-0942-4bdb-aa15-147e155bcabe": {"node_ids": ["03aa987c-e625-4aec-b25f-0857d9200065"], "metadata": {}}, "9cf70eb0-ad15-4132-bd17-885ae901cac8": {"node_ids": ["dd9ae3d1-9ac1-488c-b824-1b32a32577ed"], "metadata": {}}, "b524c727-3cf8-4da2-96d6-f6e24845ae2c": {"node_ids": ["352067db-0ab3-4203-a0f8-a410b6a87035"], "metadata": {}}, "bd593e76-48d0-4dd3-b561-00acf3774855": {"node_ids": ["ced33566-3104-449d-b02c-99184f97aeeb"], "metadata": {}}, "e1a6c8c7-cc88-4e8f-bb8c-243799aebc29": {"node_ids": ["ccb540b8-d20b-4663-b141-995ac3bf2ecc"], "metadata": {}}, "f3473ea0-1f2c-4e67-8efb-fdfc58dab74f": {"node_ids": ["55c176fd-634f-4495-8a72-161154af928e"], "metadata": {}}, "2c9b2e2a-f464-43f5-8c41-8f69c2f6033e": {"node_ids": ["663c29f8-ba22-4422-9906-22b39ea30d3e"], "metadata": {}}, "38467dda-af5e-44ec-b279-59183b7c27e1": {"node_ids": ["34aac729-477d-4c8d-b833-11b53bb44ca2"], "metadata": {}}, "d0c163a5-9633-44e2-a3f3-448fd7cf231e": {"node_ids": ["05ddfff9-d2a5-4972-bba3-0837fda91359"], "metadata": {}}, "b670af70-1630-4f47-a3bc-6dab9c2a37dd": {"node_ids": ["8516a98f-dd9f-4b63-80fd-c2bd1a26ff9e"], "metadata": {}}, "b46bee36-9570-442d-9993-fd84ea983d3d": {"node_ids": ["86f26d9b-997a-4ac5-9ac4-18f4879e6538"], "metadata": {}}, "9ac93175-0006-4ce3-90d7-2507a4e86108": {"node_ids": ["0ebde556-153e-40a3-977b-b2c29acdd741"], "metadata": {}}, "4059bd20-22f9-416f-afdc-298c74db92a7": {"node_ids": ["b993d1b0-3ff7-419e-9062-cdc8f03212de"], "metadata": {}}, "57f564f7-c3aa-4562-b2c4-e886a2dcdb53": {"node_ids": ["10d1d9c5-972f-4791-bacc-27cbd7d13bf0"], "metadata": {}}, "61fa05b9-975c-4b4b-9667-7e3489e10f9f": {"node_ids": ["39009157-471d-48cd-a9b5-eaa31b5f6da2"], "metadata": {}}, "19810c6a-0868-4938-ab54-f3b5cc53c9ce": {"node_ids": ["aa2d68ef-16a9-46fd-8a27-2c9d9cbd9ca8"], "metadata": {}}, "d2641fbb-61a7-42a5-836a-171a1b20435f": {"node_ids": ["954ff2a0-1196-42f1-983e-6efcdd5d7524"], "metadata": {}}, "cb5857cd-adf9-465f-945d-b7b30c423cb8": {"node_ids": ["a0867702-90de-4456-9599-a95f45e14a5a"], "metadata": {}}, "51a81a72-5799-476e-b148-44c937a06617": {"node_ids": ["ff1d4027-9bf3-4f0d-ab35-23519d1a6d02"], "metadata": {}}, "1fdd6e9a-5056-478f-b748-9ea0a81b8a10": {"node_ids": ["468749e8-6f0d-4163-b757-b73cc4c4d015"], "metadata": {}}, "fd442994-cc71-4b2a-a933-6d3865192a74": {"node_ids": ["c1f85d04-22fd-4ba1-8aba-a6b59f6c83bf"], "metadata": {}}, "77db2ca6-b087-4cab-93b3-6004dbe062ec": {"node_ids": ["a7903ec9-eeff-4e56-8ee4-4f91c7fe78ab"], "metadata": {}}, "49ef36e9-1c50-4ae2-a637-6f1c4a417970": {"node_ids": ["7eef4428-ca99-44e4-aecb-546a397e51a5"], "metadata": {}}, "d6df3a02-605e-41f1-aa46-38afa2349f49": {"node_ids": ["8eebda44-6dd5-4a4f-9a23-43113ad2e27d"], "metadata": {}}, "d975c688-3148-4d04-b3b5-0178dab9adae": {"node_ids": ["99a7825e-5144-4be4-908c-df1c76b96807"], "metadata": {}}, "3cd81b77-ab85-41ec-9c79-9fb3cc86cf25": {"node_ids": ["7698812d-4bd2-45f8-82fd-1212f7597c4f"], "metadata": {}}, "0ba565cf-c482-4ae1-a6be-fee70ec18d8c": {"node_ids": ["5f1094d6-90d6-49c7-8484-e15b969db0b3"], "metadata": {}}, "7536941f-493f-4b78-ac96-25be7855a2ea": {"node_ids": ["2ffc7478-010d-486e-acd0-c3e3ba904b5c"], "metadata": {}}, "4ef6c73e-70af-45ee-a8a2-31a490be96b1": {"node_ids": ["70311f0c-16e4-4954-91dc-ba07d364b7ba"], "metadata": {}}, "5bea2810-f0c6-491b-b964-19f7e7b957d3": {"node_ids": ["42963d8c-7fff-4167-81cc-8228376ba834"], "metadata": {}}, "38b8056b-31ec-4341-96ea-6db2a7dc416d": {"node_ids": ["ec13c61f-3b7b-4921-a8eb-1a61701032f6"], "metadata": {}}, "28476864-4b3c-413f-a4ee-17f7548f6b89": {"node_ids": ["5024ec2f-74a6-4f64-b58e-145a3e04e498"], "metadata": {}}, "14373e0d-54df-47f1-9d27-d6a254e892d0": {"node_ids": ["67955a37-8c5f-4ad8-b2a5-66acddde4c08"], "metadata": {}}, "3d292e04-cbda-4858-b780-680142b9eaaf": {"node_ids": ["ff15c8b5-c807-4d24-8956-9de59c1f5c51"], "metadata": {}}, "b6fbf9e3-e0de-4ad9-8661-c11180333a14": {"node_ids": ["8e496376-68f7-456a-8581-423ed7841e33"], "metadata": {}}, "f3614ed3-168c-45df-b901-22b8124df8dc": {"node_ids": ["b9e6104d-dd33-49e2-b83b-de85439a33f2"], "metadata": {}}, "2edf271d-390b-4239-bdd5-de22b330e740": {"node_ids": ["728dd98c-f5fb-4b88-95a7-8bc9bf2ca3b6"], "metadata": {}}, "696c522f-aa8d-441e-8028-8d7c4fd3d027": {"node_ids": ["a5a7c01a-96eb-44b0-a364-0e899d1e8fba"], "metadata": {}}, "2b691166-614c-45cc-b393-2262e15ac663": {"node_ids": ["400b13c0-f99d-4d35-bbef-35b807682d21"], "metadata": {}}, "1ae0dc55-e615-4680-8bb7-d21090f7c034": {"node_ids": ["f044ad57-dca6-43d8-9517-bb331d26a64b"], "metadata": {}}}}